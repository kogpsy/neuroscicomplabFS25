[
  {
    "objectID": "ddm.html",
    "href": "ddm.html",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "22.1 DDM: Modell eines Entscheidungsprozesses\nIn unserem Random dot Experiment wurde neben der Antwort der Versuchspersonen (links, rechts) auch die Zeit (rt) gemessen, welche ben√∂tigt wurde um diese Antworten zu geben. Diese Information wurde in den vorherigen Modellen nicht gleichzeitig mit der Antwortgenauigkeit ber√ºcksichtigt.\nEin Modell mit dem solche Entscheidungsprozesse modelliert werden sind Drift-Diffusion-Modelle. Es geht davon aus, dass bin√§re Entscheidungen auf der Anh√§ufung von verrauschten Beweisen basieren, beginnend am Ausgangspunkt und endend an einer Entscheidungsschwelle, die mit einer bestimmten Entscheidung verbunden ist.\nDas Modell hat mindestens vier Parameter:\nDie Gesamtzeit f√ºr eine Reaktion ist die Zeit f√ºr die Ausbreitung vom Startpunkt bis zur Grenze plus die Non-decision time.\nIm Modell wird die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt (diskrete Zeitschritte). Diese Evidenz wird in einer Entscheidungsvariable (decision variable: dv) gesammelt.\nUm nachzuvollziehen, wie sich eine Entscheidung (in unserem Beispiel: rechts und links) innerhalb eines Trials entwickelt, kann dieser Prozess in R simuliert werden.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#der-entscheidungsprozess",
    "href": "ddm.html#der-entscheidungsprozess",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "Es gibt 2 M√∂glichkeiten die gew√§hlt werden k√∂nnen (in unserem Beispiel: rechts und links).\nEs wird angenommen, dass die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt ist (diskrete Zeitschritte).\nAusserdem wird davon ausgegangen, dass die Person den Stimulus verarbeitet und √ºber die Zeit Evidenz akkumuliert (sequential sampling).\n\n\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('links', '0', 'rechts')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#random-walk",
    "href": "ddm.html#random-walk",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.2 Random walk",
    "text": "22.2 Random walk\nEin Random walk ist das Resultat der Aufsummierung von Zufallszahlen. Dies kann in R selbst nachvollzogen werden:\nDazu wird ein Random walk mit 100 Zeitschritten simuliert (mit rnorm()). Es wird mit \\(0\\) begonnen und dann werden 99 normalverteilte Zufallszahlen dazuaddiert, also die kumulierte Summe berechnet (hierf√ºr eignet sich die Funktion cumsum()).\n\nRandom walkCode\n\n\n\n\n\n\nlibrary(gganimate) # library for animation\nset.seed(546)\n\n# 0 + 100 standardnormalverteilte Zufallszahlen\nzufallszahlen_1 = c(0, rnorm(99, 0, 1))\nrandom_walk_1 = cumsum(zufallszahlen_1)\n\nd1 = tibble(t = 1:100,\n            rand_walk = random_walk_1)\n\nd1 |&gt;\n    ggplot(aes(x = t, y = rand_walk)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Random walk') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    theme_classic() +\n    transition_reveal(nb) # animate\n\n\n\n\nDie aktuelle decision variable zu Zeitpunkt \\(t\\) als wird hier als normalverteilte Zufallszahl modelliert. Dieser Random walk hat keinen Trend, weil jeder Wert aus einer Normalverteilung mit Mittelwert \\(\\mu=0\\) gezogen wird.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenzakkumulierung",
    "href": "ddm.html#evidenzakkumulierung",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Evidenzakkumulierung",
    "text": "22.4 Evidenzakkumulierung\nDie Evidenzakkumulierung kann als Iterationen √ºber einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# F√ºr jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on f√ºr Interessierte: Funktion erstellen\n\n\n\n22.5 Hands-on:\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.5,\n                sd = 0.1,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # F√ºr jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\n\n\nDie Decision Variable dv repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable gr√∂sser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#auswirkungen-der-parameter",
    "href": "ddm.html#auswirkungen-der-parameter",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.5 Auswirkungen der Parameter",
    "text": "22.5 Auswirkungen der Parameter\nUm den Effekt dieser Parameter zu visualisieren, k√∂nnen Trials mit unterschiedlichen Parameterwerten geplottet werden.\n\n22.5.1 Drift rate\nWenn die drift rate viel gr√∂sser als \\(0\\) ist, also \\(&gt;&gt; 0\\), wird die obere Entscheidungsgrenze (decision boundary) schnell erreicht. Zudem wird es nur wenige Fehler geben. Ist die drift rate kleiner, aber immer noch \\(&gt; 0\\), wird die durschnittliche Zeit l√§nger, um eine korrekte Antwort zu geben.\n\nHohe vs.¬†tiefe drift rateCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(829)\n\nslow = drift_diffusion(driftrate = 0.8) |&gt; mutate(type = \"slow\")\nfast = drift_diffusion(driftrate = 1.2) |&gt; mutate(type = \"fast\")\n\nfastslow = bind_rows(fast, slow) \n\nfastslow |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue3\", \"skyblue\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.2 Bias\nWenn der bias \\(&gt;0.5\\) ist, wird die obere Entscheidungsgrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate‚Äîist diese klein, und der bias \\(&lt;0.5\\), ist die Chance, schnelle Fehler zu machen erh√∂ht.\n\nStarting point (bias)Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(29)\n\nunbiased = drift_diffusion(bias = 0.5) |&gt; mutate(type = \"unbiased\")\nupbiased = drift_diffusion(bias = 0.7) |&gt; mutate(type = \"upbiased\")\ndownbiased = drift_diffusion(bias = 0.3) |&gt; mutate(type = \"downbiased\")\n\nbias = bind_rows(unbiased, upbiased, downbiased) \n\nbias |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\",\"skyblue3\", \"skyblue4\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.3 Boundary separation\nLiegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies f√ºhrt dazu, dass weniger Fehler gemacht werden, da die zuf√§llige Fluktuation √ºber l√§ngere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erkl√§ren.\n\nDecision boundariesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(90)\n\ncarefree = drift_diffusion(decision_boundary = 1.6) |&gt; mutate(type = \"carefree\")\ncautious = drift_diffusion(decision_boundary = 2.1) |&gt; mutate(type = \"cautious\")\n\ncautiouscareless = bind_rows(carefree, cautious) \n\ndecision_boundaries = tribble(~type, ~decision_boundary,\n                               \"carefree\", 1.6,\n                               \"cautious\", 2.1)\ncautiouscareless |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +\n    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +\n    theme_classic()\n\n\n\n\n\n\n22.5.4 Non-decision time\nEine Ver√§nderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.\n\nNon-decision timeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4534)\n\nlongndt = drift_diffusion(ndt = 0.7) |&gt; mutate(type = \"longndt\")\nshortndt = drift_diffusion(ndt = 0.2) |&gt; mutate(type = \"shortndt\")\n\nndt = bind_rows(longndt, shortndt) \n\nndts = tribble(~type, ~ndt,\n                \"longndt\", 0.7,\n                \"shortndt\", 0.2)\n\nndt |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\n\nHands-on: Interpretation der Random Dot DDM Parameter\n\n\n\n\nDDM Random Dot ExperimentCodeDaten\n\n\nWie k√∂nnen die DDM Parameter interpretiert werden?\n\n\n\n\n\nterm\nestimate\n\n\n\n\nDrift rate\n0.01\n\n\nbs_accuracy\n3.07\n\n\nbs_speed\n2.48\n\n\nndt\n0.00\n\n\nbias\n0.50\n\n\n\n\n\n\n\n\nlibrary(brms)\nlibrary(cmdstanr)\n\nfit = brm(bf(rt | dec(resp) ~ 0,\n             bs ~ 0 + condition),\n          data = d,\n          family = wiener(link_bs = \"identity\",\n                          link_ndt = \"identity\",\n                          link_bias = \"identity\"),\n          cores = parallel::detectCores(),\n          chains = 4,\n          backend = \"cmdstanr\")\n\n\n\nDie Daten stammen aus dem Random Dot Experiment FS24. Das Experiment war identisch mit dem diesj√§hrig durchgef√ºhrten.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#diffusions-modell-in-der-forschung",
    "href": "ddm.html#diffusions-modell-in-der-forschung",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.6 Diffusions Modell in der Forschung",
    "text": "22.6 Diffusions Modell in der Forschung\nWeil mit dem Diffusionsmodell verschiedene Aspekte des Entscheidungsprozesses spezifisch modelliert und unterschieden werden k√∂nnen, wird dieses Modell h√§ufig in der Forschung verwendet. So k√∂nnen detaillierte Einsichten in den Entscheidungsprozess gewonnen werden. Hier ein paar Beispiele:\n\nUntersuchung der kognitiven Eigenschaften bei ADHS Review\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Abh√§ngigkeit (Tabak, Alkohol und Gl√ºcksspiel)\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Depression, und Angst.\nUntersuchung von ver√§ndertem Entscheidungsverhalten aufgrund von strukturellen oder funktionalen Ver√§nderungen des Gehirns z.B. bei Parkinson.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#footnotes",
    "href": "ddm.html#footnotes",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "Bogacz, Rafal; Eric Brown, Jeff Moehlis, Philip Holmes, Jonathan D. Cohen (2006). ‚ÄúThe Physics of Optimal Decision Making: A Formal Analysis of Models of Performance in Two-Alternative Forced-Choice Tasks‚Äù. Psychological Review. 113 (4): 700‚Äì765. https://doi.org/10.1037/0033-295X.113.4.700‚Ü©Ô∏é",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "webrconsole.html",
    "href": "webrconsole.html",
    "title": "WebR Konsole",
    "section": "",
    "text": "In der WebR-Konsole k√∂nnen Sie R-Code ausf√ºhren. Erstellte Variablen werden gespeichert, so lange das Browserfenster nicht geschlossen wird.\n\n‚ÄÉKonsole‚ÄÉTipp‚ÄÉL√∂sung\n\n\nGeben Sie hier Code ein.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPackages\nLaden Sie zuerst das {tidyverse} mit library(tidyverse).\nDatens√§tze\nEs stehen Ihnen folgende Datens√§tze zur Verf√ºgung:\n\ncars\niris\n\nEs k√∂nnen weitere Datens√§tze durch das Laden von Packages genutzt werden:\n\npenguins aus {palmerpenguins}\n\n\n# Laden vom penguins-Datensatz aus dem {palmerpenguins} Package\nlibrary(palmerpenguins)\nd &lt;- penguins\n\n\n\n\nlibrary(tidyverse)\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13‚Ä¶\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34‚Ä¶\n\nplot(cars)",
    "crumbs": [
      "Anhang",
      "WebR Konsole"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License and Authorship",
    "section": "",
    "text": "The complab course was initially conceptualized and written by Andrew Ellis (2021-2023), extended by Gerda Wyssen (2021-2025), Daniel Fitze (2024), and Enea Weber (2025). The course experiments (Complab 2024-2025) and their descriptions were created by Rebekka Borer.\nPrevious course material:\n\nComplab 2021\n\nComplab 2022\nComplab 2023\nComplab 2024\n\nWe thank all current and previous students who gave valuable feedback on the course and material!\nCite as: Wyssen, G., Ellis, A., Weber, E., Fitze, D. (2025). Neurowissenschaft im Computerlab. Skript FS 2025. https://kogpsy.github.io/neuroscicomplabFS25.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Anhang",
      "License and Authorship"
    ]
  },
  {
    "objectID": "ddm.html#random-walk-1",
    "href": "ddm.html#random-walk-1",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.3 Random walk",
    "text": "22.3 Random walk\n\n\n\n\n\n\n\n\n\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#random-walk-2",
    "href": "ddm.html#random-walk-2",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.5 Random walk",
    "text": "22.5 Random walk\n\n\n\n\n\n\n\n\n\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenz-√ºber-die-zeit",
    "href": "ddm.html#evidenz-√ºber-die-zeit",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Evidenz √ºber die Zeit",
    "text": "22.4 Evidenz √ºber die Zeit\nWenn wir dieses Prozess nun √ºber einen Zeitraum wiederholen, und die evidence Werte aufsummieren, erhalten wir die decision variable. Diese sieht aus wie ein random walk mit einem Drift in die Richtung der durchschnittlichen Evidenz.\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidence",
    "href": "ddm.html#evidence",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.3 Evidence",
    "text": "22.3 Evidence\nIst der Mittelwert f√ºr die decision variable positiv wird zunehmend Evidenz f√ºr die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin ‚ÄúSt√ºck‚Äù Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungef√§hr 0.5 betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz \\(&gt;0\\) dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenzakkumulierung-√ºber-die-zeit",
    "href": "ddm.html#evidenzakkumulierung-√ºber-die-zeit",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.3 Evidenzakkumulierung √ºber die Zeit",
    "text": "22.3 Evidenzakkumulierung √ºber die Zeit\nIst der Mittelwert f√ºr die decision variable positiv wird zunehmend Evidenz f√ºr die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin ‚ÄúSt√ºck‚Äù Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4442915\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.7051354\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungef√§hr 0.71 betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz \\(&gt;0\\) dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.\nWenn dieser Prozess nun √ºber mehrere Zeitschritte hinweg wiederholt wird und die evidence Werte aufsummiert werden, ergibt sich die decision variable. Diese gleicht einem Random walk, hat aber einen Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk mit und ohne DriftCode\n\n\n\n\n\n\nset.seed(546)\n\nt = 100\n\nd3 &lt;- tibble(\n    nb = 1:t,\n    random_walk_neg = cumsum(c(0, rnorm(t-1, -0.3, 1))),\n    random_walk_neutral = random_walk_1,\n    random_walk_pos = cumsum(c(0, rnorm(t-1, 0.3, 1)))\n    ) |&gt;\n    pivot_longer(cols = c(random_walk_neg, random_walk_neutral, random_walk_pos),\n                 names_to = \"name\",\n                 values_to = \"value\")\n\n# aggregate dataset and plot\nd3 |&gt;\n    ggplot(aes(x = nb, y = value, color = name)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    lims(y = c(-30, 30)) +\n    labs(x = 'Time', y = 'Random walk', color = '') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    scale_color_manual(labels = c('negative drift', 'no drift', 'positive drift'), values = c(\"tomato4\", \"black\", \"skyblue\")) +\n    theme_classic()\n\n\n\n\n\n22.3.1 Evidenzakkumulierung in R modellieren\nDie Evidenzakkumulierung kann als Iterationen √ºber einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# F√ºr jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on f√ºr Interessierte: Funktion erstellen\n\n\n\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # F√ºr jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#hands-on",
    "href": "ddm.html#hands-on",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Hands-on:",
    "text": "22.4 Hands-on:\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # F√ºr jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time",
    "href": "ddm.html#non-decision-time",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.7 Non-decision time",
    "text": "22.7 Non-decision time\nWir k√∂nnen nun noch die non-decision time hinzuf√ºgen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es nat√ºrlich weniger Evindenz, um die Grenze zu erreichen, welche n√§her beim Anfangspunkt liegt.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualit√§t der Evidenz pro Zeiteinheit\nTask Schwierigkeit, F√§higkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Pr√§ferenz f√ºr eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerz√∂gerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5,\n                            driftrate = 0.8,\n                            decision_boundary = 2,\n                            ndt = 0.5,\n                            diffvar = 0.1,\n                            dt = 0.001,\n                            max_time = 6) {\n\n    assertthat::assert_that(diffvar &gt; 0)\n\n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n\n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n\n    # start acumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n\n    for (j in 2:time_steps) {\n\n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                 min(dv[j], decision_boundary),\n                                 max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                         dv = dv,\n                         steps = seq_along(dv),\n                         driftrate = driftrate,\n                         decision_boundary = decision_boundary,\n                         bias = bias,\n                         ndt = ndt)\n    return(d)\n}",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time-und-bias",
    "href": "ddm.html#non-decision-time-und-bias",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Non-decision time und Bias",
    "text": "22.4 Non-decision time und Bias\nDie Decision Variable dv repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable gr√∂sser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.\nWir k√∂nnen nun noch die non-decision time hinzuf√ºgen, und den Anfangspunkt (bias) der Evidenzakkumulierung.\nDie non-decision time beschreibt die Zeit, welche nicht der Evidenzakkumulierung dient. Vor dem Entscheidungsprozess ist das z.B. das Ausrichten des Blicks auf die Aufgabe, nach dem Entscheidungsprozes ist dies z.B. die Ausf√ºhrung des Tastendrucks.\nDer bias, also der Anfangspunkt ist ein sehr wichtiger Parameter der beeinflusst, ob schon vor dem Entscheidungsprozess zu einer gewissen Antwort tendiert wird (Antworttendenz). Wenn beispielsweise der Anfangspunkt unterhalb der Mitte liegt, braucht es weniger Evidenz um die untere Grenze zu √ºberschreiten und mehr Evidenz f√ºr die obere Grenze zu √ºberschreiten.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualit√§t der Evidenz pro Zeiteinheit\nTask Schwierigkeit, F√§higkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Pr√§ferenz f√ºr eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerz√∂gerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5, # z\n                           driftrate = 0.8, # v\n                           decision_boundary = 2, # a\n                           ndt = 0.5, # t0\n                           diffvar = 0.1, \n                           dt = 0.001, # t step duration\n                           max_time = 6) {\n    \n    assertthat::assert_that(diffvar &gt; 0)\n    \n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n    \n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n    \n    # start accumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n    \n    for (j in 2:time_steps) {\n        \n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                       min(dv[j], decision_boundary),\n                                       max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                      dv = dv,\n                      steps = seq_along(dv),\n                      driftrate = driftrate,\n                      decision_boundary = decision_boundary,\n                      bias = bias,\n                      ndt = ndt)\n    return(d)\n}\n\n\n\n\n\n\n\n\n\n\nHands-on: DDM Parameter\n\n\n\nVer√§ndern Sie im Code die Werte der Variablen\n\nmean_driftrate (positive und negative Werte)\nsd_driftrate\nbias\nboundary\ntimesteps.\n\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "Herzlich Willkommen\nHier finden Sie das Wichtigste zum Kurs FS2025.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#ilias",
    "href": "index.html#ilias",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Ilias",
    "text": "Ilias\nUnter diesen Links finden Sie die Iliasgruppen:\nILIAS-Gruppe Freitag 08.15-10.00 üëâ 468703-FS2025-0\nILIAS-Gruppe Freitag 10.15-12.00 üëâ 468703-FS2025-1",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#kursvoraussetzungen",
    "href": "index.html#kursvoraussetzungen",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Kursvoraussetzungen",
    "text": "Kursvoraussetzungen\nWir werden mit der Programmiersprache R und zu einem kleinen Teil mit Python arbeiten. Sie ben√∂tigen in der Veranstaltung deshalb einen eigenen Laptop (Tablets sind nicht geeignet!) mit ca. 20 GB freiem Speicherplatz und mit einer installierten (aktuellen) Version von R und RStudio (Link zum Download von R und RStudio).\nR Kenntnisse (gem√§ss Statistik I-IV in Psychologie) werden vorausgesetzt. Zur Auffrischung dient folgender Link (https://methodenlehre.github.io/einfuehrung-in-R/) oder f√ºr Fortgeschrittene die B√ºcher ‚ÄûAdvanced R‚Äù und ‚ÄûR for Data Scientists‚Äù von Hadley Wickham.\nZus√§tzlich dient √úbung 2 zur Auffrischung der Vorkenntnisse auf die im sp√§teren Verlauf des Kurses aufgebaut wird.\nBitte installieren Sie bis zum 2. Kurstermine folgende Software:\n\nNeue Versionen von R und RStudio\nPsychoPy\nJASP",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#leistungsnachweise",
    "href": "index.html#leistungsnachweise",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nDer Kurs entspricht 5 ETCS. Daf√ºr m√ºssen 3 Bereiche erf√ºllt werden:\n\nAnwesenheit im Kurs\nbestandene √úbungen\nbestandenes Abschlussquiz\n\nAlle Leistungsnachweise werden in den Veranstaltungen angek√ºndigt. Die Termine f√ºr die Leistungsnachweise finden Sie unter Termine der Leistungsnachweise.\n\nAnwesenheit\nDie Anwesenheit im Kurs wird vorausgesetzt, an 2 Terminen darf gefehlt werden.\nDas Online-Skript erlaubt das Nacharbeiten des wichtigsten Stoffes im Eigenstudium, wir k√∂nnen jedoch nicht f√ºr die Vollst√§ndigkeit garantieren. Hilfestellung beim Programmieren und Verstehen der Inhalte erhalten Sie w√§hrend der Kurszeiten. Aus zeitlichen Gr√ºnden k√∂nnen wir keine ausf√ºhrliche Beantwortung von Fragen zum Kursinhalt per E-Mail anbieten. Bitte stellen Sie Ihre Fragen in der Veranstaltung - auch Ihre Mitstudierenden werden davon profitieren, oft haben mehrere Personen dieselbe Frage.\n\n\n√úbungen\nEs gibt f√ºnf √úbungen.\n\nDie √úbungen werden auf der Website aufgeschaltet und in der Veranstaltung erkl√§rt.\nDie Ergebnisse der √úbungen m√ºssen in den entsprechenden Ordner auf ILIAS hochgeladen werden. Je nach Umfang der √úbung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens zwei Wochen betragen.\nAusser √úbung 2 m√ºssen alle √úbungen abgegeben und als bestanden bewertet werden. Wird eine ungen√ºgende √úbungen abgegeben erhalten Sie eine zweite Frist f√ºr die Abgabe oder einen Zusatzauftrag.\n√úbungen d√ºrfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen m√ºssen die √úbung abgeben. Damit wir sehen, welche √úbungsabgaben zusammengeh√∂ren: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_3_GW_EW.R\nAlle √úbungen m√ºssen bestanden werden. Ob die √úbung bestanden wurde, sehen Sie auf Ilias. Bei Nicht-Bestehen muss die √úbung nochmals abgeben werden oder eine Zusatzaufgabe erledigt werden.\n\nVerwenden von LLMs f√ºr √úbungen: Sie d√ºrfen LLMs gerne als Tool nutzen, um die √úbung zu bearbeiten. Es liegt in Ihrer Verantwortung, den Output von LLMs vor der Abgabe gr√ºndlich zu pr√ºfen. Halten Sie sich an Folgendes:\n\nLLMs geben Code aus. Aber sogar wenn dieser problemlos ausgef√ºhrt werden kann, muss genau √ºberpr√ºft werden, ob der Code das Richtige tut. Dieses √úberpr√ºfen kann unter Umst√§nden genau so lange dauern, wie das Lesen und Verstehen der Dokumentation.\nDas √úberpr√ºfen von Code erfordert gewisse Grundkenntnisse. Das Verwenden von LLMs ersetzt kein Lernaufwand.1\nDas direkte Verwenden von Code ohne kompetente Pr√ºfung ist in der Forschung unethisch!\nEs d√ºrfen keine sensiblen Daten eingegeben werden bzw. auch keine Datens√§tze die nicht √∂ffentlich sind.\n\n\n\nAbschlussquiz\nDas Abschlussquiz wird gegen Ende des Semesters auf Ilias freigeschaltet und dient dazu das Gelernte zu pr√ºfen und so Feedback zu geben, wie gut man die Lerninhalte erinnert. Sie haben die M√∂glichkeit das Quiz mehrmals zu wiederholen.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#datacamp",
    "href": "index.html#datacamp",
    "title": "Neurowissenschaft im Computerlab",
    "section": "DataCamp",
    "text": "DataCamp\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL auf unterschiedlichen Niveaus an; sowohl f√ºr Anf√§nger als auch f√ºr Fortgeschrittene gibt es ein breites Angebot.\nIm Rahmen dieser Lehrveranstaltung k√∂nnen alle Teilnehmenden sich unter folgendem Link mit ihrer Uni Bern E-Mail Adresse (*students.unibe.ch) registrieren und die Kurse kostenlos nutzen:\nüëâüèº Einladungslink DataCamp Registration (zuerst muss ein DataCamp Zugang erstellt werden.)\nWir werden jeweils die empfohlenen Datacamp Kurse verlinken. Sie haben mit dem Link Zugriff auf alle Datacamp-Kurse bis Ende FS25.\nüëâüèº Zur Auffrischung von R-Kenntnissen eignet sich dieser Kurs: Introduction to R\nüëâüèº Als Einf√ºhrung in Python eignet sich folgender Kurs: Introduction to Python",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "‚Ü©Ô∏é",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "href": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "Das Modell wurde von Roger Ratcliff entwickelt und hat seinen Ursprung in Modellen zu den Bewegungen von Partikeln in einer Fl√ºssigkeit, und geht auf Arbeiten von Albert Einstein und Norbert Wiener zur√ºck.\n\n\n\nDrift rate steht f√ºr die durchschnittliche Anzahl von Beweisen pro Zeiteinheit und ist ein Index f√ºr die Schwierigkeit der Aufgabe oder die F√§higkeit des Subjekts.\nBoundary separation stellt die Vorsicht dar; eine gr√∂√üere Trennung der Grenzen f√ºhrt zu weniger Fehlern (wegen geringerer Auswirkung des Diffusionsrauschens innerhalb des Trials), jedoch um den Preis einer langsameren Reaktion (speed-accuracy tradeoff).\nStarting point repr√§sentiert die a-priori Pr√§ferenz f√ºr eine der Wahlalternativen.\nNon-decision time ist ein Verz√∂gerungsparameter, der die Zeit f√ºr periphere Prozesse (Kodierung eines Reizes, Umwandlung der Repr√§sentation des Reizes in eine entscheidungsbezogene Repr√§sentation) und Ausf√ºhrung einer Reaktion misst.\n\n\n\n\n\n\n\n\nAnnahmen des DDM\n\n\n\n\n\nDas DDM geht von folgenden Annahmen aus:\n\nBinary decision making: DDM ist ein Model f√ºr bin√§re Entscheidungen. Es gibt also 2 M√∂glichkeiten zwischen denen entschieden werden muss (in unserem Beispiel: rechts und links).\nContinuous sampling: Es wird davon ausgegangen, dass die Person den Stimulus verarbeitet und √ºber die Zeit Evidenz akkumuliert (sequential sampling). Entscheidungen beruhen demnach auf einem kontinuierlichen Verarbeitung von Daten.\nSingle-stage processing: Entscheidungen basieren auf einer einstufigen Verarbeitung.\nParameter sind konstant. Das heisst z.B. die drift rate kann sich nicht √ºber Zeit ver√§ndern.\n\n\n\n\n\n\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('left', '0', 'right')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#entscheidungen-im-ddm",
    "href": "ddm.html#entscheidungen-im-ddm",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.2 Entscheidungen im DDM",
    "text": "22.2 Entscheidungen im DDM\nIm Modell wird die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt (diskrete Zeitschritte). Diese Evidenz wird in einer Entscheidungsvariable (decision variable: dv) gesammelt.\nUm nachzuvollziehen, wie sich eine Entscheidung innerhalb eines Trials entwickelt, kann dieser Prozess in R simuliert werden.\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('links', '0', 'rechts')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#drift-rate-evidenzakkumulierung-√ºber-die-zeit",
    "href": "ddm.html#drift-rate-evidenzakkumulierung-√ºber-die-zeit",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.3 Drift rate: Evidenzakkumulierung √ºber die Zeit",
    "text": "22.3 Drift rate: Evidenzakkumulierung √ºber die Zeit\nWenn stattdessen aus einer Verteilung mit \\(\\mu=0.1\\) gezogen werden w√ºrde, erg√§be dies einen positiven Trend √ºber die Zeit hinweg und es w√ºrde sich Evidenz f√ºr eine Entscheidungsrichtung ansammeln.\nDie driftrate entspricht also dem Mittelwert der Evidenz und sd deren Standardabweichung.\n\n\n\n\n\n\nHands-on: Drift rate\n\n\n\nModellieren Sie die aktuelle decision variable zu Zeitpunkt \\(t\\) als normalverteilte Zufallszahl, bei der die driftrate nicht 0 entspricht.\nVer√§ndern Sie daf√ºr die Werte der Variablen mean_driftrate (positive und negative Werte) und sd_driftrate im Code.\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nIst der Mittelwert f√ºr die decision variable positiv wird zunehmend Evidenz f√ºr die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin ‚ÄúSt√ºck‚Äù Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4442915\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.7051354\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungef√§hr 0.71 betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz \\(&gt;0\\) dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.\nWenn dieser Prozess nun √ºber mehrere Zeitschritte hinweg wiederholt wird und die evidence Werte aufsummiert werden, ergibt sich die decision variable. Diese gleicht einem Random walk, hat aber einen Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk mit und ohne DriftCode\n\n\n\n\n\n\nset.seed(546)\n\nt = 100\n\nd3 &lt;- tibble(\n    nb = 1:t,\n    random_walk_neg = cumsum(c(0, rnorm(t-1, -0.3, 1))),\n    random_walk_neutral = random_walk_1,\n    random_walk_pos = cumsum(c(0, rnorm(t-1, 0.3, 1)))\n    ) |&gt;\n    pivot_longer(cols = c(random_walk_neg, random_walk_neutral, random_walk_pos),\n                 names_to = \"name\",\n                 values_to = \"value\")\n\n# aggregate dataset and plot\nd3 |&gt;\n    ggplot(aes(x = nb, y = value, color = name)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    lims(y = c(-30, 30)) +\n    labs(x = 'Time', y = 'Random walk', color = '') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    scale_color_manual(labels = c('negative drift', 'no drift', 'positive drift'), values = c(\"tomato4\", \"black\", \"skyblue\")) +\n    theme_classic()\n\n\n\n\n\n22.3.1 Evidenzakkumulierung in R modellieren\nDie Evidenzakkumulierung kann als Iterationen √ºber einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# F√ºr jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on f√ºr Interessierte: Funktion erstellen\n\n\n\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # F√ºr jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time-bias-und-boundaries",
    "href": "ddm.html#non-decision-time-bias-und-boundaries",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Non-decision time, bias und boundaries",
    "text": "22.4 Non-decision time, bias und boundaries\nDie Decision Variable dv repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable gr√∂sser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.\nWir k√∂nnen nun noch die non-decision time und den Anfangspunkt (bias) der Evidenzakkumulierung hinzuf√ºgen.\nDie non-decision time beschreibt die Zeit, welche nicht der Evidenzakkumulierung dient. Vor dem Entscheidungsprozess ist das z.B. das Ausrichten des Blicks auf die Aufgabe, nach dem Entscheidungsprozes ist dies z.B. die Ausf√ºhrung des Tastendrucks.\nDer bias, also der Anfangspunkt ist ein sehr wichtiger Parameter der beeinflusst, ob schon vor dem Entscheidungsprozess zu einer gewissen Antwort tendiert wird (Antworttendenz). Wenn beispielsweise der Anfangspunkt unterhalb der Mitte liegt, braucht es weniger Evidenz um die untere Grenze zu √ºberschreiten und mehr Evidenz f√ºr die obere Grenze zu √ºberschreiten.\nDie boundaries beeinflussen, wie viel Evidenz ausreicht, um eine Entscheidung zu treffen. Will man sich ganz sicher sein, sind die boundaries weiter auseinander.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualit√§t der Evidenz pro Zeiteinheit\nTask Schwierigkeit, F√§higkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Pr√§ferenz f√ºr eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerz√∂gerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5, # z\n                           driftrate = 0.8, # v\n                           decision_boundary = 2, # a\n                           ndt = 0.5, # t0\n                           diffvar = 0.1, \n                           dt = 0.001, # t step duration\n                           max_time = 6) {\n    \n    assertthat::assert_that(diffvar &gt; 0)\n    \n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n    \n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n    \n    # start accumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n    \n    for (j in 2:time_steps) {\n        \n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                       min(dv[j], decision_boundary),\n                                       max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                      dv = dv,\n                      steps = seq_along(dv),\n                      driftrate = driftrate,\n                      decision_boundary = decision_boundary,\n                      bias = bias,\n                      ndt = ndt)\n    return(d)\n}\n\n\n\n\n\n\n\n\n\n\nHands-on: DDM Parameter\n\n\n\nVer√§ndern Sie im Code die Werte der Variablen\n\nmean_driftrate (positive und negative Werte)\nsd_driftrate\nbias\nboundary\ntimesteps.\n\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  }
]