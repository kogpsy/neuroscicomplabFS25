[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "Herzlich Willkommen\nHier finden Sie das Wichtigste zum Kurs FS2025.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#ilias",
    "href": "index.html#ilias",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Ilias",
    "text": "Ilias\nUnter diesen Links finden Sie die Iliasgruppen:\nILIAS-Gruppe Freitag 08.15-10.00 üëâ 468703-FS2025-0\nILIAS-Gruppe Freitag 10.15-12.00 üëâ 468703-FS2025-1",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#kursvoraussetzungen",
    "href": "index.html#kursvoraussetzungen",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Kursvoraussetzungen",
    "text": "Kursvoraussetzungen\nWir werden mit der Programmiersprache R und zu einem kleinen Teil mit Python arbeiten. Sie ben√∂tigen in der Veranstaltung deshalb einen eigenen Laptop (Tablets sind nicht geeignet!) mit ca. 20 GB freiem Speicherplatz und mit einer installierten (aktuellen) Version von R und RStudio (Link zum Download von R und RStudio).\nR Kenntnisse (gem√§ss Statistik I-IV in Psychologie) werden vorausgesetzt. Zur Auffrischung dient folgender Link (https://methodenlehre.github.io/einfuehrung-in-R/) oder f√ºr Fortgeschrittene die B√ºcher ‚ÄûAdvanced R‚Äù und ‚ÄûR for Data Scientists‚Äù von Hadley Wickham.\nZus√§tzlich dient √úbung 2 zur Auffrischung der Vorkenntnisse auf die im sp√§teren Verlauf des Kurses aufgebaut wird.\nBitte installieren Sie bis zum 2. Kurstermine folgende Software:\n\nNeue Versionen von R und RStudio\nPsychoPy\nJASP",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#leistungsnachweise",
    "href": "index.html#leistungsnachweise",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nDer Kurs entspricht 5 ETCS. Daf√ºr m√ºssen 3 Bereiche erf√ºllt werden:\n\nAnwesenheit im Kurs\nbestandene √úbungen\nbestandenes Abschlussquiz\n\nAlle Leistungsnachweise werden in den Veranstaltungen angek√ºndigt. Die Termine f√ºr die Leistungsnachweise finden Sie unter Termine der Leistungsnachweise.\n\nAnwesenheit\nDie Anwesenheit im Kurs wird vorausgesetzt, an 2 Terminen darf gefehlt werden.\nDas Online-Skript erlaubt das Nacharbeiten des wichtigsten Stoffes im Eigenstudium, wir k√∂nnen jedoch nicht f√ºr die Vollst√§ndigkeit garantieren. Hilfestellung beim Programmieren und Verstehen der Inhalte erhalten Sie w√§hrend der Kurszeiten. Aus zeitlichen Gr√ºnden k√∂nnen wir keine ausf√ºhrliche Beantwortung von Fragen zum Kursinhalt per E-Mail anbieten. Bitte stellen Sie Ihre Fragen in der Veranstaltung - auch Ihre Mitstudierenden werden davon profitieren, oft haben mehrere Personen dieselbe Frage.\n\n\n√úbungen\nEs gibt f√ºnf √úbungen.\n\nDie √úbungen werden auf der Website aufgeschaltet und in der Veranstaltung erkl√§rt.\nDie Ergebnisse der √úbungen m√ºssen in den entsprechenden Ordner auf ILIAS hochgeladen werden. Je nach Umfang der √úbung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens zwei Wochen betragen.\nAusser √úbung 2 m√ºssen alle √úbungen abgegeben und als bestanden bewertet werden. Wird eine ungen√ºgende √úbungen abgegeben erhalten Sie eine zweite Frist f√ºr die Abgabe oder einen Zusatzauftrag.\n√úbungen d√ºrfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen m√ºssen die √úbung abgeben. Damit wir sehen, welche √úbungsabgaben zusammengeh√∂ren: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_3_GW_EW.R\nAlle √úbungen m√ºssen bestanden werden. Ob die √úbung bestanden wurde, sehen Sie auf Ilias. Bei Nicht-Bestehen muss die √úbung nochmals abgeben werden oder eine Zusatzaufgabe erledigt werden.\n\nVerwenden von LLMs f√ºr √úbungen: Sie d√ºrfen LLMs gerne als Tool nutzen, um die √úbung zu bearbeiten. Es liegt in Ihrer Verantwortung, den Output von LLMs vor der Abgabe gr√ºndlich zu pr√ºfen. Halten Sie sich an Folgendes:\n\nLLMs geben Code aus. Aber sogar wenn dieser problemlos ausgef√ºhrt werden kann, muss genau √ºberpr√ºft werden, ob der Code das Richtige tut. Dieses √úberpr√ºfen kann unter Umst√§nden genau so lange dauern, wie das Lesen und Verstehen der Dokumentation.\nDas √úberpr√ºfen von Code erfordert gewisse Grundkenntnisse. Das Verwenden von LLMs ersetzt kein Lernaufwand.1\nDas direkte Verwenden von Code ohne kompetente Pr√ºfung ist in der Forschung unethisch!\nEs d√ºrfen keine sensiblen Daten eingegeben werden bzw. auch keine Datens√§tze die nicht √∂ffentlich sind.\n\n\n\nAbschlussquiz\nDas Abschlussquiz wird gegen Ende des Semesters auf Ilias freigeschaltet und dient dazu das Gelernte zu pr√ºfen und so Feedback zu geben, wie gut man die Lerninhalte erinnert. Sie haben die M√∂glichkeit das Quiz mehrmals zu wiederholen.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#datacamp",
    "href": "index.html#datacamp",
    "title": "Neurowissenschaft im Computerlab",
    "section": "DataCamp",
    "text": "DataCamp\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL auf unterschiedlichen Niveaus an; sowohl f√ºr Anf√§nger als auch f√ºr Fortgeschrittene gibt es ein breites Angebot.\nIm Rahmen dieser Lehrveranstaltung k√∂nnen alle Teilnehmenden sich unter folgendem Link mit ihrer Uni Bern E-Mail Adresse (*students.unibe.ch) registrieren und die Kurse kostenlos nutzen:\nüëâüèº Einladungslink DataCamp Registration (zuerst muss ein DataCamp Zugang erstellt werden.)\nWir werden jeweils die empfohlenen Datacamp Kurse verlinken. Sie haben mit dem Link Zugriff auf alle Datacamp-Kurse bis Ende FS25.\nüëâüèº Zur Auffrischung von R-Kenntnissen eignet sich dieser Kurs: Introduction to R\nüëâüèº Als Einf√ºhrung in Python eignet sich folgender Kurs: Introduction to Python",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "‚Ü©Ô∏é",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "forschungsprozess.html",
    "href": "forschungsprozess.html",
    "title": "1¬† Complab im Forschungsprozess",
    "section": "",
    "text": "Der Begriff Computerlab wird f√ºr unsere Veranstaltung genutzt, um sich auf die vielf√§ltige Arbeit, die Neurowissenschaftler:innen an Computern oder anderen elektronischen Ger√§ten durchf√ºhren, um neurowissenschaftliche Forschungsfragen zu beantworten. Jede Forschungsarbeit hat mehrere Phasen, welche ganz unterschiedliche Anforderungen stellen und eigenen Skills ben√∂tigen.\nIn jeder Phase des Forschungsprozesses werden verschiedenste\n\nelektronische Ger√§te (Computer, Eyetracker, EEG-Ger√§te, MRTs, etc.)\nProgramme (PsychoPy, E-Prime, etc.)\nProgrammiersprachen (R, MATLAB, Python, Java, C++, Ruby, Julia, etc.)\nspeicherbare Ergebnisse: Skripte, Datens√§tze, Stimuli, Grafiken‚Ä¶\netc.\n\nverwendet.\n\n\n\nPhasen des Forschungsprozesses\n\n\nIn diesem Kurs werden wir einige Stationen dieses Forschungsprozesses gemeinsam bearbeiten, um Einblick in das neurowissenschaftliche Arbeiten zu erhalten.\n\n\n\n\n\n\nHands-on: Complab im Forschungsprozess\n\n\n\n\nW√§hlen Sie in 2-4er Gruppen eines der untenstehenden Paper (Open Access) aus:\n\n\nQuon et al. (2021): Quon et al.¬†(2021): Musical components important for the Mozart K448 effect in epilepsy\nRichter et al. (2021): Richter et al.¬†(2021): Listening to speech with a guinea pig-to-human brain-to-brain interface\nZhang et al. (2021): Zhang et al.¬†(2021): Longitudinal effects of meditation on brain resting-state functional connectivity\n\n\nSchreiben Sie zuerst in einem Satz oben auf Ihr Blatt auf, was die Fragestellung des Papers ist.\nGehen Sie das Paper durch und schreiben Sie heraus, wo √ºberall im ‚ÄúComputerlab‚Äù gearbeitet wurde, bei dieser Forschungsarbeit. (Sie k√∂nnen auch Vermutungen anstellen.)\n\nz.B. Datenanalyse -&gt; R/RStudio\n[15 Minuten]\n\n\n\n\n\n\nQuon, Robert J., Michael A. Casey, Edward J. Camp, Stephen Meisenhelter, Sarah A. Steimel, Yinchen Song, Markus E. Testorf, et al. 2021. ‚ÄúMusical Components Important for the Mozart K448 Effect in Epilepsy.‚Äù Scientific Reports 11 (1): 16490. https://doi.org/10.1038/s41598-021-95922-7.\n\n\nRichter, Claus-Peter, Petrina La Faire, Xiaodong Tan, Pamela Fiebig, David M. Landsberger, and Alan G. Micco. 2021. ‚ÄúListening to Speech with a Guinea Pig-to-Human Brain-to-Brain Interface.‚Äù Scientific Reports 11 (1): 12231. https://doi.org/10.1038/s41598-021-90823-1.\n\n\nZhang, Zongpai, Wen-Ming Luh, Wenna Duan, Grace D. Zhou, George Weinschenk, Adam K. Anderson, and Weiying Dai. 2021. ‚ÄúLongitudinal Effects of Meditation on Brain Resting-State Functional Connectivity.‚Äù Scientific Reports 11 (1): 11361. https://doi.org/10.1038/s41598-021-90729-y.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Complab im Forschungsprozess</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html",
    "href": "voraussetzungen.html",
    "title": "2¬† Voraussetzungen der Forschung",
    "section": "",
    "text": "3 Marr‚Äôs levels of explanation\nDavid Marr hat drei Ebenen vorgeschlagen, um zu kl√§ren, wie komplexe Systeme, insbesondere kognitive Systeme wie das Gehirn, Informationen verarbeiten. Die Idee ist, dass jedes informationsverarbeitende System (biologisch oder k√ºnstlich) auf diesen drei verschiedenen Ebenen analysiert werden kann. Zusammen zeigen sie, was das System tut, wie es das tut und wie es physikalisch realisiert ist.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html#levels-of-analyses",
    "href": "voraussetzungen.html#levels-of-analyses",
    "title": "2¬† Voraussetzungen der Forschung",
    "section": "3.1 3 Levels of analyses",
    "text": "3.1 3 Levels of analyses\n\n3.1.1 Computational level (what and why)\n\nWas macht das System?\nEs definiert das Ziel oder den Zweck des Prozesses. Diese Ebene erkl√§rt, welches Problem das System l√∂st und warum es wichtig ist.\nBeispiel aus dem Sehen: Das System muss die 3D-Welt aus dem 2D-Input der Retina rekonstruieren. Warum? Weil das Verst√§ndnis der r√§umlichen Umgebung f√ºr das √úberleben wichtig ist.\nWas es zeigt: Das ‚Äûgro√üe Ganze‚Äú - die Funktion, die das System erf√ºllt.\n\n\n\n3.1.2 Algorithmic level (how)\n\nWie erreicht das System das Ziel?\nEs geht um die spezifischen Darstellungen und Verfahren, die zur Erreichung des Ziels eingesetzt werden. Betrachten Sie dies als die ‚ÄûAnweisungen‚Äú oder ‚ÄûSoftware‚Äú des Systems.\nBeispiel aus dem Sehen: Das Gehirn erkennt Kanten, kombiniert Merkmale und identifiziert Objekte mithilfe von Algorithmen wie Merkmalsextraktion und Mustervergleich.\nWas es zeigt: Den Prozess - die schrittweise Umwandlung vom Input zum Output.\n\n\n\n3.1.3 Implementational level\n\nWie wird der Prozess physisch umgesetzt?\nDiese Ebene beschreibt die Hardware oder biologischen Strukturen, die die Berechnungen ausf√ºhren. Beim Menschen sind dies Neuronen, Gehirnbereiche und neuronale Schaltkreise.\nBeispiel aus dem Sehen: Die Randerkennung erfolgt in der Retina und in fr√ºhen visuellen Bereichen wie dem prim√§ren visuellen Kortex (V1). Bestimmte Neuronen feuern bei bestimmten Ausrichtungen des Lichts.\nWas es zeigt: Die materielle Basis - die Mechanismen, die es m√∂glich machen.\n\nKognitive Neurowissenschaft kann auf allen drei Ebenen t√§tig sein. Beispiel aus der Gesichtserkennung:\n\nDas Gehirn muss Gesichter schnell und genau erkennen, weil dies f√ºr die soziale Interaktion evolution√§r wichtig ist.\nDie Gesichtserkennung kann die Extraktion von Merkmalen (Augen, Nase, Mund) und eine ganzheitliche Verarbeitung umfassen.\nDas fusiforme Gesichtsareal (FFA) spielt eine Schl√ºsselrolle bei der Wahrnehmung von Gesichtern.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html#grundlegendes-postulat",
    "href": "voraussetzungen.html#grundlegendes-postulat",
    "title": "2¬† Voraussetzungen der Forschung",
    "section": "3.2 Grundlegendes Postulat:",
    "text": "3.2 Grundlegendes Postulat:\nMentale Prozesse ergeben sich aus der Gehirnaktivit√§t.\nGanz wichtig ist: Korrelation ‚â† Kausalit√§t. Neuroimaging-Methoden zeigen nur Korrelationen und keine Kausalit√§t.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "experiments.html",
    "href": "experiments.html",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "",
    "text": "3.1 Forschungsbereiche der Neurowissenschaften\nIn der Neurowissenschaft wird mit naturwissenschaftlichem Schwerpunkt der Aufbau und die Funktionen des Nervensystems untersucht. Neurowissenschaften sind ein sehr weites Forschungsbereich in dem unterschiedlichste und zahlreiche Themen bearbeitet werden. Die Forschungsbereiche reichen von Affektiven Neurowissenschaften, die den Zusammenhang von Gehirn und Emotionen untersuchen, √ºber Neurochemistry, die sich u.a. mit Neurotransmittern und psychopharmakologischen Themen befasst, bis hin zu Neuroengineering, welches neuronale Systeme zu verstehen, ersetzen, reparieren oder verbessern versucht.1\nSo vielf√§ltig, wie die Forschungsbereiche sind auch die experimentellen Ans√§tze und Methoden. Neurowissenschaftliche Forschung wird oft an Organismen und Tieren durchgef√ºhrt (z.B. Einzelzellableitungen in Affen). In diesem Kurs fokussieren wir uns auf neurowissenschaftliche Forschung am Menschen im Bereich der kognitiven Neurowissenschaft und Neuropsychologie. Das bedeutet, wir besprechen die Datenerhebung und -verarbeitung in verhaltenswissenschaftlichen Experimenten (teilweise auch im Zusammenhang mit bildgebenden Verfahren), welche Gehirnprozesse von Menschen untersuchen.\nKognitive Neurowissenschaften sind eng verkn√ºpft mit Forschungsbereichen, wie beispielsweise der Psychologie, der Linguistik, k√ºnstlicher Intelligenz, Philosophie und Anthropologie:",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#forschungsbereiche-der-neurowissenschaften",
    "href": "experiments.html#forschungsbereiche-der-neurowissenschaften",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "",
    "text": "Das Nebenfach Neurowissenschaften an der Universit√§t Bern fokussiert auf Aspekte der Neurowissenschaft, die f√ºr das Gebiet der Psychologie relevant sind, wie z. B. die neuronalen Grundlagen von Kognition, Emotion oder Sozialverhalten.\n\n\n\n\n\nGrafik von O. Guest (2024) modifiziert nach dem Paper von Van Rooij et al. (2023)\n\n\n\nWer sich f√ºr die Bedeutung von AI im Zusammenhang mit den Neurowissenschaften interessiert findet im Paper von Van Rooij et al. (2023) eine kritische Auseinandersetzung mit Chancen und Herausforderungen dieser Verkn√ºpfung.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#besondere-herausforderungen-von-experimenten-in-den-verhaltenswissenschaften-kognitiven-neurowissenschaften",
    "href": "experiments.html#besondere-herausforderungen-von-experimenten-in-den-verhaltenswissenschaften-kognitiven-neurowissenschaften",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "3.2 Besondere Herausforderungen von Experimenten in den Verhaltenswissenschaften / kognitiven Neurowissenschaften",
    "text": "3.2 Besondere Herausforderungen von Experimenten in den Verhaltenswissenschaften / kognitiven Neurowissenschaften\nDas Erstellen und Durchf√ºhren neurowissenschaftlicher Experimente bringt viele Herausforderungen mit sich.\n\n3.2.1 Passung: Experimentalparadigmen passend zur Fragestellung\nNeurowissenschaftliche Experimente m√ºssen exakt auf die Fragestellung zugeschnitten werden um aussagekr√§ftige Daten zu liefern. Oft muss ein neues Paradigma erstellt werden, d.h. Forschende k√∂nnen kein schon bestehendes Experiment nutzen, sondern untersuchen einen Aspekt eines neuronalen Prozesses mit einer neuen Methode, einer neuen Fragestellung oder einem neuen Ansatz. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So k√∂nnen beispielsweise Instruktionen oder verwendete Stimuli, deren Gr√∂sse und Anzeigedauer pr√§zise definiert werden. Dies erfordert breite Kenntnisse im Programmieren, der zu verwendenden Technik, wie auch der Gehirnprozesse.\n\n\n3.2.2 Pr√§zision: Hohe r√§umliche und zeitliche Aufl√∂sung\nEine grosse Schwierigkeit neurowissenschaftlicher Experimente ist oft, dass eine pr√§zise Kontrolle von r√§umlichen und zeitliche Eigenschaften der Experimente n√∂tig ist um sinnvolle Daten zu erhalten. Visuelle Stimuli m√ºssen z.B. sehr genau und immer gleich pr√§sentiert werden k√∂nnen. Die zeitliche Aufl√∂sung ist gerade bei EEG Experimenten von enormer Bedeutung, da EEG eine sehr hohe zeitliche Aufl√∂sung hat. R√§umliche Aufl√∂sung kann bedeuten, dass sehr pr√§zise visuelle Darbietung m√∂glich sein muss, sowie dass die Versuchsperson sich im Setup nicht bewegen darf, weil dies die Distanzen verschiebt (z.B. im MRT, oder der Abstand zum Bildschirm beim Eyetracking).\n\n\n3.2.3 Synchronisation: Mehrere Datenspuren\nNeurowissenschaftliche Experimente beinhalten oft die Datenerhebung auf mehreren Ebenen, z.B. wird gleichzeitig Hirnaktivit√§t und das Dr√ºcken von Antwortbuttons aufgenommen. Das bedeutet, dass Bildschirm, MRT/EEG/Eyetracking/etc., sowie die Antwort zeitlich koregistriert/synchronisiert werden m√ºssen, um die Daten im Nachhinein auswerten zu k√∂nnen. Technisch ist das oft mit grossem Aufwand verbunden und ben√∂tigt einiges an Pilotierung.\n\n\n3.2.4 Komplexit√§t: Zu untersuchender Prozess und St√∂rprozesse\nOft soll ein ganz spezifischer Prozess untersucht werden, aber das ist eine sehr komplexe Aufgabe, weil im menschlichen Gehirn gleichzeitig sehr viele verschiedene Prozesse ablaufen, kein Hirnareal hat nur eine einzige Aufgabe und aus ethischen Gr√ºnden ist das ‚ÄúAusschalten‚Äù von St√∂rfaktoren nicht immer m√∂glich. Was kann man tun?\nEin Weg den Prozess sichtbar zu machen ist es zum Beispiel einen Kontrast zu rechnen, dies wird beispielsweise bei EEG und fMRI Experimenten, aber auch bei Reaktionszeitexperimenten sehr oft gemacht. Hierf√ºr erhebt man Daten in einer Test-Bedingung in der der Prozess abgerufen wird und eine Kontroll-Bedingung, welche als ‚ÄúBaseline‚Äù dient. Die Baseline enth√§lt alle ‚Äúnicht interessierenden‚Äù Prozesse, die in der Test-Bedingung vorhanden sind. Durch das Vergleichen der Test- und Kontrollbedingung erh√§lt man einen Kontrast: Also das was den interessierenden Prozess ausmacht!\nSie m√ºssen sich beim Erstellen eines Experiments also nicht nur Gedanken dazu machen, was Sie interessiert - sondern genau so auch dar√ºber was Sie nicht interessiert. In der Theorie t√∂nt das einfach, in der Praxis ist das oft recht kniffelig.\n\n\n3.2.5 Ressourcenintensive Datenerhebung: Teuer und anspruchsvoll\nBildgebende Verfahren, ben√∂tigen zum Teil extrem teure Ger√§te, wie z.B. fMRI, und bedeuten oft hohen Aufwand, z.B. das Kleben der Elektroden beim EEG. Bei der Untersuchung von ganz bestimmten Patientengruppen hat man zudem oft nicht sehr viele Personen zur Verf√ºgung die den Einschlusskriterien entsprechen. Oft m√ºssen Personen auch aus dem Experiment ausgeschlossen werden, weil sie z.B. Auff√§lligkeiten im MRI zeigen, die nichts mit dem zu untersuchenden Prozess zu tun hat oder sie brechen w√§hrend der Untersuchung ab. Gerade bei der Untersuchung klinischer Aspekte stellen sich oft Schwierigkeiten, wie beispielsweise fehlende Motivation oder Compliance von Patient:innen. Daher k√∂nnen oft keine sehr grossen Stichproben erhoben werden, was im Gegenzug besonders pr√§zise Experimente erfordert.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#wichtige-elemente-von-experimenten",
    "href": "experiments.html#wichtige-elemente-von-experimenten",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "3.3 Wichtige Elemente von Experimenten",
    "text": "3.3 Wichtige Elemente von Experimenten\nBeim Programmieren von Experimenten lohnt es sich, sich zuerst dar√ºber im klaren zu sein, welche Bausteine das geplante Experiment hat. Im Folgenden werden einige typische Elemente eines Verhaltensexperiments beschrieben. Oft kommen hier nat√ºrlich noch Stimulations- oder Aufnahmemethoden hinzu.\n\n3.3.1 Begr√ºssung und Einverst√§ndniserkl√§rung\nHier wird die Versuchsperson begr√ºsst, wird √ºber das Experiment aufgekl√§rt und gibt (wenn nicht vorher auf Papier schon geschehen) ihre Einverst√§ndnis zur Teilnahme am Experiment. Dies wird je nach Ethikkommission und Ethikantrag unterschiedlich gehandhabt. Wichtige Informationen sind hierbei, dass die Versuchsperson weiss worauf sie sich einl√§sst (Ist zum Beispiel Hirnstimulation/fMRI/etc. geplant? Wie lange dauert das Experiment ungef√§hr? Was soll sie tun, wenn sie abbrechen m√∂chte?). Die Schwierigkeit ist oft, gen√ºgend Information zu geben aber die Hypothese nicht zu verraten.\n\n\n3.3.2 Instruktion\nDie Instruktion wird oft schriftlich gegeben, um diese zwischen den Versuchspersonen konstant zu halten. Es ist teilweise herausfordernd, einen Task so genau zu erkl√§ren, dass er verst√§ndlich ist, aber die Erkl√§rung auch kurz genug zu halten, dass die Instruktion auch gelesen wird. Oft werden √úbungstrials verwendet um die Instruktion zu verdeutlichen.\n\n\n3.3.3 Stimuli\nUnter Stimuli werden die gezeigten Elemente verstanden, die den Task ausmachen. Es k√∂nnen T√∂ne, Bilder, W√∂rter, etc. als Stimuli verwendet werden.\n\n\n\n\n\n\nHands-on: Stimuli\n\n\n\nWelche Stimuli aus neurowissenschaftlichen Experimenten kennen Sie?\nTauschen Sie sich mit Ihren Mitstudierenden aus und schreiben/zeichnen Sie ein paar Beispiele vorne an die Tafel.\n[~5 Minuten]\n\n\n\n\n3.3.4 Trial\nEin Trial beschreibt ein sich wiederholender Vorgang in dem der Stimulus gezeigt wird und z.B. von der Versuchsperson eine Antwort erwartet wird. Ein Trial wird oft sehr viele Male wiederholt. Die Stimuli k√∂nnen zwischen den Trials variieren oder gleich bleiben. Das Timing der Trials kann konstant sein (ein Stimulus wird bspw. immer gleich lang gezeigt) oder variiert werden (unterschiedliche Anzeigedauer).\nZwischen den Trials wird ein Inter-Trial-Interval (ITI) festgelegt. Dies wird z.B. bei fMRI Experimenten dann variiert, damit (je nach Repetition Time/TR) nicht immer in derselben Schicht aufgenommen wird bei Stimuluspr√§sentation.\nW√§hrend einem Trial wird die Antwort / Response der Versuchsperson aufgenommen. Bei der Aufnahme von Reaktiosnzeiten muss festgelegt werden, wann der Trial oder die Stimuluspr√§sentation beginnt und mit welcher Handlung sie endet. Es kann bestimmt werden, welche Antworten zul√§ssig sind (bspw. nur bestimmte Tasten) und was passiert wenn eine richtige oder falsche Antwort gegeben wird: Gibt es z.B. ein Feedback bei falschen Antworten?\n\n\n3.3.5 Run / Block\nEin Run/ein Block bezeichnet eine Einheit mit mehreren Trials. Oft werden Bedingungen z.B. zwischen den Runs randomisiert. Zwischen den Runs sind Pausen m√∂glich, damit sich die Versuchsperson erholen kann. Oft wird vor dem Experimentstart ein ‚Äú√úbungsblock‚Äù durchgef√ºhrt, um sich sicher zu sein, dass die Versuchspersonen die Aufgabe und Instruktion verstanden haben.\n\n\n3.3.6 Debriefing und Verabschiedung\nIm Debriefing wird der Versuchsperson erkl√§rt, um was es im Experiment gegangen ist, welche Hypothesen untersucht wurden und eine eventuelle Coverstory aufgedeckt. Oft werden Personen vor dem Debriefing nach der getesteten Hypothese gefragt, um zu schauen, ob sie diese erraten hatten. Das gibt Aufschluss dar√ºber wie sehr das Experiment dadurch verzerrt sein k√∂nnte, dass die Versuchspersonen Bescheid wissen. Wichtig ist es auch den Versuchspersonen zum Schluss zu danken.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#vorgehen-experiment-programmieren",
    "href": "experiments.html#vorgehen-experiment-programmieren",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "3.4 Vorgehen Experiment programmieren",
    "text": "3.4 Vorgehen Experiment programmieren\nWichtige Schritte beim Programmieren von Experimenten sind folgende (nicht unbedingt in dieser Reihenfolge, das kommt auf das Experiment an):\n\nTask ausw√§hlen\nStimuli ausw√§hlen und generieren\nTrial erstellen (Fixationskreuz? Stimulus? Antwortm√∂glichkeiten? Feedback? Masking?)\nTiming festlegen: Dauer Stimuluspr√§sentation? ITIs (Inter-Trial-Intervals)? Antwortfenster?\nDesign: Anzahl Bedingungen und Trials bestimmen (Power bedenken), within oder between Design?\nAblauf des Experiments festlegen: Gesamtdauer? Pausen n√∂tig?\nInstruktion: klare Anweisungen, Coverstory\nEinbindung von allen technischen Ger√§ten (z.B. EEG Recorder, MRT, Brainstimulation-Devices, Eyetracking) und Synchronisation\n\n\n3.4.1 Flowcharts\nFlowcharts, auf Deutsch Flussdiagramme, eignen sich um Prozesse zu beschreiben. Beim Programmieren kann man damit gut darstellen, was ein Programm machen soll.\n\nBei der Planung und dem Erstellen eines Experiments ist es ebenfalls hilfreich eine Flowchart zu erstellen. In einer Experiment-Flowchart sind die Elemente eines Experimentes in Boxen eingezeichnet und mit Pfeilen verbunden um sie zeitlich einzuordnen. Timing-Informationen k√∂nnen unter oder neben den Boxen festgehalten werden. Die Anzahl Repetitionen wird oft neben den Pfeilen eingef√ºgt. Hilfreich ist auch zu kennzeichnen, wo welche Daten erhoben werden (button presses, EEG, etc.).\n\nWir werden in diesem Kurs immer wieder darauf eingehen, wie man ein Experiment m√∂glichst gut planen kann um aussagekr√§ftige Daten zu erhalten. Hier gibt es viele M√∂glichkeiten wie Pilotierung, Datensimulation und die ad√§quate Wahl der statistischen Verfahren in Bezug auf die Fragestellung.\n\nEine Flowchart eignet sich ebenfalls sehr gut, um in einem Paper/einer Arbeit darzustellen, wie der Ablauf des Experiments war.\n\n\n\n\n\n\nHands-on: Flowcharts\n\n\n\nSuchen Sie zusammen zu einem Thema Ihrer Wahl eine Flowchart.\n\nIdentifizieren Sie alle Elemente des Experiments, die Sie finden.\nGibt es Informationen zu den Stimuli?\nGibt es Informationen zum Timing?\nGibt es Informationen zur Datenerhebung?\nFehlt etwas? Wie w√ºrden Sie dies erg√§nzen?\n\n[~10 Minuten]\n\n\n\n\n\n\nShepherd, Gordon M. 1988. Neurobiology, 2nd Ed. Neurobiology, 2nd Ed. New York, NY, US: Oxford University Press.\n\n\nVan Rooij, Iris, Olivia Guest, Federico G Adolfi, Ronald De Haan, Antonina Kolokolova, and Patricia Rich. 2023. ‚ÄúReclaiming AI as a Theoretical Tool for Cognitive Science.‚Äù Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/4cbuv.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#footnotes",
    "href": "experiments.html#footnotes",
    "title": "3¬† Neurowissenschaftliche Experimente",
    "section": "",
    "text": "Forschungsbereiche der Neurowissenschaften: ‚Ü©Ô∏é",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html",
    "href": "psychopy_experiments.html",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "",
    "text": "4.1 Umgebung",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#umgebung",
    "href": "psychopy_experiments.html#umgebung",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "",
    "text": "4.1.1 Experiment-File erstellen und abspeichern\n\n√ñffnen Sie PsychoPy und speichern Sie in einem daf√ºr erstellten Ordner (z.B. psychopy_experiment) das Experiment-File ab (z.B. unter experiment_stroop-task).\n\n\n\n4.1.2 Builder (GUI) und Coder?\nExperimente k√∂nnen in PsychoPy mit dem Builder (in einem GUI) erstellt werden, der Python Code wird so automatisch f√ºr Sie generiert. Sie k√∂nnen sich diesen Code auch anschauen und ver√§ndern. Leider k√∂nnen Sie sobald Sie den Code ver√§ndert haben, diese √Ñnderungen nicht zur√ºck in den Builder √ºbertragen. Im Builder-Modus k√∂nnen Sie aber Codest√ºcke einf√ºgen um einzelne Teile des Experiments in Python (oder anderen Programmiersprachen) zu programmieren und dennoch im Builder weiterarbeiten zu k√∂nnen.\n\nFalls Sie planen ein Online-Experiment durchzuf√ºhren, eignet sich der Builder besonders, da die Experimente direkt online durchgef√ºhrt werden k√∂nnen.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#experiment-erstellen",
    "href": "psychopy_experiments.html#experiment-erstellen",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "4.2 Experiment erstellen",
    "text": "4.2 Experiment erstellen\n\n4.2.1 Stimuli\nIn PsychoPy finden Sie schon vorprogrammierte Stimulus Elemente, wie Gratings oder Rating Scales und k√∂nnen Texte, geometrische Figuren, Bilder und Filme einf√ºgen. Auch komplexere Stimuluselemente wie Random Dots k√∂nnen sehr einfach konfiguriert werden ohne dass sie von Grund auf neu programmiert werden m√ºssen.\n\nErstellen Sie einen Stimulus. Beachten Sie folgende Aspekte:\n\nFarbe\nGr√∂sse\nweitere Eigenschaften, wie Bedingung/Kongruenz?\nTiming (Stimulusdauer, Stimulusende)\n\nNotieren Sie, welche Eigenschaften des Stimulus sich √ºber die Trials hinweg ver√§ndern sollte. Dies k√∂nnen auch mehrere Eigenschaften sein. Diese Liste ben√∂tigen Sie sp√§ter.\n\n\n\n4.2.2 Trial\n\nErg√§nzen Sie alle Elemente, die f√ºr einen vollst√§ndigen Trial notwendig sind:\n\nAntwort der Versuchsperson / Response (siehe auch 4.2.4)\nInter-Trial-Intervall (ITI): kann vor oder nach dem Stimulus eingef√ºgt werden. (Die Zeit des ITI wird oft variiert. Dies m√ºsste also auch auf die Liste oben)\nFixationskreuz?\nMask?\nFeedback?\n\n\n\n\n4.2.3 Trialschleife\nSie m√ºssen nicht alle Trials (oder in PsychoPy: Routines) des Experiments einzeln programmieren, sondern k√∂nnen diese wiederholen, in dem Sie eine Trial-Schleife (loop) um den Trial herum erstellen.\n\nErstellen Sie einen loopindem Sie im Feld Flow auf Insert loop klicken.\n\nMit loopType k√∂nnen Sie steuern, die Bedingungen randomisiert/gemischt oder sequentiell/der Reihe nach angezeigt werden sollen.\nMit nReps k√∂nnen Sie angeben, wie oft jeder Stimulus wiederholt werden soll. Haben Sie also einen Stimulus mit zwei zu varierenden Eigenschaften , welche je 3 Stufen haben (also 9 Zeilen im conditions-File und nReps= 2), ergibt das 18 Trials.\n\n\nMittels diesen Schleifen k√∂nnen die Bedingungen implementiert werden z.B. dass sich der Stimulus bei jedem Trial ver√§ndert. Dies kann mit einer conditions-Datei spezifiziert werden, idealerweise im .csv oder .xlsx-Format.\n\nDie Endung .csv bedeutet, dass die Daten als comma separated values abgespeichert werden, also durch ein Komma getrennt. Dieses Dateiformat eignet sich besser als .xlsx, weil es mit vielen Programmen kompatibel und gut einlesbar ist.\n\nBeispielsweise wollen wir drei verschiedene Worte anzeigen (dog, cat und rabbit) und dieses Wort unterschiedlich lange anzeigen (Dauer: 1, 10 und 100 Frames). Die Versuchspersonen sollen dann den Anfangsbuchstaben des Wortes dr√ºcken, also d f√ºr dog, c f√ºr cat und r f√ºr rabbit.\n\nUm die Bedingungen (in unserem Fall: die sich ver√§ndernden Stimuluseigenschaften) zu definieren, erstellen wir eine .csvoder .xlsx-Datei (z.B. in Excel/Notepad/etc.) mit dem Namen conditions und speichern dieses im selben Ordner wie das Experiment.\n\nF√ºgen Sie f√ºr jedes sich ver√§ndernde Element einen Variablennamen und die entsprechenden Werte ein (dies sind die Eigenschaften, die Sie sich bei Punkt 4.2.1 notiert haben). Die Variablennamen schreiben wir immer in die oberste Zeile der Datei.\nWenn wir z.B. einen Text anzeigen m√∂chten, schreiben wir in die erste Zeile word und duration.\nIn die Spalte unter die Variablennamen schreiben wir die Werte.\nAls Beispiel k√∂nnten die Worte die wir anzeigen lassen wollen cat, dog und rabbit lauten. Dann stehen in der Spalte word, diese 3 W√∂rter unter dem Variablennamen. Unter dem Variablennamen duration geben wir die Anzahl Frames ein, also 1, 10 und 100. Wir wollen jedes Wort mit jeder Dauer kombinieren. Das ergibt 9 Zeilen.\nF√ºgen Sie in jeder Zeile unter dem Variablennamen corrAns die jeweils korrekte Antwort ein.\nF√ºgen Sie, falls vorhanden, in jeder Zeile weitere wichtige Information zum Stimulus ein.\nIm Beispiel m√∂chten Sie z.B. sp√§ter fleischfressende mit pflanzenfressenden Tieren vergleichen, deshalb eine Spalte meat. Dies ver√§ndert im Experiment nichts, dient aber am Schluss zur Auswertung, weil diese Variable auch immer in den Datensatz geschrieben wird.\n\n\nF√ºgen Sie nun im Loop-Fenster die conditions-Datei ein.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nJede Zeile in der conditions-Datei unterhalb des Variablennamens entspricht einer Bedingung (condition).\nSetzen Sie nReps auf 1 w√§hrend Sie das Experiment erstellen, so sparen Sie Zeit.\n\n\nIm PsychoPy k√∂nnen Sie Variablen mit einem vorangestellten $einf√ºgen.\n\n√ñffnen Sie nun wieder das Stimulusfenster und passen Sie dort die Stimuluseigenschaften an. Anstatt von hard-coded values (also einmalig, fix festgelegten Werten) geben wir nun einen Variablennamen ein. Der Stimulus darf nicht auf constant gesetzt sein, sonst kann er sich nicht Trial f√ºr Trial ver√§ndern, setzen Sie ihn deshalb unbedingt auf set every repeat.\nIn unserem Beispiel f√ºgen wir bei text die Laufvariable (ver√§ndernde Eigenschaft) ein: $word. Die Anzeigedauer des Textes soll $duration in Frames sein.\n\n\n\nLassen Sie das Experiment laufen und kontrollieren Sie, ob alles funktioniert hat.\n\n\n\n\n\n\n\nTipp\n\n\n\nMit dieser Methode k√∂nnen Sie auch Instruktionen, ITIs, etc. variieren lassen.\n\n\n\n\n4.2.4 Antworten aufnehmen\nIn PsychoPy muss definiert werden, wie die Antwort der Versuchsperson aufgenommen wird. Dies kann mit der Maus, der Tastatur oder anderen Devices umgesetzt werden. Die M√∂glichkeiten sehen Sie unter Responses.\n\nF√ºgen Sie eine Antwortkomponente hinzu und benennen Sie diese sinnvoll.\nIn unserem Beispiel m√∂chten wir, dass die Versuchsperson mittels Keyboard antwortet.\n\nMit Force end of Routine k√∂nnen Sie einstellen, ob eine Antwort den Trial beendet und mit dem n√§chsten fortf√§hrt.\nDer Namen der Antwortkomponente wird sp√§ter im Datensatz als Variable zu finden sein.\nWerden in einer Antwortkomponente namens key_resp mittels Tastendruck Antwort und Response Time aufgenommen, heissen die Variablen dann key_resp.keys(gedr√ºckte Taste) und key_resp.rt (Antwortdauer).\nEntscheiden Sie, ob PsychoPy √ºberpr√ºfen soll, ob die richtige Antwort gegeben wurde.\nWenn Sie dies m√∂chten, gleicht PsychoPy in unserem Beispiel die gegebene Antwort (key_resp.keys) mit der daf√ºr eingegebenen Variable (hier corrAns) ab. Stimmen diese √ºberein, f√ºgt es in die Variable key_resp.corr 1 ein, wenn nicht 0).\nMit first key definieren Sie, dass der erste Tastendruck z√§hlt.\n\n\n\n\n\n\n4.2.5 Weitere Elemente\nIn PsychoPy GUI wird Ihnen im Fenster Floweine Art Flowchart angezeigt. Hier sehen Sie, welche Elemente Ihr aktuelles Experiment enth√§lt.\n\nF√ºgen Sie nun alle weiteren Elemente, die Sie zu Beginn auf Ihrer Flowchart eingezeichnet hatten, z.B.\n\nBegr√ºssung\nEinverst√§ndnis\nInstruktion\nDebriefing, Verabschiedung\n\nLassen Sie das Experiment laufen und kontrollieren Sie, ob alles funktioniert hat.\n\n\n\n\n\n\n\nTipp\n\n\n\nBeim Programmieren lohnt es sich oft, die kleinen Schritte zwischenzutesten, weil es dann einfacher ist herauszufinden, wo genau der Fehler passiert ist.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#datenspeicherung",
    "href": "psychopy_experiments.html#datenspeicherung",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "4.3 Datenspeicherung",
    "text": "4.3 Datenspeicherung\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy die Daten automatisch in einer trial-by-trial .csv-Datei. Das bedeutet, dass jeder Trial 1 Zeile generiert. Die .csv-Datei erh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es m√∂glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die .csv-Dateien werden in einem Ordner mit dem Name data abgelegt.\nIn den Fenstern der Elemente kann jeweils angegeben werden, was alles gespeichert werden soll.\n\n\n\n\n\n\nTipp\n\n\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuh√§ngen. Dies verhindert, dass Daten √ºberschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird.\n\n\nDas oben verwendete Beispielsexperiment ergibt folgenden Datensatz:\n\nSie sehen die Infos aus der conditions-Datei (gelb), die Z√§hlerinformationen der Loops (hellgrau), die Timinginformationen (dunkelgrau), die Antwortinformationen (blau) und die Experimentinformationen (gr√ºn).",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#test-pilotierung",
    "href": "psychopy_experiments.html#test-pilotierung",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "4.4 Test / Pilotierung",
    "text": "4.4 Test / Pilotierung\n\nF√ºhren Sie das Experiment aus und schauen Sie sich den Datensatz an: Sind alle wichtigen Informationen auf jeder Zeile vorhanden?\n\nVersuchspersonen-ID\nBedingung\nStimuluseigenschaften (z.B. word)\nAntwort der Versuchsperson\nAntwortdauer der Versuchsperson\nAntwort korrekt?\n\nK√∂nnen die Daten √ºberschrieben werden?\nLassen Sie jemanden anderes Ihr Experiment durchf√ºhren, und geben Sie einander Feedback.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#verwenden-von-codekomponenten-im-builder",
    "href": "psychopy_experiments.html#verwenden-von-codekomponenten-im-builder",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "4.5 Verwenden von Codekomponenten im Builder",
    "text": "4.5 Verwenden von Codekomponenten im Builder\nAuch wenn man das Experiment im Builder erstellt erfordern einige Experimentelemente das Verwenden von Codekomponenten. In diesem Abschnitt werden zwei h√§ufige Anwendungsbeispiele besprochen: Die variable Blockdauer (z.B. f√ºr Fixationskreuze oder ITIs) und das Geben von Feedback (z.B. in einem √úbungsdurchgang).\n\n\n\n\n\n\nIf-else Statements in Python\n\n\n\nIn Python k√∂nnen Sie f√ºr verschiedene F√§lle (cases) andere Aktionen ausf√ºllen, indem Sie If-else Statements nutzen.\nEin If-else Statement enth√§lt ein if (wenn), einer condition (das zutrifft), einem body (dann mach das).\nErg√§nzt kann dies werden mit ifelse (oder wenn)+ condition (das zutrifft) + body (dann mach das) und einem else (wenn nichts davon zutrifft) + body (dann mach das).\nWichtig: - Python ist indentation-sensibel, das bedeutet: Die Einr√ºckung (1 Tab) muss stimmen, sonst funktioniert der Code nicht. Auch der Doppelpunkt : ist wichtig und muss an der richtigen Stelle stehen. Wenn Sie mehrere conditions verwenden m√∂chten, m√ºssen Sie diese in Klammern () setzen. Hier sehen Sie die Syntax eines If-else Statements:\nif (condition):\n    body\n    \nelif (condition):\n    body\n    \nelse:\n    body\n\n\n\nEinf√ºhrung in Python auf Datacamp: üëâüèº Introduction to Python\n\n\n4.5.1 Variable Dauer von Elementen\n\nFixationskreuz und ITI mit randomisierter Dauer\nUm das Experiment f√ºr die Versuchsperson unvorhersehbarer zu machen, implementieren wir vor dem eigentlichen Stimulus ein Fixationskreuz mit variabler L√§nge. Diese L√§nge soll 0.2, 0.4, 0.6, oder 0.8 Sekunden betragen.\n\nF√ºgen Sie einen Codeblock code_fixationcross ein und definieren Sie unter Begin Routine die Variable fixationcross_duration.\n\nF√ºgen Sie einen Textblock fixationcross ein mit dem Text + und Schriftgr√∂sse 10. Geben Sie unter duration Ihre vorher definierte Variable ein (vergessen Sie dabei das $ nicht): $fixationcross_duration.\n\n\n\n\n\n\n\n\nHands-on: Variable ITI einbauen\n\n\n\nF√ºgen Sie nach dem Stimulus eine ITI mit variabler Dauer hinzu.\nEinfachere Variante: Die ITI soll 10, 20, 30, 40 oder 50 Frames betragen.\nSchwierigere Variante: Die ITI soll eine Zufallszahl zwischen 0.2 und 0.8 Sekunden betragen.\n\n\n\n\n\n4.5.2 Feedback\nEs gibt Experimente, welche Feedback erfordern. Oft wird vor der Datenerhebung ein √úbungsblock eingebaut, welcher Feedback enth√§lt, so dass die Versuchspersonen wissen, ob sie den Task richtig verstanden haben.\n\nErstellen Sie zuerst eine Trialschleife mit einem Stimulus und einer Response.\nF√ºgen Sie nach dem Stimulus und der Antwort (aber innerhalb der Trialschleife!) eine Routine feedback ein.\nF√ºgen Sie innerhalb der Routine feedback eine Codekomponente hinzu. In dieser Komponente k√∂nnen Sie nun\n\nF√ºgen Sie nun eine Textkomponente hinzu und f√ºgen Sie beim Textfeld die Variable $response_msg ein, damit die Versuchsperson abh√§ngig von ihrer Antwort das entsprechende Feedback erh√§lt, welches zuvor in der Codekomponente definiert wurde.\n\n\n\n\n\n\n\n\nHands-on: Feedback geben\n\n\n\nSie k√∂nnen mittels einer Codekomponente auch reagieren, wenn die Versuchsperson zu schnell, zu langsam oder gar nicht antwortet.\n\nErstellen Sie einen √úbungsdurchgang. F√ºgen Sie eine Code-Komponente hinzu und legen Sie fest, welches Feedback die Versuchsperson erhalten soll.\n\nEinfache Variante: Geben Sie der Person Feedback, ob ihre Antwort richtig oder falsch war.\nMittelschwere Variante: Geben Sie der Person Feedback, wenn Sie zu schnell oder zu langsam antwortet.\nSchwere Variante: Erstellen Sie einen Counter, welcher der Versuchsperson anzeigt, wie gut sie ist, indem f√ºr jede richtige Antwort 5 Punkte erh√§lt, f√ºr jede falsche Antwort 5 Punkte abgezogen werden.\nFalls Sie zur Geschwindigkeit R√ºckmeldung geben wollen oder einen Counter bauen, k√∂nnen Sie etwas in dieser Art machen.\nif dots_keyboard_response.keys is None:\n    response_text = \"miss\"\n\nelif dots_keyboard_response.rt &lt;= 0.1:\n    response_text = \"too fast\"\n\nelse:\n    if (direction == \"left\" and dots_keyboard_response.keys == \"f\" or \n        direction == \"right\" and dots_keyboard_response.keys == \"j\"):\n        response_text = \"+5 points\"\n    else:\n        response_text = \"+0 points\"",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#weitere-wichtige-punkte",
    "href": "psychopy_experiments.html#weitere-wichtige-punkte",
    "title": "4¬† Verhaltensexperimente mit PsychoPy",
    "section": "4.6 Weitere wichtige Punkte",
    "text": "4.6 Weitere wichtige Punkte\n\n4.6.1 Degrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abh√§ngig sind. Degrees of visual angle gibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die Gr√∂sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von OpenSesame. √úblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm f√ºr die Erstellung behavioraler Experimente.\n\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem Link mehr Information.\n\n\n4.6.2 Timing\nFrames vs.¬†time (sec or ms): Die pr√§ziseste Art zur Steuerung des Timings von Stimuli besteht darin, sie f√ºr eine festgelegte Anzahl von Frames zu pr√§sentieren. Bei einer Framerate von 60 Hz k√∂nnen Sie Ihren Stimulus nicht z. B. 120 ms lange pr√§sentieren; die Bildperiode w√ºrde Sie auf einen Zeitraum von 116,7 ms (7 Bilder) oder 133,3 ms (8 Bilder) beschr√§nken. Dies ist besonders wichtig f√ºr Reaktionszeit-Aufgaben und EEG-Studien, wo ein pr√§zises Millisekunden-Timing erforderlich ist. Hier finden Sie weitere Informationen zu diesem Thema: Presening Stimuli - Psychopy.\n\nHertz ist eine Einheit die angibt, wie h√§ufig etwas pro Sekunde passiert. Hertz kann wie Mal pro Sekunde ausgesprochen werden. 60 Hertz bedeutet also, 60 Mal pro Sekunde.\n\n\n\n4.6.3 Individualisierte Aufgabenschwierigkeit / Schwellenmessung\nIm Random Dot Experiment macht es z.B. f√ºr gewisse Fragestellungen Sinn die Aufgabenschwierigkeit f√ºr jede Person anzupassen, da sonst ceiling/floor-Effekte auftreten k√∂nnen.\nIn PsychoPy kann ein Staircase in einem Loop verwendet werden, um die Schwierigkeit einer Aufgabe basierend auf der Leistung der Teilnehmer dynamisch anzupassen. Sie ist besonders h√§ufig in Experimenten zur Schwellenmessung, bei denen das Ziel darin besteht, die kleinste wahrnehmbare Reizintensit√§t zu bestimmen. Hier finden Sie weitere Informationen zu diesem Thema: Using a Staircase - PsychoPy.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html",
    "href": "stroop_experiment.html",
    "title": "5¬† Stroop Paradigma",
    "section": "",
    "text": "6 Stroop Task\nDer Stroop Task wurde 1935 zum ersten Mal beschrieben (Stroop, 1935) und ist einer der meist zitierten und verwendeten neuropsychologischen Aufgaben (MacLeod, 1991). In der Neuropsychologie wird der Stroop Color and Word Test (SCWT) verwendet, um die F√§higkeit zur Inhibition kognitiver Interferenz zu messen, welche entsteht wenn zwei Stimuluseigenschaften gleichzeitig verarbeitet werden sich aber widersprechen (Scarpina & Tagini, 2017). Teilweise misst der Task auch andere kognitive Funktionen, wie visuelle Suche oder Arbeitsged√§chtnis, weshalb der Vergleich von Bedingungen relevant ist (Peri√°√±ez et al., 2021).\nW√§hrend dem Stroop Task wird ein Text mit Farbw√∂rtern pr√§sentiert. Im kongruenten Durchgang entsprechen die Farben des Textes dem Farbwort (das Wort ‚Äúrot‚Äù wird in rot pr√§sentiert), im inkongruenten Durchgang unterscheiden sich die Farben des Textes vom Farbwort (das Wort ‚Äúrot‚Äù wird in gelber Farbe pr√§sentiert). Die Person muss angeben in welcher Farbe das Wort abgedruckt ist. In der kongruenten Bedingung f√§llt dies leichter, weil das gelesene Wort auch der Farbe entspricht. In der inkongruenten Bedingung verlangsamt sich die Geschwindigkeit durch die entstehende Interferenz von Wort und Farbe, da das Wort automatisch gelesen wird. Oft wird auch noch eine neutrale Bedingung verwendet, wo nur die Farbe oder das Wort pr√§sentiert werden.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#kurzbeschrieb-kursexperiment",
    "href": "stroop_experiment.html#kurzbeschrieb-kursexperiment",
    "title": "5¬† Stroop Paradigma",
    "section": "6.1 Kurzbeschrieb Kursexperiment",
    "text": "6.1 Kurzbeschrieb Kursexperiment\nIn diesem Experiment l√∂sen die Personen zwei Bedingungen des Stroop Task, einmal geben sie die Farben der W√∂rter an in einer kongruenten Bedingung (Wortinhalt und Wortfarbe) stimmen √ºberein. Einmal l√∂sen sie die Aufgabe in einer inkongruenten Bedingung (Wortinhalt und Wortfarbe stimmen nicht √ºberein).\nDie kongruente und inkongruente Bedingung kommen im selben Block vor. Die Instruktion lautet f√ºr beide Bedingungen gleich, da immer die Wortfarbe angegeben werden muss. Drei Farben werden verwendet: rot, blau und gelb.\nDas Stroop Kursexperiment ist folgendermassen aufgebaut:\n\n\n\n\n\n\n\nHands-on: Stroop Kursexperiment\n\n\n\nLaden Sie das Experiment herunter und testen Sie, ob es auf Ihrem Laptop l√§uft. Hier finden Sie die Anweisungen dazu.\n\nTesten Sie, ob das Experiment startet und ob die √úbungstrials funktionieren. Kontrollieren Sie, ob es ein Datenfile abgespeichert hat und schauen Sie, ob dieses Datenfile alles Relevante enth√§lt. Wenn alles ok ist, ist das Experiment bereit f√ºr √úbung 1. F√ºhren Sie die Testungen ausserhalb des Computerlabs durch.\nBeantworten Sie folgende Fragen zum Experiment:\n\n\nWas wurde im Experiment variiert? Wie viele unterschiedliche Trials gibt es?\nWelche Bedingungen gibt es?\nWieviele Trials werden pro Bedingung durchgef√ºhrt?\nWie lange wird der Wort-Stimulus angezeigt? Wann ist er fertig (zeit oder tasten-definiert?)?\nWie denken Sie, wird sich das Verhalten (Reaktionszeit, Richtigkeit) zwischen den Bedingungen unterscheiden?",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#credits",
    "href": "stroop_experiment.html#credits",
    "title": "5¬† Stroop Paradigma",
    "section": "6.2 Credits",
    "text": "6.2 Credits\nDieses Experiment wurde von Rebekka Borer programmiert.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#referenzen",
    "href": "stroop_experiment.html#referenzen",
    "title": "5¬† Stroop Paradigma",
    "section": "6.3 Referenzen",
    "text": "6.3 Referenzen\nMacLeod C. M. (1991). Half a century of research on the Stroop effect: an integrative review. Psychological Bulletin. 109(2), 163‚Äì203. https://doi.org/10.1037/0033-2909.109.2.163\nPeri√°√±ez, J. A., Lubrini, G., Garc√≠a-Guti√©rrez, A., & R√≠os-Lago, M. (2021). Construct validity of the stroop color-word test: influence of speed of visual search, verbal fluency, working memory, cognitive flexibility, and conflict monitoring. Archives of Clinical Neuropsychology, 36(1), 99-111. https://doi.org/10.1093/arclin/acaa034\nScarpina, F., & Tagini, S. (2017). The stroop color and word test. Frontiers in psychology, 8, 557. https://doi.org/10.3389/fpsyg.2017.00557\nStroop, J. R. (1935). Studies of interference in serial verbal reactions. Journal of Experimental Psychology, 18(6), 643‚Äì662. https://doi.org/10.1037/",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html",
    "href": "random_dot_experiment.html",
    "title": "6¬† Random Dot Paradigma",
    "section": "",
    "text": "7 Random Dot Experiment\nJeden Tag treffen wir Tausende von kleinen Entscheidungen, meistens unter gewissem Zeitdruck. Viele davon sind trivial (z. B. welches Paar Socken man anzieht) und automatisch (z. B. ob man die Espresso- oder Lungo-Taste auf der Kaffeemaschine dr√ºckt). Die meisten Entscheidungen im wirklichen Leben setzen sich eigentlich aus zwei Entscheidungen zusammen: Einerseits der Entscheidung, mit dem Abw√§gen aufzuh√∂ren und aufgrund des aktuellen Wissenstandes zu handeln. Andererseits die Wahl oder Entscheidungshandlung selbst. Dieser sequentielle Charakter der Entscheidungsfindung ist eine grundlegende Eigenschaft des menschlichen Nervensystems und spiegelt seine Unf√§higkeit wieder, Informationen sofort zu verarbeiten.\nPerzeptuelle Entscheidungen sind Entscheidungen, welche auf der Wahrnehmung, Einordnung und Integration von Sinnesreizen beruhen. Um beispielsweise eine Strasse sicher √ºberqueren zu k√∂nnen, m√ºssen wir mittels den Sinnesinformationen der Augen und Ohren sowie der Verarbeitung dieser Reize einsch√§tzen mit welcher Geschwindigkeit ein herannahendes Auto unterwegs ist und ob wir lieber abwarten bis es vorbeigefahren ist. Innerhalb der Neurowissenschaften wird perceptual decision making untersucht, um die neuronalen Schaltkreise welche Wahrnehmungssignale kodieren, speichern und analysieren zu verstehen und mit beobachtbarem Verhalten in Verbindung zu bringen. Von Interesse ist zum Beispiel wie die Entscheidung ausf√§llt, wenn die sensorischen Daten undeutlich oder sogar widerspr√ºchlich sind. Besonders spannend ist auch wie Vorwissen (prior knowledge) auf das Entscheidungsverhalten einwirkt.\nObwohl das Treffen von Entscheidungen f√ºr uns etwas sehr Vertrautes ist, ist das Wissen darum, wie das Gehirn diese Entscheidungsaufgaben l√∂st noch sehr begrenzt. Eine einzelne Entscheidung kann schon sehr komplex sein. Um die Dynamik der Entscheidungsfindung zu verstehen, konzentrieren sich die meisten Studien deshalb auf einfache, wiederholbare Wahlprobleme mit nur zwei (bin√§ren) Antwortm√∂glichkeiten. Ein typisches Paradigma in neurowissenschaftlichen Studien ist das random-dot motion paradigm. Hierbei muss eine Person entscheiden in welche Richtung sich eine Punktewolke bewegt.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html#kurzbeschrieb-kursexperiment",
    "href": "random_dot_experiment.html#kurzbeschrieb-kursexperiment",
    "title": "6¬† Random Dot Paradigma",
    "section": "7.1 Kurzbeschrieb Kursexperiment",
    "text": "7.1 Kurzbeschrieb Kursexperiment\nIn unserem Experiment l√∂sen die Versuchspersonen einen Random Dot Task zweimal (in zwei Bl√∂cken). In jedem Block erhalten sie eine andere Instruktion, die Aufgabe bleibt jedoch dieselbe: Sie m√ºssen herausfinden in welche Richtung sich die Punktewolke bewegt. In einem Block werden sie instruiert die Aufgabe m√∂glichst schnell zu l√∂sen. Im anderen Block werden sie instruiert die Aufgabe m√∂glichst richtig zu l√∂sen. Wir werden dann analysieren, wie sich das Entscheidungsverhalten von Menschen ver√§ndert, je nachdem wie sie instruiert wurden.\nDas Random Dot Kursexperiment ist folgendermassen aufgebaut:\n\n\n\n\n\n\n\nHands-on: Random Dot Kursexperiment\n\n\n\nLaden Sie das Experiment herunter und testen Sie, ob es auf Ihrem Laptop l√§uft. Hier finden Sie die Anweisungen dazu.\n\nTesten Sie, ob das Experiment startet und ob die √úbungstrials funktionieren. Kontrollieren Sie, ob es ein Datenfile abgespeichert hat und schauen Sie, ob dieses Datenfile alles Relevante enth√§lt. Wenn alles ok ist, ist das Experiment bereit f√ºr √úbung 1. F√ºhren Sie die Testungen ausserhalb des Computerlabs durch.\nBeantworten Sie folgende Fragen zum Experiment:\n\n\nWas wurde im Experiment variiert? Wie viele unterschiedliche Trials gibt es?\nWelche Bedingungen gibt es?\nWieviele Trials werden pro Bedingung durchgef√ºhrt?\nWie lange wird der Dot-Stimulus angezeigt? Wann ist er fertig (zeit oder tasten-definiert?)?\nWie denken Sie, wird sich das Verhalten (Reaktionszeit, Richtigkeit) zwischen den Bedingungen unterscheiden?",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html#credits",
    "href": "random_dot_experiment.html#credits",
    "title": "6¬† Random Dot Paradigma",
    "section": "7.2 Credits",
    "text": "7.2 Credits\nDieses Experiment wurde von Rebekka Borer programmiert.\n\n\n\n\nHauser, Christopher K., and Emilio Salinas. 2014. ‚ÄúPerceptual Decision Making.‚Äù In Encyclopedia of Computational Neuroscience, edited by Dieter Jaeger and Ranu Jung, 1‚Äì21. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4614-7320-6_317-1.\n\n\nMulder, M. J., E.-J. Wagenmakers, R. Ratcliff, W. Boekel, and B. U. Forstmann. 2012. ‚ÄúBias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff.‚Äù Journal of Neuroscience 32 (7): 2335‚Äì43. https://doi.org/10.1523/JNEUROSCI.4156-11.2012.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "intro_python.html",
    "href": "intro_python.html",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "",
    "text": "7.1 Wichtige Datentypen in Python (mit Vergleich zu R)",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#wichtige-datentypen-in-python-mit-vergleich-zu-r",
    "href": "intro_python.html#wichtige-datentypen-in-python-mit-vergleich-zu-r",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "",
    "text": "Typ\nBeschreibung\nPython Beispiel\nR-√Ñquivalent\n\n\n\n\nListe\nVer√§nderbare Sammlung von Elementen\nx = [1, 2, 3, \"Hallo\"]\nx &lt;- list(1, 2, 3, \"Hallo\")\n\n\nTupel\nUnver√§nderbare Sammlung von Elementen\nx = (1, 2, 3)\nKein direktes √Ñquivalent\n\n\nDictionary\nSammlung von Schl√ºssel-Wert-Paaren\nx = {\"Name\": \"Max\", \"Alter\": 20}\nx &lt;- list(Name = \"Max\", Alter = 20)\n\n\nNumPy Array\nNumerisches Array f√ºr schnelle mathematische Operationen\nx = np.array([1, 2, 3])\nx &lt;- c(1, 2, 3)",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#beispiele",
    "href": "intro_python.html#beispiele",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.2 Beispiele",
    "text": "7.2 Beispiele\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nNote\n\n\n\nWichtig: In Python beginnt die Z√§hlung bei 0, nicht bei 1 wie in R!\n\n\n\n\n\n\n\n\nHands-on 1: Eigene Liste und Tupel erstellen\n\n\n\n\nErstellen Sie eine Liste mit den Zahlen 10, 20, 30.\nF√ºgen Sie der Liste die Zahl 40 hinzu: eure_liste.append(40).\nErstellen Sie ein Tupel mit den gleichen Zahlen.\nVersuchen Sie, ein Element mit append im Tupel hinzuf√ºgen. Was passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#bibliotheken-importieren",
    "href": "intro_python.html#bibliotheken-importieren",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.3 Bibliotheken importieren",
    "text": "7.3 Bibliotheken importieren\nIn Python verwenden wir import, um externe Bibliotheken zu laden (√§hnlich wie library() in R):\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nHierbei sind: - pandas f√ºr Tabellenstrukturen (wie data.frame in R) - numpy f√ºr numerische Berechnungen - matplotlib f√ºr Grafiken\n\n\n\n\n\n\nHands-on 2: Bibliotheken testen\n\n\n\nImportieren Sie numpy und erstellen Sie ein Array mit den Werten 5, 10, 15.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nHands-on 3: Listen vs Arrays verstehen\n\n\n\n\nErstellen Sie eine Python-Liste [2, 4, 6] und verdoppeln Sie sie mit * 2.\n\nErstellen Sie ein NumPy-Array mit denselben Werten und multiplizieren Sie es mit 2.\n\nWas ist der Unterschied in der Ausgabe?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\na &lt;- c(1, 2, 3)\nprint(a * 2)\n\n[1] 2 4 6\n\n#Jede Zahl wird mathematisch multipliziert (genau wie bei NumPy arrays).\n\n\n#b &lt;- list(1, 2, 3)\n#print(b * 2)\n# Weil Listen in R keine mathematischen Operationen direkt unterst√ºtzen ‚Äî sie sind nur Sammlungen von beliebigen Objekten.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#datens√§tze-einlesen-und-anschauen",
    "href": "intro_python.html#datens√§tze-einlesen-und-anschauen",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.4 Datens√§tze einlesen und anschauen",
    "text": "7.4 Datens√§tze einlesen und anschauen\n\n\n\nR Funktion\nPython Funktion\n\n\n\n\nread.csv(\"path\")\npd.read_csv(\"path\")\n\n\nhead(df)\ndf.head()\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#dot-notation-verstehen",
    "href": "intro_python.html#dot-notation-verstehen",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.5 Dot-Notation verstehen",
    "text": "7.5 Dot-Notation verstehen\nIn R ruft man Funktionen wie head(df) auf, wobei das Objekt als Argument √ºbergeben wird.\nIn Python geh√∂rt die Funktion direkt zum Objekt und wird mit Punktnotation aufgerufen:\n\n\n\nR\nPython\n\n\n\n\nhead(df)\ndf.head()\n\n\nmean(df$col)\ndf[\"col\"].mean()\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMerke: In Python sind viele Funktionen Methoden, die direkt an ein Objekt (wie ein DataFrame) gebunden sind. Deshalb funktioniert head(df) nicht!\n\n\n\n\n\n\n\n\nHands-on 4: Methoden mit Dot-Notation verwenden\n\n\n\n\nZeigen Sie die ersten 10 Zeilen von df an.\nVerwenden Sie df.describe() f√ºr einen √úberblick.\nWenden Sie .mean() und .min() auf df[\"petal_width\"] an.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#zugriff-auf-spalten-und-zeilen",
    "href": "intro_python.html#zugriff-auf-spalten-und-zeilen",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.6 Zugriff auf Spalten und Zeilen",
    "text": "7.6 Zugriff auf Spalten und Zeilen\nIn Python (mit pandas) k√∂nnen Sie √§hnlich wie in R auf bestimmte Teile einer Tabelle zugreifen ‚Äî aber mit etwas anderer Syntax.\n\n\n\n\n\n\n\n\nZiel\nPython Syntax\nR-√Ñquivalent\n\n\n\n\nSpalte ausw√§hlen\ndf[\"species\"]\ndf$species\n\n\nMehrere Spalten ausw√§hlen\ndf[[\"sepal_length\", \"species\"]]\ndf[, c(\"sepal_length\", \"species\")]\n\n\nErste Zeilen anzeigen\ndf.head(3)\nhead(df, 3)\n\n\nZeile nach Position\ndf.iloc[0]\ndf[1, ]\n\n\nWert aus Zeile & Spalte\ndf.iloc[0][\"sepal_length\"]\ndf[1, \"sepal_length\"]\n\n\nZeilen nach Bedingung\ndf[df[\"sepal_length\"] &gt; 6]\ndf[df$sepal_length &gt; 6, ]\n\n\n\n\n\n7.6.1 Beispiele:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nHands-on 5: Zeilen und Spalten ausw√§hlen\n\n\n\n\nGeben Sie nur die Spalte \"petal_width\" aus.\n\nZeigen Sie die ersten 5 Zeilen des Datensatzes mit df.head().\n\nGeben Sie \"sepal_length\" und \"sepal_width\" aus.\n\nGeben Sie den Wert in Zeile 1, Spalte \"species\" aus.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#daten-filtern-und-neue-variablen-erstellen",
    "href": "intro_python.html#daten-filtern-und-neue-variablen-erstellen",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.7 Daten filtern und neue Variablen erstellen",
    "text": "7.7 Daten filtern und neue Variablen erstellen\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nHands-on 6: Filtern und neue Spalten berechnen\n\n\n\n\nFiltern Sie die Zeilen mit sepal_length &gt; 6.\nErstellen Sie eine neue Spalte namens petal_ratio, die petal_length / petal_width ist.\nWas ist der Mittelwert der neuen Spalte?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\n\nHands-on 7: Recap\n\n\n\n\nFiltern Sie nur die virginica-Blumen.\nErstellen Sie eine neue Spalte: sepal_area = sepal_length * sepal_width\nWas ist der Maximalwert von petal_length bei virginica?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "intro_python.html#zusammenfassung-r-vs-python",
    "href": "intro_python.html#zusammenfassung-r-vs-python",
    "title": "7¬† Python: Einf√ºhrung f√ºr Neurowissenschaften",
    "section": "7.8 Zusammenfassung: R vs Python",
    "text": "7.8 Zusammenfassung: R vs Python\n\n\n\n\n\n\n\n\nAufgabe\nR\nPython\n\n\n\n\nPaket laden\nlibrary(ggplot2)\nimport seaborn as sns\n\n\nVektor erstellen\nc(1, 2, 3)\nnp.array([1, 2, 3])\n\n\nListe erstellen\nlist(1, 2, 3)\n[1, 2, 3]\n\n\nBenannte Liste\nlist(id = 1)\n{\"id\": 1}\n\n\nCSV einlesen\nread.csv(\"data.csv\")\npd.read_csv(\"data.csv\")\n\n\nErste Zeilen anzeigen\nhead(df)\ndf.head()\n\n\nSpalte ausw√§hlen\ndf$col\ndf[\"col\"]\n\n\nMehrere Spalten\ndf[, c(\"a\", \"b\")]\ndf[[\"a\", \"b\"]]\n\n\nZeile(n) nach Position\ndf[1, ]\ndf.iloc[0]\n\n\nWert aus Zeile und Spalte\ndf[1, \"col\"]\ndf.iloc[0][\"col\"]\n\n\nZeilen filtern\ndf[df$col &gt; 3, ]\ndf[df[\"col\"] &gt; 3]\n\n\nMittelwert berechnen\nmean(df$col)\ndf[\"col\"].mean()\n\n\nStandardabweichung\nsd(df$col)\ndf[\"col\"].std()\n\n\nNeue Spalte hinzuf√ºgen\ndf$new &lt;- df$a / df$b\ndf[\"new\"] = df[\"a\"] / df[\"b\"]\n\n\nHistogram\nhist(df$col)\nsns.histplot(df[\"col\"])\n\n\nBoxplot\nboxplot(col ~ group, data=df)\nsns.boxplot(x=\"group\", y=\"col\", data=df)\n\n\n\n\n\n\n\n\n\nüí° L√∂sungen zu den Hands-on Aufgaben\n\n\n\n\n\n\n7.8.1 Hands-on 1\nmeine_liste = [10, 20, 30]\nmeine_liste.append(40)\nprint(meine_liste)\n\nmein_tupel = (10, 20, 30)\n# mein_tupel.append(40)  # Fehler! Tupel unterst√ºtzen .append() nicht\n\n\n\n7.8.2 Hands-on 2\nimport numpy as np\nx = np.array([5, 10, 15])\nprint(x * 3)  # [15 30 45]\n\n\n\n7.8.3 Hands-on 3\na = [2, 4, 6]\nprint(a * 2)  # [2, 4, 6, 2, 4, 6]\n\nb = np.array([2, 4, 6])\nprint(b * 2)  # [4 8 12]\n\n\n\n7.8.4 Hands-on 4\nprint(df.head(10))\nprint(df.describe())\nprint(df[\"petal_width\"].mean())\nprint(df[\"petal_width\"].min())\n\n\n\n7.8.5 Hands-on 5\n# 1. Nur die Spalte \"petal_width\"\nprint(df[\"petal_width\"])\n\n# 2. Erste 5 Zeilen\nprint(df.head(5))\n\n# 3. Zwei Spalten anzeigen\nprint(df[[\"sepal_length\", \"sepal_width\"]])\n\n# 4. Wert aus Zeile 1, Spalte \"species\"\nprint(df.iloc[0][\"species\"])\n\n\n\n7.8.6 Hands-on 6\ngefiltert = df[df[\"sepal_length\"] &gt; 6]\ndf[\"petal_ratio\"] = df[\"petal_length\"] / df[\"petal_width\"]\nprint(df[\"petal_ratio\"].mean())\n\n\n\n7.8.7 Hands-on 7\n# 1. Nur die virginica\nvirginica = df[df[\"species\"] == \"virginica\"]\n\n# 2. Neue Spalte: sepal_area = sepal_length * sepal_width\nvirginica[\"sepal_area\"] = virginica[\"sepal_length\"] * virginica[\"sepal_width\"]\n\n# 3. Maximalwert von petal_length\nprint(virginica[\"petal_length\"].max())",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Python: Einf√ºhrung f√ºr Neurowissenschaften</span>"
    ]
  },
  {
    "objectID": "loops.html",
    "href": "loops.html",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "",
    "text": "8.1 for-Schleifen\nDie for-Schleife wird oft genutzt, um √ºber eine Liste oder eine andere Sequenz zu iterieren.\nIn dieser Konsole k√∂nnen Sie Python-Code schreiben, ver√§ndern und ausf√ºhren:\nMan kann eine for-Schleife auch mit range() verwenden:",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#for-schleifen",
    "href": "loops.html#for-schleifen",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "",
    "text": "hirnregionen = [\"Frontallappen\", \"Okzipitallappen\", \"Temporallappen\"] \nfor hirnregion in hirnregionen: \n    print(\"Ich mag den\", hirnregion, \"!\")\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nfor i in range(5):  # Iteriert von 0 bis 4\n    print(\"Iteration Nummer:\", i)\n    \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#while-schleifen",
    "href": "loops.html#while-schleifen",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "8.2 while-Schleifen",
    "text": "8.2 while-Schleifen\nEine while-Schleife wird benutzt, wenn die Anzahl der Iterationen nicht im Voraus bekannt ist, sondern von einer Bedingung abh√§ngt.\nzaehler = 0\nwhile zaehler &lt; 3:\n    print(\"Dies ist Schleifeniteration:\", zaehler)\n    zaehler = zaehler + 1  # Erh√∂ht den Z√§hler, um eine Endlosschleife zu vermeiden\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nHands-on 1-3: for und while-Schleifen erstellen\n\n\n\n\nGeben Sie die Zahlen von 1 bis 10 mit einer for-Schleife aus.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nGeben Sie ‚ÄúPython macht Spa√ü!‚Äù f√ºnfmal mit einer while-Schleife aus.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nErstellen Sie eine Schleife, die nur gerade Zahlen von 1 bis 20 ausgibt.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#flowcharts",
    "href": "loops.html#flowcharts",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "8.3 Flowcharts",
    "text": "8.3 Flowcharts\nBeispiel Flowchart:\ni = 1\nwhile i &lt;= 100:\n    print(i)\n    if i == 39:\n        i = 61\n    else:\n        i = i + 1\n\n\n\nhttps://de.wikipedia.org/wiki/Programmablaufplan#/media/Datei:Flowchart_de.svg\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nHands-on 4: Flowchart erstellen\n\n\n\nErstellen Sie eine Flowchart f√ºr die for-Schleife in Aufgabe 3.\nSie k√∂nnen diese auf https://app.diagrams.net/ erstellen.\n\n\n\n\n\n\n\n\nHands-on 5: Fortgeschrittene √úbung: Donuts-Essen\n\n\n\nErstellen Sie eine Flowchart f√ºr den folgenden Code:\ndonuts = 5\nwhile donuts &gt; 0:\n    print(\"Ich esse einen Donut. Lecker!\")\n    donuts = donuts - 1\n    if donuts == 1:\n        print(\"Oh nein! Nur noch ein Donut √ºbrig!\")\n    elif donuts == 0:\n        print(\"Keine Donuts mehr... Zeit, neue zu kaufen!\")\nHier k√∂nnen Sie ausprobieren, was der Code macht. Passt das zu Ihrer Flowchart?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#wichtig-endlosschleifen-vermeiden",
    "href": "loops.html#wichtig-endlosschleifen-vermeiden",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "8.4 Wichtig: Endlosschleifen vermeiden",
    "text": "8.4 Wichtig: Endlosschleifen vermeiden\nSchleifen m√ºssen immer eine Bedingung haben, die sie beendet. Sonst k√∂nnte folgendes passieren:\ni = 0\nwhile i &lt; 1:\n    i = i - 1\n    print(i)  # Diese Schleife l√§uft endlos!\nHier fehlt eine Bedingung, die i wieder gr√∂√üer macht, sodass die Schleife stoppt.\nProbieren Sie es aus (wenn Sie einen Crash Ihres Browsertabs nicht scheuen‚Ä¶?).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#fazit",
    "href": "loops.html#fazit",
    "title": "8¬† Schleifen programmieren mit Python",
    "section": "8.5 Fazit",
    "text": "8.5 Fazit\nSchleifen sind ein m√§chtiges Werkzeug um wiederkehrende Aufgaben effizient zu l√∂sen. Schleifen werden fast √ºberall benutzt: Experimente programmieren, Daten einlesen, Daten bearbeiten, Grafiken erstellen, usw.\n\n\n\n\n\n\n\nHands-on L√∂sungen\n\n\n\n\n\n\n8.5.1 Hands-on 1\nfor i in range(10):\n    print(i + 1)\nAlternativ:\nzahlen = [1,2,3,4,5,6,7,8,9,10]\nfor z in zahlen:\n    print(z)\nOder:\nzahlen = 1\nwhile zahlen &lt;= 10:\n    print(zahlen)\n    zahlen = zahlen + 1\n\n\n8.5.2 Hands-on 2\ni = 0\nwhile i &lt; 5:\n    print(\"Python macht Spa√ü!\")\n    i = i + 1\n\n\n8.5.3 Hands-on 3\nn = 2\nwhile n &lt;= 20:\n    print(n)\n    n = n + 2\n\n\n8.5.4 Hands-on 4\n\n\n\n\n\n\n\n8.5.5 Hands-on 5",
    "crumbs": [
      "Experimentieren & Programmieren",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "uebung_1.html",
    "href": "uebung_1.html",
    "title": "√úbung 1",
    "section": "",
    "text": "Auftrag\nF√ºhren Sie selbst und mit 2 weiteren Personen das Stroop und das Random Dot Experiment durch. Laden Sie anschliessend die 6 Datens√§tze auf Ilias hoch. Die beiden Experimente dauern zusammen ca. 30 Minuten ( abh√§ngig von den Versuchspersonen).\nF√ºhren Sie das Experiment mit der Einstellung Run durch und nicht im Pilot-Mode!\nWichtig:\nDie erhobenen Daten werden wir dann in den kommenden Sitzungen verwenden, achten Sie also auf gute Datenqualit√§t.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "√úbung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#vorgehen",
    "href": "uebung_1.html#vorgehen",
    "title": "√úbung 1",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nLaden Sie die 2 Experimente herunter und testen Sie, ob Sie einwandfrei laufen. Die Experimente befinden sich auf Github. Sie k√∂nnen sie unter den untenstehenden Links downloaden. Klicken Sie daf√ºr auf den ZIP-Ordner, und dann auf View Raw oder auf das Icon mit ... und dort auf Download. Sie m√ºssen das File dann evtl. entzippen, bevor Sie das Experiment starten k√∂nnen. Bei Problemen finden Sie unten einen Abschnitt Troubleshooting. Wenn das nichts hilft, k√∂nnen Sie sich bei der n√§chsten Veranstaltung an uns wenden.\n\nStroop Experiment\nRandom Dot Experiment\n\nF√ºhren Sie selber die beiden Experimente durch.\n\nStellen Sie sicher, dass hier ein vollst√§ndiger Datensatz abgespeichert wird. Testen Sie erst dann zus√§tzliche Personen.\n\nLassen Sie 2 weitere Personen die beiden Experimente ausf√ºhren (jede Person soll beide Experimente ausf√ºhren).\n\nDie Personen m√ºssen zwischen 18 und 60 Jahren alt sein.\nDie Personen sollten eine normale oder korrigiert-zu-normale (Brille/Kontaktlinsen) Sehst√§rke haben.\nKeine Mitstudierenden aus dem Computerlab testen.\nAchten Sie darauf, dass die Personen die Aufgaben konzentriert und ohne Ablenkung l√∂sen k√∂nnen.\n\nLaden Sie die 6 Datens√§tze auf ILIAS hoch.\n\nLaden Sie die 6 .csv/.xlsx-Files mit den erhobenen Datens√§tzen auf Ilias unter √úbung 1 hoch.\n\n\nDie Datens√§tze finden Sie im Experimentordner (dort wo das .psyexp-File des Experiments gespeichert ist) einen Ordner data. In diesem Ordner sind mehrere Dateien vorhanden. Sie m√ºssen nur die .csv/.xlsx-Files pro Person hochladen, die anderen Files werden nicht ben√∂tigt. Die Datei muss einige KB gross sein, sonst hat etwas nicht geklappt (z.B. wenn die Datei nur 2 KB gross ist).",
    "crumbs": [
      "Experimentieren & Programmieren",
      "√úbung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#abgabetermin",
    "href": "uebung_1.html#abgabetermin",
    "title": "√úbung 1",
    "section": "Abgabetermin",
    "text": "Abgabetermin\n14. M√§rz 2024 23:55",
    "crumbs": [
      "Experimentieren & Programmieren",
      "√úbung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#trouble-shooting",
    "href": "uebung_1.html#trouble-shooting",
    "title": "√úbung 1",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nBitte die Fehlermeldung im Fenster genau durchlesen. Dort finden Sie Hinweise darauf, was schief gelaufen ist.\nDas Experiment startet nicht.\n\nUnter Einstellungen (Radsymbol) den Reiter Basic ausw√§hlen. Bei Use PsychoPy version die neuste PsychoPy Version 2024.2.4 ausw√§hlen.\nUnter Einstellungen (Radsymbol) den Reiter Input ausw√§hlen. Bei Keyboard backend (statt ioHub) PsychToolbox ausw√§hlen.\n\nDas Experiment startet zwar, der Bildschirm ist aber dann einfach f√ºr eine kurze Zeit grau und das Fenster schliesst sich wieder.\n\nZugriffsrechte gegeben? (Bei Windows: Als Administrator starten, bei MacOS: Zugriffsrechte erteilen)\nUnter Einstellungen (Radsymbol) den Reiter Input ausw√§hlen. Keyboard Backend auf PsychToolbox statt ioHub setzen.",
    "crumbs": [
      "Experimentieren & Programmieren",
      "√úbung 1"
    ]
  },
  {
    "objectID": "datawrangling.html",
    "href": "datawrangling.html",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "",
    "text": "9.1 Datenformate\nBevor mit einem Datensatz gearbeitet wird, empfiehlt es sich den Datensatz anzuschauen und Folgendes zu identifizieren:",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#datenformate",
    "href": "datawrangling.html#datenformate",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "",
    "text": "In welchem Dateiformat ist der Datensatz gespeichert? (z.B. in .csv, .xlsx oder anderen?)\nIn welchem Datenformat ist der Datensatz geordnet? (long oder wide oder mixed?)\nGibt es ein data dictionary mit Erkl√§rungen zu den Variablen?",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#set-up",
    "href": "datawrangling.html#set-up",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.2 Set up",
    "text": "9.2 Set up\n\n\n\n\n\n\nHands-on: Vorbereitung\n\n\n\n\n√ñffnen Sie RStudio.\nErstellen Sie ein neues RStudio-Project.\n\nKlicken Sie daf√ºr auf File &gt; New Project\nBenennen Sie das Project complab_fs25 und speichern Sie es an einem sinnvollen Ort auf Ihrem Computer. W√§hlen Sie, dass daf√ºr ein neuer Ordner erstellt werden soll.\n\nErstellen Sie in diesem Projekt-Ordner einen Ordner namens data.\nKopieren Sie in den data-Ordner Ihre erhobenen Daten des Stroop Experiments. Falls Sie noch keine Daten erhoben haben, dann laden Sie hier einen Beispiels-Datensatz herunter und speichern Sie ihn im data-Ordner.\nErstellen Sie ein neues RScript oder ein RNotebook (.Rmd-File: File &gt; New File &gt; RNotebook) und speichern Sie dieses unter intro_datawrangling im Projekt-Ordner.\n\n\n\n\n\n\n\n\n\nTipp: Namensgebung f√ºr Files und Variablen\n\n\n\nWenn Sie Filenamen ausw√§hlen, achten Sie darauf dass diese machine-readable sind:\n\nkeine L√ºcken (verwenden Sie stattdessen den camelCase, den snake_case oder -)\nkeine √§, √∂, √º oder andere Sonderzeichen verwenden",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#packages-installieren-und-laden",
    "href": "datawrangling.html#packages-installieren-und-laden",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.3 Packages installieren und laden",
    "text": "9.3 Packages installieren und laden\nF√ºr das Bearbeiten der Daten verwenden eignen sich Funktionen aus dem Package {tidyverse}, eine Sammlung von verschiedenen, f√ºr data science sehr geeigneten R Packages. Funktionen aus dem {tidyverse} erm√∂glichen und vereinfachen viele Schritte der Datenverarbeitung. Im Folgenden werden die wichtigsten und h√§ufigst verwendeten Funktionen beschrieben. Das {tidyverse} k√∂nnen Sie direkt in R herunterladen:\n\nMehr Informationen zum {tidyverse} finden Sie hier.\n\n\n# Download und Installieren des Packages (nur einmal ausf√ºhren)\ninstall.packages(\"tidyverse\")\n\nEin Package muss nur einmal heruntergeladen und installiert werden, danach ist es lokal auf dem Computer gespeichert. Aber: Jedes Mal wenn R ge√∂ffnet wird, m√ºssen Packages wieder neu geladen werden.\n\n# Package laden (bei jedem √ñffnen von R zu Beginn des Skripts ausf√ºhren)\nlibrary(\"tidyverse\") \n\nSobald ein Package installiert ist, k√∂nnen die Funktionen auch verwendet werden ohne, dass das ganze Package mit library() geladen wird, indem die Funktion mit dem Package-Namen zusammen aufgerufen wird: packagename::packagefunction(). Dies macht Sinn, wenn verschiedene Packages dieselben Namen f√ºr verschiedene Funktionen nutzen und es so zu Konflikten kommt oder wenn nur eine Funktion aus einem Package verwendet werden soll und alle anderen sowieso nicht gebraucht werden.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-importieren-in-r-read.csv",
    "href": "datawrangling.html#daten-importieren-in-r-read.csv",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.4 Daten importieren in R: read.csv()",
    "text": "9.4 Daten importieren in R: read.csv()\nEinen Datensatz in .csv-Format kann mit der Funktion read.csv() importiert werden. Teilweise muss innerhalb der Klammer zus√§tzlich der Separator mit sep = \",\" angegeben werden, also mit welchem Zeichen die Spalten getrennt sind. Normalerweise ist dies , in .csv (comma separated values), es kann aber auch ;, . oder eine L√ºcke  sein.\n\n# Daten laden und anschauen\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\")\nglimpse(d_stroop)\n\n\n\n\n\n\n\nHands-on: Daten einlesen\n\n\n\nLesen Sie den Stroop Datensatz in Ihrem data-Ordner ein und schauen Sie ihn dann mit den Funktionen glimpse() und head() an.\n\nWelche Variablen sind wichtig f√ºr die weitere Auswertung?\nWelche braucht es wahrscheinlich nicht mehr?\nFinden Sie Versuchspersonenidentifikation? / Reaktionszeit? / Antwort der Versuchsperson?\n\n\n\n\n\n\n\n\n\nTipp: Daten anderer Formate einlesen\n\n\n\nFalls Sie eine Excel-Datei einlesen m√∂chten, k√∂nnen Sie dies mit der read_excel()-Funktion aus dem Package readxl() tun: readxl::read_excel().\nFalls Sie nicht wissen, mit welcher Funktion Sie Ihre Daten einlesen k√∂nnen, k√∂nnen Sie dies in RStudio ausprobieren indem Sie beim Reiter Environment auf Import Dataset klicken und dort Ihren Datensatz ausw√§hlen oder √ºber File &gt; Import Dataset. Sie k√∂nnen dort diverse Einstellungen t√§tigen. In der R Console k√∂nnen Sie dann den Code sehen, der zum Einlesen verwendet wurde und die dortige Funktion in Ihren Code kopieren.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#verwenden-der-pipe-oder",
    "href": "datawrangling.html#verwenden-der-pipe-oder",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.5 Verwenden der Pipe: |> oder %>%",
    "text": "9.5 Verwenden der Pipe: |&gt; oder %&gt;%\nIn R k√∂nnen Sie die Pipe verwenden um mehrere Datenverarbeitungsschritte aneinander zu h√§ngen. Damit sparen Sie sich aufw√§ndige Zwischenschritte und vermeiden das Erstellen von immer neuen Datens√§tzen. Statt zwei einzelne Datenverarbeitungsschritte zu machen wie oben, k√∂nnen mehrere Schritte (hier Daten einlesen und anzeigen) zusammengefasst werden, in dem nach Zeilenende eine Pipe eingef√ºgt wird:\n\nWann Pipes ungeeignet sind wird hier beschrieben.\n\n\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\") |&gt;\n    glimpse()\n\nDie Base R Pipe |&gt; und die magritter Pipe %&gt;%_ unterscheiden sich in Details, in diesem Kapitel spielt es jedoch keine Rolle, welche Pipe Sie verwenden.\n\n\n\n\n\n\nTipp\n\n\n\nAchtung: Wenn wir zu Beginn ein &lt;- oder = verwenden, wird alles was nach der Pipe kommt wird ebenfalls im Datensatz ver√§ndert. Wird z.B. der Code ‚Ä¶\n\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\") |&gt;\n    head()\n\n‚Ä¶eingegeben, besteht der Datensatz d_stroop dann nur noch aus 6 Zeilen, weil die Funktion head() den Datensatz auf die ersten 6 Zeilen k√ºrzt.\nWird die Pipe ohne &lt;- oder = verwendet, bleibt der Datensatz unver√§ndert:\n\nd_stroop |&gt;\n    head()",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-filtern-filter",
    "href": "datawrangling.html#daten-filtern-filter",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.6 Daten filtern: filter()",
    "text": "9.6 Daten filtern: filter()\nMit filter() k√∂nnen bestimmte Beobachtungen oder Untergruppen ausgew√§hlt werden. Hierf√ºr muss in der Funktion filter(.data, filter, ...) der Datensatz, die betreffende Variable, sowie eine Bedingung eingegeben werden. Es wird die ganze Zeile im Datensatz behalten in der die Variable der Bedingung entspricht.\nBeispiele:\n\n# nur die Trials mit den rot angezeigten W√∂rtern behalten\nd_stroop_filtered &lt;- filter(d_stroop, color == \"red\")\n\n# dasselbe mit der Pipe\nd_filtered &lt;- d_stroop |&gt; filter(color == \"red\")\n\n# nur Trials die ohne blau angezeigten W√∂rter behalten\nd_filtered &lt;- d_stroop |&gt; filter(color != \"blue\")\n\n# nur √úbungstrials mit einer Antwortszeit unter oder gleich gross wie 1 Sekunde behalten\nd_filtered &lt;- d_stroop |&gt; filter(respPractice.rt &lt;= 1)\n\n# nur √úbungstrials mit Antwortzeiten zwischen 1 und 2 Sekunden behalten\nd_filtered &lt;- d_stroop |&gt; filter(respPractice.rt &gt; 1 & respPractice.rt &lt; 2)\n\n# mehrere Filter verwenden\nd_filtered &lt;- d_stroop |&gt; \n    filter(color == \"red\") |&gt;\n    filter(respPractice.rt &lt;= 1)\n\nIn unserem Datensatz m√∂chten wir nur die g√ºltigen Experimentdaten behalten, die Color-To-Key (ctk) Bedingung sowie die Practice Trials m√∂chten wir ausschliessen.\nDie Variable trials_test.thisN enth√§lt die Trialnummer, sie enth√§lt nur Eintr√§ge, w√§hrend der g√ºltigen Trials. Wir k√∂nnen dies nutzen und alle Zeilen behalten in welchen die Zelle der Variable trials_test.thisN nicht leer ist:\n\nd_stroop &lt;- d_stroop |&gt; \n    filter(!is.na(trials_test.thisN)) \n\n\n\n\n\n\n\nHands-on: Daten filtern\n\n\n\nErstellen Sie einen neuen Datensatz namens d_stroop_correct und filtern Sie diesen so dass er nur Trials mit richtigen Antworten enth√§lt. Schauen Sie in der Variable keyResp_test_run.corr, ob tats√§chlich nur noch richtige Antworten √ºbrig geblieben sind.\nAchtung: Arbeiten Sie in den weiteren Schritten nicht mit diesem Datensatz weiter, da wir die falschen Antworten in einem n√§chsten Schritt noch im Datensatz brauchen.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#variablen-ausw√§hlen-select",
    "href": "datawrangling.html#variablen-ausw√§hlen-select",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.7 Variablen ausw√§hlen: select()",
    "text": "9.7 Variablen ausw√§hlen: select()\nEin komplexer Datensatz mit sehr vielen Variablen wird oft f√ºr die Analyse aus Gr√ºnden der Einfachheit oder Anonymisierung reduziert. Das bedeutet, dass man sich die n√∂tigen Variablen herausliest, und nur mit diesem reduzierten Datensatz weiterarbeitet. Hierzu eignet sich die Funktion select() sehr gut: Mit select(.data, variablenname, ...) k√∂nnen die zu behaltenden Variablen ausgew√§hlt werden. Wird ein ! vor einen Variablennamen gesetzt, wird die Variable nicht behalten.\nMit select() k√∂nnen wir auch die Variablen sortieren und umbenennen, damit unser Datensatz so strukturiert ist, wie wir ihn gebrauchen k√∂nnen.\nBeispiele:\n\n# Variable word und color behalten ohne Pipe\nd_simpler &lt;- select(d_stroop, word, color)\n\n# Variable word und color behalten mit Pipe\nd_simpler &lt;- d_stroop |&gt; select(word, color)\n\n# alle Variablen ausser word behalten\nd_simpler &lt;- d_stroop |&gt; select(!word)\n\n# Variablennamen ver√§ndern\nd_simpler &lt;- d_stroop |&gt; select(newvariablename = word)\n\nSollen mehrere Variablen am St√ºck ausgew√§hlt werden, kann man die erste Variable in der Reihe (z.B. word) und die letzte in der Reihe (z.B. congruent) als word:congruent eingeben, dann werden auch alle dazwischen liegenden Variablen ausgew√§hlt.\n\n\n\n\n\n\nHands-on: Variablen ausw√§hlen\n\n\n\nSchauen Sie sich Ihren Datensatz an, welche Variablen ben√∂tigen Sie f√ºr die weitere Analysen?\nErstellen Sie einen neuen Datensatz d_stroop_clean in welchem Sie die entsprechenden Variablen ausw√§hlen und umbennen, wenn Sie Ihnen zu lange/kompliziert erscheinen.\nUntenstehend finden Sie ein Beispiel, wie der Datensatz danach aussehen k√∂nnte.\n\n\n\n\nRows: 120\nColumns: 10\n$ id         &lt;chr&gt; \"sub-154989\", \"sub-154989\", \"sub-154989\", \"sub-154989\", \"su‚Ä¶\n$ experiment &lt;chr&gt; \"stroop_test\", \"stroop_test\", \"stroop_test\", \"stroop_test\",‚Ä¶\n$ trial      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1‚Ä¶\n$ word       &lt;chr&gt; \"rot\", \"rot\", \"blau\", \"gelb\", \"rot\", \"blau\", \"blau\", \"gelb\"‚Ä¶\n$ color      &lt;chr&gt; \"red\", \"red\", \"blue\", \"yellow\", \"yellow\", \"yellow\", \"red\", ‚Ä¶\n$ corrAns    &lt;chr&gt; \"r\", \"r\", \"b\", \"g\", \"g\", \"g\", \"r\", \"r\", \"b\", \"g\", \"b\", \"b\",‚Ä¶\n$ congruent  &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,‚Ä¶\n$ response   &lt;chr&gt; \"r\", \"r\", \"b\", \"g\", \"g\", \"g\", \"r\", \"r\", \"b\", \"g\", \"b\", \"b\",‚Ä¶\n$ rt         &lt;dbl&gt; 1.0639791, 0.7370255, 1.1883303, 1.2007897, 1.6688681, 1.58‚Ä¶\n$ accuracy   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,‚Ä¶",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#neue-variablen-generieren-und-ver√§ndern-mutate-und-case_when",
    "href": "datawrangling.html#neue-variablen-generieren-und-ver√§ndern-mutate-und-case_when",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.8 Neue Variablen generieren und ver√§ndern: mutate() und case_when()",
    "text": "9.8 Neue Variablen generieren und ver√§ndern: mutate() und case_when()\nMit der mutate(.data, ‚Ä¶) Funktion k√∂nnen im Datensatz neue Variablen generiert oder bestehende ver√§ndert werden.\nBeispiel:\n\n# Neue Variablen erstellen\nd_new &lt;- d_stroop_clean |&gt;\n    mutate(num_variable = 1.434,\n           chr_variable = \"1.434\",\n           sumofxy_variable = rt + 1,\n           copy_variable = word)\n\n# Bestehende Variablen ver√§ndern\nd_new &lt;- d_new |&gt;\n    mutate(num_variable = num_variable * 1000) # z.B. um Sekunden zu Millisekunden zu machen\n\nMit case_when() kann eine neue Variable erstellt werden in Abh√§ngigkeit von Werten anderer Variablen. Damit kann z.B. eine Variable accuracy erstellt werden, die den Wert correct hat, wenn die Aufgabe richtig gel√∂st wurde (z.B. Bedingung rot und Tastendruck r) und sonst den Wert error hat.\nBeispiel:\n\nd_condvariable &lt;- d_stroop_clean |&gt;\n    mutate(cond_variable = case_when(rt &gt; 0.8 ~ \"higher\",\n                                     rt &lt;= 0.8 ~ \"lower\",\n                                     .default = NA))\n\n\n\n\n\n\n\nHands-on: Variablen generieren und ver√§ndern\n\n\n\n\nErstellen Sie im Datensatz d_stroop_clean eine neue Variable mit dem Namen researcher, den Ihren Namen enth√§lt.\nErstellen Sie zudem eine Variable accuracy_check, mit correct f√ºr korrekte und error f√ºr inkorrekte Trials. Kontrollieren Sie mit der Variable keyResp_test_run.corr (oder Ihrem neuen Variablennamen, wenn Sie diese umbenannt haben) im Datensatz, ob Sie die Aufgabe richtig gel√∂st haben.\n√Ñndern Sie die Trialnummer, so dass sie nicht mehr mit 0 beginnt, sondern mit 1.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#variablenklasse-ver√§ndern-as.factor-as.numeric",
    "href": "datawrangling.html#variablenklasse-ver√§ndern-as.factor-as.numeric",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.9 Variablenklasse ver√§ndern: as.factor(), as.numeric(), ‚Ä¶",
    "text": "9.9 Variablenklasse ver√§ndern: as.factor(), as.numeric(), ‚Ä¶\nVariablen k√∂nnen verschiedene Klassen haben, sie k√∂nnen z.B. kategoriale (factor, character) oder numerische (integer, numeric, double) Informationen enthalten. Beim Einlesen ‚Äúr√§t‚Äù R, welche Klasse eine Variable hat. Teilweise m√∂chten wir dies √§ndern. Wenn wir eine Variable zu einem Faktor machen m√∂chten, verwenden wir as.factor(). Dies macht z.B. Sinn, wenn die Versuchspersonennummer als Zahl eingelesen wurde. Um von einem Faktor zu einer numerischen Variable zu kommen, verwenden wir as.numeric().\n\n# Die Variable \"congruent\" zu einem Faktor machen\nd_stroop_clean |&gt; \n    mutate(congruent = as.factor(congruent))\n\n\n\n\n\n\n\nHands-on: Variablenklassen\n\n\n\nSchauen Sie sich den Datensatz mit glimpse() oder mit View() an. Welche Klassen enth√§lt Ihr Datensatz und was bedeuten Sie?",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "href": "datawrangling.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.10 Daten gruppieren und zusammenfassen: group_by() und summarise()",
    "text": "9.10 Daten gruppieren und zusammenfassen: group_by() und summarise()\nMit diesen beiden Funktionen k√∂nnen wir mit wenig Code den Datensatz gruppieren und zusammenfassen.\n\n# Nach W√∂rter gruppieren\nd_stroop_clean |&gt; group_by(word) |&gt;\n    summarise(mean_rt = mean(rt),\n              sd_rt = sd(rt))\n\n# A tibble: 3 √ó 3\n  word  mean_rt sd_rt\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 blau     1.23 0.490\n2 gelb     1.26 0.447\n3 rot      1.16 0.552\n\n\n\n\n\n\n\n\nHands-on: Daten zusammenfassen\n\n\n\nErstellen Sie einen neuen Datensatz d_stroop_summary\n\nGruppieren Sie den Datensatz f√ºr Wortfarbe und Kongruenz.\nFassen Sie f√ºr diese Gruppen die durchschnittliche Antwortzeit und Accuracy sowie die Standardabweichungen zusammen.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#datens√§tze-speichern-write.csv",
    "href": "datawrangling.html#datens√§tze-speichern-write.csv",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.11 Datens√§tze speichern: write.csv()",
    "text": "9.11 Datens√§tze speichern: write.csv()\n\nwrite.csv(d_stroop_clean, file = \"data/dataset_stroop_clean.csv\", row.names = FALSE)\n\n\n\n\n\n\n\nHands-on: Datens√§tze speichern\n\n\n\nSpeichern Sie einen neuen Datensatz mit den vorverarbeiteten Daten.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#data-wrangling-workflow-implementieren",
    "href": "datawrangling.html#data-wrangling-workflow-implementieren",
    "title": "9¬† Daten importieren und vorverarbeiten",
    "section": "9.12 Data wrangling workflow implementieren",
    "text": "9.12 Data wrangling workflow implementieren\n\n\n\n\n\n\nHands-on: Data wrangling workflow\n\n\n\nErstellen Sie nun ein Projekt f√ºr das Random-Dot Experiment und f√ºhren Sie die gelernten data wrangling Schritte selbstst√§ndig durch.\n\n\n\nZu den gelernten Funktionen finden Sie hier Grafiken die evtl. helfen, sich die Funktions-Namen zu merken.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html",
    "href": "datawrangling_automatisiert.html",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "",
    "text": "10.1 Setup\n# Package laden (bei jedem √ñffnen von R zu Beginn des Skripts ausf√ºhren)\nlibrary(\"tidyverse\")",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#stroop-experiment-data-wrangling",
    "href": "datawrangling_automatisiert.html#stroop-experiment-data-wrangling",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "10.2 Stroop-Experiment data wrangling",
    "text": "10.2 Stroop-Experiment data wrangling\n\n# Daten vorverarbeiten\ndata_stroop &lt;- read_csv(\"data/stroop_example2.csv\")\nglimpse(data_stroop)\n\nd_stroop &lt;- read_csv(\"data/stroop_example2.csv\") |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color,\n           congruent,\n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#daten-mit-eigener-funktion-einlesen",
    "href": "datawrangling_automatisiert.html#daten-mit-eigener-funktion-einlesen",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "10.3 Daten mit eigener Funktion einlesen",
    "text": "10.3 Daten mit eigener Funktion einlesen\n\nread_stroop &lt;- function(path){\n    # Code kopiert von oben\n    d_stroop &lt;- read_csv(path) |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color, \n           congruent, \n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)\n    # ---------------------\n    return(d_stroop)\n}\n\nd_stroop_fun &lt;- read_stroop(path = \"data/stroop_example2.csv\")\n\nRows: 161 Columns: 92\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (26): wordCTK, colorCTK, corrAnsCTK, wordPractice, colorPractice, corrAn...\ndbl (65): congruentCTK, congruentPractice, congruent, trials_CTK.thisRepN, t...\nlgl  (1): notes\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\nHands-on 1: Eigene Funktion schreiben\n\n\n\nSchreiben Sie eine Funktion, die nur reaction times von &lt;0.5 w√§hlt, und den Prozent von korrekten Antworten ausgibt.\n\nfast_correct &lt;- function(data){\n    ___ # Code einf√ºgen\n}\n\nfast_correct(d_stroop)",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#einlesen-automatisieren",
    "href": "datawrangling_automatisiert.html#einlesen-automatisieren",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "10.4 Einlesen Automatisieren",
    "text": "10.4 Einlesen Automatisieren\nWir ben√∂tigen eine Liste aller Datenfiles. Die Funktion list.files() gibt einer Liste aller Dokumente in einem Ordner zur√ºck. Mit dem Argument pattern = ... kann spezifiziert werden, welche Buchstaben(folgen) der Filenamen entahlten soll.\n\nlist.files(path = 'data/raw')\n\n  [1] \"sub-001_random_dot.csv\"  \"sub-001_stroop_test.csv\"\n  [3] \"sub-002_random_dot.csv\"  \"sub-002_stroop_test.csv\"\n  [5] \"sub-003_random_dot.csv\"  \"sub-003_stroop_test.csv\"\n  [7] \"sub-004_random_dot.csv\"  \"sub-004_stroop_test.csv\"\n  [9] \"sub-005_random_dot.csv\"  \"sub-005_stroop_test.csv\"\n [11] \"sub-006_random_dot.csv\"  \"sub-006_stroop_test.csv\"\n [13] \"sub-007_random_dot.csv\"  \"sub-007_stroop_test.csv\"\n [15] \"sub-008_random_dot.csv\"  \"sub-008_stroop_test.csv\"\n [17] \"sub-009_random_dot.csv\"  \"sub-009_stroop_test.csv\"\n [19] \"sub-010_random_dot.csv\"  \"sub-010_stroop_test.csv\"\n [21] \"sub-011_random_dot.csv\"  \"sub-011_stroop_test.csv\"\n [23] \"sub-012_random_dot.csv\"  \"sub-012_stroop_test.csv\"\n [25] \"sub-013_random_dot.csv\"  \"sub-013_stroop_test.csv\"\n [27] \"sub-014_random_dot.csv\"  \"sub-014_stroop_test.csv\"\n [29] \"sub-015_random_dot.csv\"  \"sub-015_stroop_test.csv\"\n [31] \"sub-016_random_dot.csv\"  \"sub-016_stroop_test.csv\"\n [33] \"sub-017_random_dot.csv\"  \"sub-017_stroop_test.csv\"\n [35] \"sub-018_random_dot.csv\"  \"sub-018_stroop_test.csv\"\n [37] \"sub-019_random_dot.csv\"  \"sub-019_stroop_test.csv\"\n [39] \"sub-020_random_dot.csv\"  \"sub-020_stroop_test.csv\"\n [41] \"sub-021_random_dot.csv\"  \"sub-021_stroop_test.csv\"\n [43] \"sub-022_random_dot.csv\"  \"sub-022_stroop_test.csv\"\n [45] \"sub-023_random_dot.csv\"  \"sub-023_stroop_test.csv\"\n [47] \"sub-024_random_dot.csv\"  \"sub-024_stroop_test.csv\"\n [49] \"sub-025_random_dot.csv\"  \"sub-025_stroop_test.csv\"\n [51] \"sub-026_random_dot.csv\"  \"sub-026_stroop_test.csv\"\n [53] \"sub-027_random_dot.csv\"  \"sub-027_stroop_test.csv\"\n [55] \"sub-028_random_dot.csv\"  \"sub-028_stroop_test.csv\"\n [57] \"sub-029_random_dot.csv\"  \"sub-029_stroop_test.csv\"\n [59] \"sub-030_random_dot.csv\"  \"sub-030_stroop_test.csv\"\n [61] \"sub-031_random_dot.csv\"  \"sub-031_stroop_test.csv\"\n [63] \"sub-032_random_dot.csv\"  \"sub-032_stroop_test.csv\"\n [65] \"sub-033_random_dot.csv\"  \"sub-033_stroop_test.csv\"\n [67] \"sub-034_random_dot.csv\"  \"sub-034_stroop_test.csv\"\n [69] \"sub-035_random_dot.csv\"  \"sub-035_stroop_test.csv\"\n [71] \"sub-036_random_dot.csv\"  \"sub-036_stroop_test.csv\"\n [73] \"sub-037_random_dot.csv\"  \"sub-037_stroop_test.csv\"\n [75] \"sub-038_random_dot.csv\"  \"sub-038_stroop_test.csv\"\n [77] \"sub-039_random_dot.csv\"  \"sub-040_random_dot.csv\" \n [79] \"sub-040_stroop_test.csv\" \"sub-041_random_dot.csv\" \n [81] \"sub-041_stroop_test.csv\" \"sub-042_random_dot.csv\" \n [83] \"sub-042_stroop_test.csv\" \"sub-043_random_dot.csv\" \n [85] \"sub-043_stroop_test.csv\" \"sub-044_random_dot.csv\" \n [87] \"sub-044_stroop_test.csv\" \"sub-045_random_dot.csv\" \n [89] \"sub-045_stroop_test.csv\" \"sub-046_random_dot.csv\" \n [91] \"sub-046_stroop_test.csv\" \"sub-047_random_dot.csv\" \n [93] \"sub-047_stroop_test.csv\" \"sub-048_random_dot.csv\" \n [95] \"sub-048_stroop_test.csv\" \"sub-049_random_dot.csv\" \n [97] \"sub-049_stroop_test.csv\" \"sub-050_random_dot.csv\" \n [99] \"sub-050_stroop_test.csv\" \"sub-051_random_dot.csv\" \n[101] \"sub-051_stroop_test.csv\" \"sub-052_random_dot.csv\" \n[103] \"sub-052_stroop_test.csv\" \"sub-053_random_dot.csv\" \n[105] \"sub-053_stroop_test.csv\" \"sub-054_random_dot.csv\" \n[107] \"sub-054_stroop_test.csv\" \"sub-055_random_dot.csv\" \n[109] \"sub-055_stroop_test.csv\" \"sub-056_random_dot.csv\" \n[111] \"sub-057_random_dot.csv\"  \"sub-057_stroop_test.csv\"\n[113] \"sub-058_random_dot.csv\"  \"sub-058_stroop_test.csv\"\n[115] \"sub-059_random_dot.csv\"  \"sub-059_stroop_test.csv\"\n[117] \"sub-060_random_dot.csv\"  \"sub-060_stroop_test.csv\"\n[119] \"sub-061_random_dot.csv\"  \"sub-061_stroop_test.csv\"\n[121] \"sub-062_random_dot.csv\"  \"sub-062_stroop_test.csv\"\n[123] \"sub-063_random_dot.csv\"  \"sub-063_stroop_test.csv\"\n[125] \"sub-064_random_dot.csv\"  \"sub-064_stroop_test.csv\"\n[127] \"sub-065_random_dot.csv\"  \"sub-065_stroop_test.csv\"\n[129] \"sub-066_random_dot.csv\"  \"sub-066_stroop_test.csv\"\n[131] \"sub-067_random_dot.csv\"  \"sub-067_stroop_test.csv\"\n[133] \"sub-068_random_dot.csv\"  \"sub-068_stroop_test.csv\"\n[135] \"sub-069_random_dot.csv\"  \"sub-069_stroop_test.csv\"\n[137] \"sub-070_random_dot.csv\"  \"sub-070_stroop_test.csv\"\n[139] \"sub-071_random_dot.csv\"  \"sub-071_stroop_test.csv\"\n[141] \"sub-072_random_dot.csv\"  \"sub-072_stroop_test.csv\"\n[143] \"sub-073_random_dot.csv\"  \"sub-073_stroop_test.csv\"\n[145] \"sub-074_random_dot.csv\"  \"sub-074_stroop_test.csv\"\n[147] \"sub-075_random_dot.csv\"  \"sub-075_stroop_test.csv\"\n[149] \"sub-076_random_dot.csv\"  \"sub-076_stroop_test.csv\"\n[151] \"sub-077_random_dot.csv\"  \"sub-077_stroop_test.csv\"\n[153] \"sub-078_random_dot.csv\"  \"sub-078_stroop_test.csv\"\n[155] \"sub-079_random_dot.csv\"  \"sub-079_stroop_test.csv\"\n[157] \"sub-080_random_dot.csv\"  \"sub-080_stroop_test.csv\"\n[159] \"sub-081_random_dot.csv\"  \"sub-082_random_dot.csv\" \n[161] \"sub-082_stroop_test.csv\" \"sub-083_random_dot.csv\" \n[163] \"sub-083_stroop_test.csv\" \"sub-084_random_dot.csv\" \n[165] \"sub-084_stroop_test.csv\" \"sub-085_random_dot.csv\" \n[167] \"sub-085_stroop_test.csv\" \"sub-086_random_dot.csv\" \n[169] \"sub-086_stroop_test.csv\" \"sub-087_random_dot.csv\" \n[171] \"sub-087_stroop_test.csv\" \"sub-088_random_dot.csv\" \n[173] \"sub-088_stroop_test.csv\" \"sub-089_random_dot.csv\" \n[175] \"sub-089_stroop_test.csv\" \"sub-090_random_dot.csv\" \n[177] \"sub-090_stroop_test.csv\" \"sub-091_random_dot.csv\" \n[179] \"sub-091_stroop_test.csv\" \"sub-092_random_dot.csv\" \n[181] \"sub-092_stroop_test.csv\" \"sub-093_random_dot.csv\" \n[183] \"sub-093_stroop_test.csv\" \"sub-094_stroop_test.csv\"\n[185] \"sub-095_random_dot.csv\"  \"sub-095_stroop_test.csv\"\n[187] \"sub-096_random_dot.csv\"  \"sub-096_stroop_test.csv\"\n[189] \"sub-097_random_dot.csv\"  \"sub-097_stroop_test.csv\"\n[191] \"sub-098_random_dot.csv\"  \"sub-098_stroop_test.csv\"\n[193] \"sub-099_random_dot.csv\"  \"sub-099_stroop_test.csv\"\n[195] \"sub-100_random_dot.csv\"  \"sub-100_stroop_test.csv\"\n[197] \"sub-101_random_dot.csv\"  \"sub-101_stroop_test.csv\"\n[199] \"sub-102_random_dot.csv\"  \"sub-102_stroop_test.csv\"\n[201] \"sub-103_random_dot.csv\"  \"sub-103_stroop_test.csv\"\n[203] \"sub-104_random_dot.csv\"  \"sub-104_stroop_test.csv\"\n[205] \"sub-105_random_dot.csv\"  \"sub-105_stroop_test.csv\"\n[207] \"sub-106_random_dot.csv\"  \"sub-106_stroop_test.csv\"\n[209] \"sub-107_random_dot.csv\"  \"sub-107_stroop_test.csv\"\n[211] \"sub-108_random_dot.csv\"  \"sub-108_stroop_test.csv\"\n[213] \"sub-109_random_dot.csv\"  \"sub-109_stroop_test.csv\"\n[215] \"sub-110_random_dot.csv\"  \"sub-110_stroop_test.csv\"\n[217] \"sub-111_random_dot.csv\"  \"sub-111_stroop_test.csv\"\n[219] \"sub-112_random_dot.csv\"  \"sub-112_stroop_test.csv\"\n[221] \"sub-113_random_dot.csv\"  \"sub-113_stroop_test.csv\"\n[223] \"sub-114_random_dot.csv\"  \"sub-114_stroop_test.csv\"\n[225] \"sub-115_random_dot.csv\"  \"sub-115_stroop_test.csv\"\n[227] \"sub-116_random_dot.csv\"  \"sub-116_stroop_test.csv\"\n[229] \"sub-117_random_dot.csv\"  \"sub-117_stroop_test.csv\"\n[231] \"sub-118_random_dot.csv\"  \"sub-118_stroop_test.csv\"\n[233] \"sub-119_random_dot.csv\"  \"sub-119_stroop_test.csv\"\n[235] \"sub-120_random_dot.csv\"  \"sub-120_stroop_test.csv\"\n[237] \"sub-121_random_dot.csv\"  \"sub-121_stroop_test.csv\"\n[239] \"sub-122_random_dot.csv\"  \"sub-122_stroop_test.csv\"\n[241] \"sub-123_random_dot.csv\"  \"sub-123_stroop_test.csv\"\n[243] \"sub-124_random_dot.csv\"  \"sub-124_stroop_test.csv\"\n[245] \"sub-125_random_dot.csv\"  \"sub-125_stroop_test.csv\"\n[247] \"sub-126_random_dot.csv\"  \"sub-126_stroop_test.csv\"\n[249] \"sub-127_random_dot.csv\"  \"sub-127_stroop_test.csv\"\n[251] \"sub-128_random_dot.csv\"  \"sub-128_stroop_test.csv\"\n[253] \"sub-129_random_dot.csv\"  \"sub-129_stroop_test.csv\"\n[255] \"sub-130_random_dot.csv\"  \"sub-130_stroop_test.csv\"\n[257] \"sub-131_random_dot.csv\"  \"sub-131_stroop_test.csv\"\n[259] \"sub-132_random_dot.csv\"  \"sub-132_stroop_test.csv\"\n[261] \"sub-133_random_dot.csv\"  \"sub-133_stroop_test.csv\"\n[263] \"sub-134_random_dot.csv\"  \"sub-134_stroop_test.csv\"\n[265] \"sub-135_random_dot.csv\"  \"sub-135_stroop_test.csv\"\n[267] \"sub-136_random_dot.csv\"  \"sub-136_stroop_test.csv\"\n[269] \"sub-137_random_dot.csv\"  \"sub-137_stroop_test.csv\"\n[271] \"sub-138_random_dot.csv\"  \"sub-138_stroop_test.csv\"\n[273] \"sub-139_random_dot.csv\"  \"sub-139_stroop_test.csv\"\n[275] \"sub-140_random_dot.csv\"  \"sub-140_stroop_test.csv\"\n[277] \"sub-141_random_dot.csv\"  \"sub-141_stroop_test.csv\"\n[279] \"sub-142_random_dot.csv\"  \"sub-142_stroop_test.csv\"\n[281] \"sub-143_random_dot.csv\"  \"sub-143_stroop_test.csv\"\n[283] \"sub-144_random_dot.csv\"  \"sub-144_stroop_test.csv\"\n[285] \"sub-145_random_dot.csv\"  \"sub-145_stroop_test.csv\"\n[287] \"sub-146_random_dot.csv\"  \"sub-146_stroop_test.csv\"\n[289] \"sub-147_random_dot.csv\"  \"sub-147_stroop_test.csv\"\n[291] \"sub-148_random_dot.csv\"  \"sub-148_stroop_test.csv\"\n[293] \"sub-149_random_dot.csv\"  \"sub-149_stroop_test.csv\"\n[295] \"sub-150_random_dot.csv\"  \"sub-150_stroop_test.csv\"\n[297] \"sub-151_random_dot.csv\"  \"sub-151_stroop_test.csv\"\n[299] \"sub-152_random_dot.csv\"  \"sub-152_stroop_test.csv\"\n[301] \"sub-153_random_dot.csv\"  \"sub-153_stroop_test.csv\"\n[303] \"sub-154_random_dot.csv\"  \"sub-154_stroop_test.csv\"\n[305] \"sub-155_random_dot.csv\"  \"sub-155_stroop_test.csv\"\n[307] \"sub-156_random_dot.csv\"  \"sub-156_stroop_test.csv\"\n[309] \"sub-157_random_dot.csv\"  \"sub-157_stroop_test.csv\"\n[311] \"sub-158_random_dot.csv\"  \"sub-158_stroop_test.csv\"\n[313] \"sub-159_random_dot.csv\"  \"sub-159_stroop_test.csv\"\n[315] \"sub-160_random_dot.csv\"  \"sub-160_stroop_test.csv\"\n[317] \"sub-161_random_dot.csv\"  \"sub-161_stroop_test.csv\"\n[319] \"sub-162_random_dot.csv\"  \"sub-162_stroop_test.csv\"\n[321] \"sub-163_random_dot.csv\"  \"sub-163_stroop_test.csv\"\n[323] \"sub-164_random_dot.csv\"  \"sub-164_stroop_test.csv\"\n[325] \"sub-165_random_dot.csv\"  \"sub-165_stroop_test.csv\"\n[327] \"sub-166_random_dot.csv\"  \"sub-167_random_dot.csv\" \n[329] \"sub-167_stroop_test.csv\" \"sub-168_random_dot.csv\" \n[331] \"sub-168_stroop_test.csv\" \"sub-169_random_dot.csv\" \n[333] \"sub-169_stroop_test.csv\" \"sub-170_random_dot.csv\" \n[335] \"sub-170_stroop_test.csv\" \"sub-171_random_dot.csv\" \n[337] \"sub-171_stroop_test.csv\" \"sub-172_random_dot.csv\" \n[339] \"sub-172_stroop_test.csv\" \"sub-173_random_dot.csv\" \n[341] \"sub-173_stroop_test.csv\" \"sub-174_random_dot.csv\" \n[343] \"sub-174_stroop_test.csv\" \"sub-175_random_dot.csv\" \n[345] \"sub-175_stroop_test.csv\" \"sub-176_random_dot.csv\" \n[347] \"sub-176_stroop_test.csv\" \"sub-177_random_dot.csv\" \n[349] \"sub-177_stroop_test.csv\" \"sub-178_random_dot.csv\" \n[351] \"sub-178_stroop_test.csv\" \"sub-179_random_dot.csv\" \n[353] \"sub-179_stroop_test.csv\" \"sub-180_random_dot.csv\" \n[355] \"sub-180_stroop_test.csv\" \"sub-181_random_dot.csv\" \n[357] \"sub-181_stroop_test.csv\" \"sub-182_random_dot.csv\" \n[359] \"sub-182_stroop_test.csv\" \"sub-183_random_dot.csv\" \n[361] \"sub-183_stroop_test.csv\" \"sub-184_random_dot.csv\" \n[363] \"sub-184_stroop_test.csv\" \"sub-185_random_dot.csv\" \n[365] \"sub-185_stroop_test.csv\" \"sub-186_random_dot.csv\" \n[367] \"sub-186_stroop_test.csv\" \"sub-187_random_dot.csv\" \n[369] \"sub-187_stroop_test.csv\" \"sub-188_random_dot.csv\" \n[371] \"sub-188_stroop_test.csv\" \"sub-189_random_dot.csv\" \n[373] \"sub-189_stroop_test.csv\" \"sub-190_random_dot.csv\" \n[375] \"sub-190_stroop_test.csv\" \"sub-191_random_dot.csv\" \n[377] \"sub-191_stroop_test.csv\" \"sub-192_random_dot.csv\" \n[379] \"sub-192_stroop_test.csv\" \"sub-193_random_dot.csv\" \n[381] \"sub-193_stroop_test.csv\" \"sub-194_random_dot.csv\" \n[383] \"sub-194_stroop_test.csv\" \"sub-195_random_dot.csv\" \n[385] \"sub-195_stroop_test.csv\" \"sub-196_random_dot.csv\" \n[387] \"sub-196_stroop_test.csv\" \"sub-197_random_dot.csv\" \n[389] \"sub-197_stroop_test.csv\" \"sub-198_random_dot.csv\" \n[391] \"sub-198_stroop_test.csv\" \"sub-199_random_dot.csv\" \n[393] \"sub-199_stroop_test.csv\" \"sub-200_random_dot.csv\" \n[395] \"sub-200_stroop_test.csv\" \"sub-201_random_dot.csv\" \n[397] \"sub-201_stroop_test.csv\" \"sub-202_random_dot.csv\" \n[399] \"sub-202_stroop_test.csv\" \"sub-203_random_dot.csv\" \n[401] \"sub-203_stroop_test.csv\" \"sub-204_random_dot.csv\" \n[403] \"sub-204_stroop_test.csv\" \"sub-205_random_dot.csv\" \n[405] \"sub-205_stroop_test.csv\" \"sub-206_random_dot.csv\" \n[407] \"sub-206_stroop_test.csv\" \"sub-207_random_dot.csv\" \n[409] \"sub-207_stroop_test.csv\" \"sub-208_random_dot.csv\" \n[411] \"sub-208_stroop_test.csv\" \"sub-209_random_dot.csv\" \n[413] \"sub-209_stroop_test.csv\" \"sub-210_random_dot.csv\" \n[415] \"sub-210_stroop_test.csv\" \"sub-211_random_dot.csv\" \n[417] \"sub-211_stroop_test.csv\" \"sub-212_random_dot.csv\" \n[419] \"sub-212_stroop_test.csv\" \"sub-213_random_dot.csv\" \n[421] \"sub-213_stroop_test.csv\" \"sub-214_random_dot.csv\" \n[423] \"sub-214_stroop_test.csv\" \"sub-215_random_dot.csv\" \n[425] \"sub-215_stroop_test.csv\" \"sub-216_random_dot.csv\" \n[427] \"sub-216_stroop_test.csv\" \"sub-217_random_dot.csv\" \n[429] \"sub-217_stroop_test.csv\" \"sub-218_random_dot.csv\" \n[431] \"sub-218_stroop_test.csv\" \"sub-219_random_dot.csv\" \n[433] \"sub-219_stroop_test.csv\" \"sub-220_random_dot.csv\" \n[435] \"sub-220_stroop_test.csv\" \"sub-221_random_dot.csv\" \n[437] \"sub-221_stroop_test.csv\" \"sub-222_random_dot.csv\" \n[439] \"sub-222_stroop_test.csv\" \"sub-223_random_dot.csv\" \n[441] \"sub-223_stroop_test.csv\" \"sub-224_random_dot.csv\" \n[443] \"sub-224_stroop_test.csv\" \"sub-225_random_dot.csv\" \n[445] \"sub-225_stroop_test.csv\" \"sub-226_random_dot.csv\" \n[447] \"sub-226_stroop_test.csv\" \"sub-227_random_dot.csv\" \n[449] \"sub-227_stroop_test.csv\" \"sub-228_random_dot.csv\" \n[451] \"sub-228_stroop_test.csv\" \"sub-229_random_dot.csv\" \n[453] \"sub-229_stroop_test.csv\" \"sub-230_random_dot.csv\" \n[455] \"sub-230_stroop_test.csv\" \"sub-231_random_dot.csv\" \n[457] \"sub-231_stroop_test.csv\" \"sub-232_random_dot.csv\" \n[459] \"sub-232_stroop_test.csv\" \"sub-233_random_dot.csv\" \n[461] \"sub-233_stroop_test.csv\" \"sub-234_random_dot.csv\" \n[463] \"sub-234_stroop_test.csv\" \"sub-235_random_dot.csv\" \n[465] \"sub-235_stroop_test.csv\" \"sub-236_random_dot.csv\" \n[467] \"sub-236_stroop_test.csv\" \"sub-237_random_dot.csv\" \n[469] \"sub-237_stroop_test.csv\" \"sub-238_random_dot.csv\" \n[471] \"sub-238_stroop_test.csv\" \"sub-239_random_dot.csv\" \n[473] \"sub-240_random_dot.csv\" \n\nlist.files(path = 'data/raw', pattern = 'stroop')\n\n  [1] \"sub-001_stroop_test.csv\" \"sub-002_stroop_test.csv\"\n  [3] \"sub-003_stroop_test.csv\" \"sub-004_stroop_test.csv\"\n  [5] \"sub-005_stroop_test.csv\" \"sub-006_stroop_test.csv\"\n  [7] \"sub-007_stroop_test.csv\" \"sub-008_stroop_test.csv\"\n  [9] \"sub-009_stroop_test.csv\" \"sub-010_stroop_test.csv\"\n [11] \"sub-011_stroop_test.csv\" \"sub-012_stroop_test.csv\"\n [13] \"sub-013_stroop_test.csv\" \"sub-014_stroop_test.csv\"\n [15] \"sub-015_stroop_test.csv\" \"sub-016_stroop_test.csv\"\n [17] \"sub-017_stroop_test.csv\" \"sub-018_stroop_test.csv\"\n [19] \"sub-019_stroop_test.csv\" \"sub-020_stroop_test.csv\"\n [21] \"sub-021_stroop_test.csv\" \"sub-022_stroop_test.csv\"\n [23] \"sub-023_stroop_test.csv\" \"sub-024_stroop_test.csv\"\n [25] \"sub-025_stroop_test.csv\" \"sub-026_stroop_test.csv\"\n [27] \"sub-027_stroop_test.csv\" \"sub-028_stroop_test.csv\"\n [29] \"sub-029_stroop_test.csv\" \"sub-030_stroop_test.csv\"\n [31] \"sub-031_stroop_test.csv\" \"sub-032_stroop_test.csv\"\n [33] \"sub-033_stroop_test.csv\" \"sub-034_stroop_test.csv\"\n [35] \"sub-035_stroop_test.csv\" \"sub-036_stroop_test.csv\"\n [37] \"sub-037_stroop_test.csv\" \"sub-038_stroop_test.csv\"\n [39] \"sub-040_stroop_test.csv\" \"sub-041_stroop_test.csv\"\n [41] \"sub-042_stroop_test.csv\" \"sub-043_stroop_test.csv\"\n [43] \"sub-044_stroop_test.csv\" \"sub-045_stroop_test.csv\"\n [45] \"sub-046_stroop_test.csv\" \"sub-047_stroop_test.csv\"\n [47] \"sub-048_stroop_test.csv\" \"sub-049_stroop_test.csv\"\n [49] \"sub-050_stroop_test.csv\" \"sub-051_stroop_test.csv\"\n [51] \"sub-052_stroop_test.csv\" \"sub-053_stroop_test.csv\"\n [53] \"sub-054_stroop_test.csv\" \"sub-055_stroop_test.csv\"\n [55] \"sub-057_stroop_test.csv\" \"sub-058_stroop_test.csv\"\n [57] \"sub-059_stroop_test.csv\" \"sub-060_stroop_test.csv\"\n [59] \"sub-061_stroop_test.csv\" \"sub-062_stroop_test.csv\"\n [61] \"sub-063_stroop_test.csv\" \"sub-064_stroop_test.csv\"\n [63] \"sub-065_stroop_test.csv\" \"sub-066_stroop_test.csv\"\n [65] \"sub-067_stroop_test.csv\" \"sub-068_stroop_test.csv\"\n [67] \"sub-069_stroop_test.csv\" \"sub-070_stroop_test.csv\"\n [69] \"sub-071_stroop_test.csv\" \"sub-072_stroop_test.csv\"\n [71] \"sub-073_stroop_test.csv\" \"sub-074_stroop_test.csv\"\n [73] \"sub-075_stroop_test.csv\" \"sub-076_stroop_test.csv\"\n [75] \"sub-077_stroop_test.csv\" \"sub-078_stroop_test.csv\"\n [77] \"sub-079_stroop_test.csv\" \"sub-080_stroop_test.csv\"\n [79] \"sub-082_stroop_test.csv\" \"sub-083_stroop_test.csv\"\n [81] \"sub-084_stroop_test.csv\" \"sub-085_stroop_test.csv\"\n [83] \"sub-086_stroop_test.csv\" \"sub-087_stroop_test.csv\"\n [85] \"sub-088_stroop_test.csv\" \"sub-089_stroop_test.csv\"\n [87] \"sub-090_stroop_test.csv\" \"sub-091_stroop_test.csv\"\n [89] \"sub-092_stroop_test.csv\" \"sub-093_stroop_test.csv\"\n [91] \"sub-094_stroop_test.csv\" \"sub-095_stroop_test.csv\"\n [93] \"sub-096_stroop_test.csv\" \"sub-097_stroop_test.csv\"\n [95] \"sub-098_stroop_test.csv\" \"sub-099_stroop_test.csv\"\n [97] \"sub-100_stroop_test.csv\" \"sub-101_stroop_test.csv\"\n [99] \"sub-102_stroop_test.csv\" \"sub-103_stroop_test.csv\"\n[101] \"sub-104_stroop_test.csv\" \"sub-105_stroop_test.csv\"\n[103] \"sub-106_stroop_test.csv\" \"sub-107_stroop_test.csv\"\n[105] \"sub-108_stroop_test.csv\" \"sub-109_stroop_test.csv\"\n[107] \"sub-110_stroop_test.csv\" \"sub-111_stroop_test.csv\"\n[109] \"sub-112_stroop_test.csv\" \"sub-113_stroop_test.csv\"\n[111] \"sub-114_stroop_test.csv\" \"sub-115_stroop_test.csv\"\n[113] \"sub-116_stroop_test.csv\" \"sub-117_stroop_test.csv\"\n[115] \"sub-118_stroop_test.csv\" \"sub-119_stroop_test.csv\"\n[117] \"sub-120_stroop_test.csv\" \"sub-121_stroop_test.csv\"\n[119] \"sub-122_stroop_test.csv\" \"sub-123_stroop_test.csv\"\n[121] \"sub-124_stroop_test.csv\" \"sub-125_stroop_test.csv\"\n[123] \"sub-126_stroop_test.csv\" \"sub-127_stroop_test.csv\"\n[125] \"sub-128_stroop_test.csv\" \"sub-129_stroop_test.csv\"\n[127] \"sub-130_stroop_test.csv\" \"sub-131_stroop_test.csv\"\n[129] \"sub-132_stroop_test.csv\" \"sub-133_stroop_test.csv\"\n[131] \"sub-134_stroop_test.csv\" \"sub-135_stroop_test.csv\"\n[133] \"sub-136_stroop_test.csv\" \"sub-137_stroop_test.csv\"\n[135] \"sub-138_stroop_test.csv\" \"sub-139_stroop_test.csv\"\n[137] \"sub-140_stroop_test.csv\" \"sub-141_stroop_test.csv\"\n[139] \"sub-142_stroop_test.csv\" \"sub-143_stroop_test.csv\"\n[141] \"sub-144_stroop_test.csv\" \"sub-145_stroop_test.csv\"\n[143] \"sub-146_stroop_test.csv\" \"sub-147_stroop_test.csv\"\n[145] \"sub-148_stroop_test.csv\" \"sub-149_stroop_test.csv\"\n[147] \"sub-150_stroop_test.csv\" \"sub-151_stroop_test.csv\"\n[149] \"sub-152_stroop_test.csv\" \"sub-153_stroop_test.csv\"\n[151] \"sub-154_stroop_test.csv\" \"sub-155_stroop_test.csv\"\n[153] \"sub-156_stroop_test.csv\" \"sub-157_stroop_test.csv\"\n[155] \"sub-158_stroop_test.csv\" \"sub-159_stroop_test.csv\"\n[157] \"sub-160_stroop_test.csv\" \"sub-161_stroop_test.csv\"\n[159] \"sub-162_stroop_test.csv\" \"sub-163_stroop_test.csv\"\n[161] \"sub-164_stroop_test.csv\" \"sub-165_stroop_test.csv\"\n[163] \"sub-167_stroop_test.csv\" \"sub-168_stroop_test.csv\"\n[165] \"sub-169_stroop_test.csv\" \"sub-170_stroop_test.csv\"\n[167] \"sub-171_stroop_test.csv\" \"sub-172_stroop_test.csv\"\n[169] \"sub-173_stroop_test.csv\" \"sub-174_stroop_test.csv\"\n[171] \"sub-175_stroop_test.csv\" \"sub-176_stroop_test.csv\"\n[173] \"sub-177_stroop_test.csv\" \"sub-178_stroop_test.csv\"\n[175] \"sub-179_stroop_test.csv\" \"sub-180_stroop_test.csv\"\n[177] \"sub-181_stroop_test.csv\" \"sub-182_stroop_test.csv\"\n[179] \"sub-183_stroop_test.csv\" \"sub-184_stroop_test.csv\"\n[181] \"sub-185_stroop_test.csv\" \"sub-186_stroop_test.csv\"\n[183] \"sub-187_stroop_test.csv\" \"sub-188_stroop_test.csv\"\n[185] \"sub-189_stroop_test.csv\" \"sub-190_stroop_test.csv\"\n[187] \"sub-191_stroop_test.csv\" \"sub-192_stroop_test.csv\"\n[189] \"sub-193_stroop_test.csv\" \"sub-194_stroop_test.csv\"\n[191] \"sub-195_stroop_test.csv\" \"sub-196_stroop_test.csv\"\n[193] \"sub-197_stroop_test.csv\" \"sub-198_stroop_test.csv\"\n[195] \"sub-199_stroop_test.csv\" \"sub-200_stroop_test.csv\"\n[197] \"sub-201_stroop_test.csv\" \"sub-202_stroop_test.csv\"\n[199] \"sub-203_stroop_test.csv\" \"sub-204_stroop_test.csv\"\n[201] \"sub-205_stroop_test.csv\" \"sub-206_stroop_test.csv\"\n[203] \"sub-207_stroop_test.csv\" \"sub-208_stroop_test.csv\"\n[205] \"sub-209_stroop_test.csv\" \"sub-210_stroop_test.csv\"\n[207] \"sub-211_stroop_test.csv\" \"sub-212_stroop_test.csv\"\n[209] \"sub-213_stroop_test.csv\" \"sub-214_stroop_test.csv\"\n[211] \"sub-215_stroop_test.csv\" \"sub-216_stroop_test.csv\"\n[213] \"sub-217_stroop_test.csv\" \"sub-218_stroop_test.csv\"\n[215] \"sub-219_stroop_test.csv\" \"sub-220_stroop_test.csv\"\n[217] \"sub-221_stroop_test.csv\" \"sub-222_stroop_test.csv\"\n[219] \"sub-223_stroop_test.csv\" \"sub-224_stroop_test.csv\"\n[221] \"sub-225_stroop_test.csv\" \"sub-226_stroop_test.csv\"\n[223] \"sub-227_stroop_test.csv\" \"sub-228_stroop_test.csv\"\n[225] \"sub-229_stroop_test.csv\" \"sub-230_stroop_test.csv\"\n[227] \"sub-231_stroop_test.csv\" \"sub-232_stroop_test.csv\"\n[229] \"sub-233_stroop_test.csv\" \"sub-234_stroop_test.csv\"\n[231] \"sub-235_stroop_test.csv\" \"sub-236_stroop_test.csv\"\n[233] \"sub-237_stroop_test.csv\" \"sub-238_stroop_test.csv\"\n\n\nUm die Files einzulesen, reichen nur die Namen der Dateien nicht aus. Dazu ben√∂tigen wir die kompletten Pfade.\n\nfiles &lt;- list.files(path = 'data/raw/', pattern = 'stroop') %&gt;% \n    paste('data/raw/', ., sep = '')\n\n\nHier wird die Pipe des magritter-Packages verwendet (%&gt;%) statt die Base-R Pipe (|&gt;). Mit %&gt;% haben wir die M√∂glichkeit mit dem . zu bestimmen wo die weitergeleiteten Inhalte der Pipe eingef√ºgt werden (nach data/). Informationen zu den Unterschieden der Pipes finden Sie hier.\n\n\n10.4.1 Alle Files von Hand einlesen\nJedes Daten File wird einzeln eingelesen. Anschliessend m√ºssen alle Files zusammengef√ºgt werden. Diese L√∂sung ist einfach zu verstehen, ist bei vielen Dokumenten aber zu aufw√§ndig.\n\nfile1 &lt;- files[1]\nfile2 &lt;- files[2]\nfile3 &lt;- files[3]\n\nd1 &lt;- read_stroop(file1)\n\nRows: 161 Columns: 110\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (77): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd2 &lt;- read_stroop(file2)\n\nRows: 161 Columns: 111\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (78): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd3 &lt;- read_stroop(file3)\n\nRows: 161 Columns: 111\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (78): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd_hand &lt;- bind_rows(d1, d2, d3)\n\n\n\n10.4.2 Alle Files mit for-Loop einlesen\nDas Einlesen kann mit einem for-Loop automatisiert werden. Der Loop iteriert √ºber alle Daten Files. Als erstes muss ein leerer Data Frame d_loop erstellt werden. Bei jeder Iteration des Loops wird ein Daten File eingelesen und dem erstellten Data Frame d_loop angeh√§ngt.\n\nd_loop &lt;- tibble()\n\nfor (file in files){\n    d_tmp &lt;- read_stroop(file)\n    d_loop &lt;- bind_rows(d_loop, d_tmp)\n}\n\n\n\n10.4.3 Alle Files mit der Funktion map() einlesen\nmap() wendet eine Funktion auf alle Elemente eines Vektors an. Der Vektor files enth√§lt die Pfade zu den Daten Files. Mit map() k√∂nnen wir also unsere selbst erstellte Funktion read_stroop() auf jeden Pfad anwenden. Im Anschluss m√ºssen die Dataframes noch verbunden werden.\n\nd_map1 &lt;- files |&gt;\n    map(read_stroop) %&gt;%\n    bind_rows()\n\nDie Funktion map_dfr() macht das gleiche wie map() f√ºgt aber zus√§tzlich die einzelnen Data Frames automatisch zusammen.\n\nd_map2 &lt;- files |&gt;\n    map_dfr(read_stroop)\n\n\n\n\n\n\n\n\nHands-on 2: map Funktion anweden\n\n\n\nBenutzen Sie die Funktion map() um unsere Funktion fast_correct() gleichzeitig auf d1, d2 und d3 anzuwenden.\nTIPP: map() braucht als Argument eine Liste!",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#kompletter-stroop-code-an-einem-ort",
    "href": "datawrangling_automatisiert.html#kompletter-stroop-code-an-einem-ort",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "10.5 Kompletter Stroop Code an einem Ort",
    "text": "10.5 Kompletter Stroop Code an einem Ort\n\nread_stroop &lt;- function(path){\n    d_stroop &lt;- read_csv(path) |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color, \n           congruent, \n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)\n    d_stroop\n}\n\nd &lt;- list.files(path = 'data/raw/', pattern = 'stroop') %&gt;% \n    paste('data/raw/', ., sep = '') |&gt;\n    map_dfr(read_stroop)\n\nd |&gt; write.csv(file = \"data/clean/dataset_stroop_clean.csv\", row.names = FALSE) # neuer Datensatz in anderen Ordner speichern um Verdoppelung zu vermeiden\n\n\nAchten Sie darauf, den neu erstellten Datensatz nicht in den raw-Ordner zu speichern. Sonst wird er (weil er stroop im Namen hat) beim n√§chsten Ausf√ºhren der Funktion read_stroop ebenfalls eingelesen, was einen Fehler verursacht.\n\n\n\n\n\n\n\nHands-on L√∂sungen\n\n\n\n\n\n\n10.5.1 Hands-on 1\n\nfast_correct &lt;- function(data){\n  d &lt;- data %&gt;% \n    filter(rt&lt;0.5)\n  p &lt;- mean(d$corr) * 100   \n  return(p)\n}\n\nfast_correct(d_stroop)\n\n[1] 100\n\n\n\n\n10.5.2 Hands-on 2\n\ndata_list &lt;- list(d1, d2, d3)\n\ndata_list |&gt; \n    map(fast_correct)\n\n[[1]]\n[1] 89.65517\n\n[[2]]\n[1] 100\n\n[[3]]\n[1] 100",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#footnotes",
    "href": "datawrangling_automatisiert.html#footnotes",
    "title": "10¬† Automatisiertes Preprocessing",
    "section": "",
    "text": "F√ºr das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und w√§hlen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. F√ºr das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner k√∂nnen einwandfrei verwendet werden!‚Ü©Ô∏é",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "uebung_2.html",
    "href": "uebung_2.html",
    "title": "√úbung 2",
    "section": "",
    "text": "Auftrag\nArbeiten Sie die Datenvorverarbeitungsschritte im Kapitel Daten importieren und vorverarbeiten durch.",
    "crumbs": [
      "Data wrangling",
      "√úbung 2"
    ]
  },
  {
    "objectID": "uebung_2.html#abgabetermin",
    "href": "uebung_2.html#abgabetermin",
    "title": "√úbung 2",
    "section": "Abgabetermin",
    "text": "Abgabetermin\nBei dieser √úbung muss nichts abgegeben werden.\nBeim Termin vom 14. M√§rz 2024 werden wir jedoch stark auf dieses Vorwissen aufbauen.",
    "crumbs": [
      "Data wrangling",
      "√úbung 2"
    ]
  },
  {
    "objectID": "uebung_2.html#trouble-shooting",
    "href": "uebung_2.html#trouble-shooting",
    "title": "√úbung 2",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nSie d√ºrfen gerne in den Pausen der vorherigen Termine auf uns zukommen, falls etwas nicht klappt oder Sie eine Frage haben.\nFalls Sie zus√§tzliche √úbungsaufgaben w√ºnschen, finden Sie hier weitere Aufgaben:\n\nWalk-through mit L√∂sungen\n√úbungsaufgaben\n\nSie k√∂nnen auch Kurse auf DataCamp besuchen, z.B.\nüëâüèº Introduction to R",
    "crumbs": [
      "Data wrangling",
      "√úbung 2"
    ]
  },
  {
    "objectID": "data_visualization_1.html",
    "href": "data_visualization_1.html",
    "title": "11¬† Datenvisualisierung mit",
    "section": "",
    "text": "11.1 Daten\nDie wichtigste Komponente einer Grafik sind die Daten. Bevor eine Grafik erstellt wird, m√ºssen die Eigenschaften des Datensatzes bekannt sein.\n# Einlesen des Datensatzes\nd &lt;- read.csv(\"data/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition)) # Variable condition zu Faktor konvertieren\n\n# Datensatz anschauen\nglimpse(d)\n\nRows: 1,846\nColumns: 3\n$ condition &lt;fct&gt; away, away, away, away, away, away, away, away, away, away, ‚Ä¶\n$ value1    &lt;dbl&gt; 32.33111, 53.42146, 63.92020, 70.28951, 34.11883, 67.67072, ‚Ä¶\n$ value2    &lt;dbl&gt; 61.411101, 26.186880, 30.832194, 82.533649, 45.734551, 37.11‚Ä¶",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#daten",
    "href": "data_visualization_1.html#daten",
    "title": "11¬† Datenvisualisierung mit",
    "section": "",
    "text": "Der verwendete Datensatz stammt von Matejka and Fitzmaurice (2017).\n\n\n\n11.1.1 Datenformat\nAm einfachsten ist das Plotten mit ggplot(), wenn die Daten im long-Format vorliegen. Das bedeutet:\n\nJede Variable die gemessen/erhoben wird, hat eine Spalte (z.B. Versuchspersonennummer, Reaktionszeit, Taste).\nJede Messung hat eine Zeile. (In unserem PsychoPy-Experiment entspricht dies einer Zeile pro Trial.)\n\nDie hier eingelesenen Daten sind schon im long-Format.\n\nFalls die Daten im wide-Format abgespeichert sind, lohnt es sich diese umzuformatieren z.B. mit pivot_longer().\n\n\n\n11.1.2 Variablen\nF√ºr die Grafik ist es relevant, welches Skalenniveau die zu visualisierenden Variablen haben. Je nach Anzahl Variablen und den entsprechenden Skalenniveaus eignen sich andere Grafik-Formate. Eine h√§ufige Schwierigkeit beim Visualisieren der Daten ist, dass die Daten nicht das f√ºr den gew√§hlten Plot passenden Skalenniveaus haben.\n\n\n\nCC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=724035\n\n\n\n\n\n\n\n\nHands-on: Datensatz anschauen\n\n\n\nSchauen Sie sich den Datensatz an.\n\nWie viele unterschiedliche Variablen gibt es?\nWie heissen die Variablen?\nWelches Skalenniveau haben sie?\n\n\n\n\n\n11.1.3 Subsetting\nWenn nur ein gewisser Teil der Daten visualisiert werden soll, muss der Datensatz gefiltert werden. Der aktuelle Datensatz enth√§lt beispielsweise verschiedene Bedingungen, jeweils mit Werten f√ºr Variable value1 und value2. Folgende 13 Bedingungen sind enthalten:\n\nunique(d$condition)\n\n [1] away       bullseye   circle     dino       dots       h_lines   \n [7] high_lines slant_down slant_up   star       v_lines    wide_lines\n[13] x_shape   \n13 Levels: away bullseye circle dino dots h_lines high_lines ... x_shape\n\n\nF√ºrs erste entscheiden wir uns f√ºr die Bedingung away.\n\nd_away &lt;- d %&gt;%\n    filter(condition == \"away\")\n\nWir k√∂nnen f√ºr diese Bedingung zus√§tzlich summary statistics berechnen, hier Mittelwert und Standardabweichung.\n\nd_away_summary &lt;- d_away %&gt;%\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1),\n              mean_value2 = mean(value2),\n              sd_value2 = sd(value2))\n\nglimpse(d_away_summary)\n\nRows: 1\nColumns: 4\n$ mean_value1 &lt;dbl&gt; 54.2661\n$ sd_value1   &lt;dbl&gt; 16.76982\n$ mean_value2 &lt;dbl&gt; 47.83472\n$ sd_value2   &lt;dbl&gt; 26.93974\n\n\nDiese Werte geben einen Anhaltspunkt, in welchem Bereich sich die Werte bewegen werden.\n\n\n11.1.4 Plot\nIn den folgenden Beispielen werden die Daten der Bedingung away verwendet. Als erstes Argument wird der Funktion ggplot() der Datensatz √ºbergeben (data = data_away).\n\nggplot(data = d_away)",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#mapping",
    "href": "data_visualization_1.html#mapping",
    "title": "11¬† Datenvisualisierung mit",
    "section": "11.2 Mapping",
    "text": "11.2 Mapping\nDas mapping beschreibt, welche Variable auf der X- und Y-Achse abgetragen werden sollen. Es wird also definiert, wie die Variablen auf die Formen (aesthetics) gemappt werden sollen. Am einfachsten wird dies zu Beginn in festgelegt (das mapping kann aber auch in der Funktion geom_ selbst definiert werden). Weitere Variablen k√∂nnten als Argumente z.B. unter group = ... oder color = ... eingef√ºgt werden.\n\nggplot(data = d_away,\n       mapping = aes(x = value1,\n                     y = value2)) \n\n\n\n\n\n\n\n\nDie Grafik verf√ºgt nun √ºber Achsen, diese werden automatisch mit den Variablennamen beschriftet. Da noch keine Formen (geoms) hinzugef√ºgt wurde ist die Grafik in der Mitte aber leer.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#geom-formen",
    "href": "data_visualization_1.html#geom-formen",
    "title": "11¬† Datenvisualisierung mit",
    "section": "11.3 Geom / Formen",
    "text": "11.3 Geom / Formen\nAls dritte Komponente wird in ggplot() die Form mit geom_ hinzugef√ºgt. Jede Form, die eingef√ºgt wird, ben√∂tigt Angaben zum mapping. Falls kein mapping angegeben wird, wird dieses aus der ggplot()-Funktion in der ersten Zeile √ºbernommen.\nEs stehen viele verschiedene Formen zur Auswahl. Beispielsweise werden mit geom_point() Punkte erstellt, mit geom_line() Linien, mit geom_boxplot Boxplots, usw. Bei der Wahl der passenden Form kommt es einerseits auf die Daten an. Sind die Daten z.B. Faktoren oder numerische Werte (siehe auch Skalenniveau oben)? Wie viele Variablen werden gleichzeitig in die Grafik eingebunden? Andererseits ist es wichtig, was mit der Grafik gezeigt werden soll: Unterschiede? Gemeinsamkeiten? Ver√§nderungen √ºber Zeit?\nGeome zur Visualisierung von Datenpunkten und Verl√§ufen:\n\nPunkte / Scatterplots - geom_point()\nLinien - geom_line()\n\nGeome zur Visualisierung von zusammenfassenden Werten:\n\nHistogramme - geom_histogram()\nMittelwerte und Standardabweichungen - geom_pointrange()\nDichteplots - geom_density()\nBoxplots - geom_boxplot()\nViolinplots - geom_violin()\n\n\nEs gibt auch weitere, sehr informative Arten der Visualisierung, wie heat maps oder shift functions, auf die wir in dieser Veranstaltung nicht eingehen.\n\n\n\n\n\n\n\nHands-on: Geoms\n\n\n\nWelche geoms eignen sich f√ºr welches Skalenniveau und welche Variablenanzahl?\nTipps:\n\nSchauen Sie sich den Datensatz mit glimpse(), head() oder summary() an.\nSchauen Sie sich die verschiedenen Formen von Plots hier an. \n\nüëâ `{ggplot2}-Cheatsheet zum Herunterladen\n\n\n\n11.3.1 Kombinieren von mehreren geoms in einer Grafik\nTeilweise werden in Visualisierungen mehrere geoms kombiniert. In vielen F√§llen macht es beispielsweise Sinn, nicht nur die Rohwerte oder Werte f√ºr jedes Subjekt, sondern in derselben Grafik auch zusammenfassende Masse, z.B. einen Boxplot, zu visualisieren.\n\nWeiterf√ºhrende Info zum Kombinieren von Plots finden Sie hier.\n\nVerwenden verschiedener geoms in einem Plot:\n\nggplot(data = d_away, \n       mapping = aes(x = condition,\n                     y = value2)) +\n    geom_boxplot(width = 0.3) +\n    geom_jitter(width = 0.1) \n\n\n\n\n\n\n\n\nKombiniert werden k√∂nnen aber nicht nur verschiedene Formen, sondern auch mehrere Datens√§tze. Dies kann in ggplot() einfach umgesetzt werden indem mehrere Geoms √ºbereinandergelegt werden und nicht das mapping aus der ggplot()-Funktion genutzt wird. Stattdessen wird f√ºr jedes geom ein separater Datensatz und ein separates mapping spezifiziert.\n\nggplot(data = d_away, \n       mapping = aes(x = condition,\n                     y = value2)) +\n    geom_jitter(width = 0.1) + # verwendet Datensatz \"d_away\"\n    geom_point(data = d_away_summary, # verwendet Datensatz \"d_away_summary\"\n               aes(x = \"away\", y = mean_value1), # condition ist nicht im Datensatz enthalten, deshalb hier hardcoded\n               color = \"red\", # Punkt rot einf√§rben\n               size = 3) # Punkt vergr√∂ssern",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#beschriftungen-und-themes",
    "href": "data_visualization_1.html#beschriftungen-und-themes",
    "title": "11¬† Datenvisualisierung mit",
    "section": "11.4 Beschriftungen und Themes",
    "text": "11.4 Beschriftungen und Themes\nSch√∂nere und informativere Plots lassen sich gestalten, wenn wir einen Titel hinzuf√ºgen, die Achsenbeschriftung anpassen und das theme ver√§ndern:\n\nggplot(data = d_away,\n       mapping = aes(x = value1,\n                     y = value2)) +\n    geom_point() +\n    labs(title = \"Ein etwas sch√∂nerer Plot\", \n         subtitle = \"Verteilung der Rohwerte\",\n        x = \"Wert 1  [a.u.]\",\n        y = \"Wert 2 [a.u.]\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\nAuch theme_classic() oder theme_bw() ergeben schlichte aber sch√∂ne Plots.\n\n\n\n\n\n\n\nHands-on\n\n\n\nErstellen Sie eine Grafik.\n\nF√ºgen Sie mit labs() passende Beschriftungen hinzu. Gibt es noch weitere, oben nicht verwendete Optionen?\nWechseln Sie das theme. Welches gef√§llt Ihnen am besten?\n\ntheme_bw()\ntheme_classic()\ntheme_dark()\n‚Ä¶ (schreiben Sie theme_ und dr√ºcken Sie Tab, um weitere Vorschl√§ge zu sehen.)",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#daten-plotten-tipps-und-tricks",
    "href": "data_visualization_1.html#daten-plotten-tipps-und-tricks",
    "title": "11¬† Datenvisualisierung mit",
    "section": "11.5 Daten plotten: Tipps und Tricks",
    "text": "11.5 Daten plotten: Tipps und Tricks\n\n\n\n\n\n\nHands-on: Informative Grafik erstellen\n\n\n\nIm Folgenden k√∂nnen Sie den Datensatz mit Grafiken erkunden.\nSie k√∂nnen entweder in Ihrem RScript / RNotebook weiterarbeiten oder Sie k√∂nnen ein GUI (graphical user interface) verwenden, dass f√ºr Sie den Code schreibt.\n\nWelche geom_s/Formen eignen sich gut f√ºr diesen Datensatz?\nWelche Abbildungen k√∂nnen alle 3 Variablen des Datensatzes ber√ºcksichtigen?\nWie kann man Bedingungen miteinander vergleichen?\nWie k√∂nnen Gr√∂sse und Farbe der geom_s bestimmt werden?\nWie passt man Schriftgr√∂ssen an?\nK√∂nnen Sie eine Grafik speichern?\nLassen Sie sich den Code direkt ins RScript / RNotebook einf√ºgen und ver√§ndern Sie den Code dort weiter.\n\n\n\n\n11.5.1 Daten plotten mit esquisser()\nUm in RStudio ein GUI f√ºr das Datenvisualisieren zu verwenden, kann das Package {esquisse} genutzt werden.\n\nInstallieren Sie das Package {esquisse} mit install.packages(\"esquisse\") in der Konsole oder √ºber Tools &gt; Install packages...\nGeben Sie in Ihrer Konsole esquisse::esquisser() ein und w√§hlen Sie dann unter Import Data den schon eingelesenen Datensatz DatasaurusDozen.csv aus.\n\n\nEin weiteres R-basiertes Visualisierungstool in welchem der Code per GUI erstellt wird, ist trelliscopejs\n\n\n\n11.5.2 Mehrere Plots in einer Grafik darstellen\nDies k√∂nnen Sie mit dem Package patchwork sehr einfach machen. Sie finden oben oder hier ein Beispiel.\n\nWenn Sie das Package {patchwork} zum ersten Mal nutzen, k√∂nnen Sie es in der Konsole mit install.packages(\"patchwork\") installieren.\n\n\n\n11.5.3 Grafik abspeichern\nEine Grafik l√§sst sich abspeichern unter dem Reiter Plots &gt; Export oder mit der Funktion ggsave().\n\n\n11.5.4 Inspiration\n\nGrafiken f√ºr verschiedene Datenarten: From Data to Viz\nSimple bis crazy Chartideen: R Charts: Ggplot\nFarben f√ºr Grafiken: R Charts: Colors, noch mehr Farben\n\n\n\n11.5.5 Weiterf√ºhrende Ressourcen zur Datenvisualisierung mit ggplot()\n\nDokumentation von ggplot2\nKurzweilige, kompakte und sehr informative Informationen und Videos √ºber das Erstellen von Grafiken in ggplot finden Sie hier: Website PsyTeachR: Data Skills for reproducible research\nHier ist der Start der PsyTeachR Videoliste von Lisa deBruine, dort finden sich auch hilfreiche Kurzvideos zu Themen von Daten einlesen bis zu statistischen Analysen. Beispielsweise zu Basic Plots, Common Plots und Plot Themes and Customization\nEinf√ºhrung in R von Andrew Ellis und Boris Mayer\n\n\n\n\n\nMatejka, Justin, and George Fitzmaurice. 2017. ‚ÄúSame Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.‚Äù In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 1290‚Äì94. Denver Colorado USA: ACM. https://doi.org/10.1145/3025453.3025912.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#footnotes",
    "href": "data_visualization_1.html#footnotes",
    "title": "11¬† Datenvisualisierung mit",
    "section": "",
    "text": "F√ºr das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und w√§hlen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. F√ºr das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner k√∂nnen einwandfrei verwendet werden!‚Ü©Ô∏é",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Datenvisualisierung mit</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html",
    "href": "data_visualization_2.html",
    "title": "12¬† Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "12.1 Diagnostik: Daten untersuchen\nDatens√§tze k√∂nnen sehr komplex sein, deshalb ist die Visualisierung der Daten ein hilfreicher erster Schritt. Mit Hilfe von Visualisierungen k√∂nnen Aussagen √ºber die Qualit√§t der Daten gemacht werden, z.B. √ºber:\nDiagnostische Grafiken dienen dazu, rasch an Informationen zu k√∂nnen und Probleme in Datens√§tzen zu entdecken. Die Grafiken m√ºssen daher nicht √§sthetisch ansprechend oder f√ºr Aussenstehende verst√§ndlich sein. Im Sinne der Reproduzierbarkeit lohnt es sich aber, auch diese Visualisierungen gut zu dokumentieren.\nIm Folgenden schauen wir uns Beispiele f√ºr diagnostische Grafiken an.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#diagnostik-daten-untersuchen",
    "href": "data_visualization_2.html#diagnostik-daten-untersuchen",
    "title": "12¬† Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "Fehlende Werte\nAufgabenschwierigkeit\nExtreme Datenpunkte (Ausreisser)\nZeitverl√§ufe\nVerteilung der Daten\n\n\n\n\n12.1.1 Fehlende Werte\nHierbei ist es wichtig, vor allem systematisch fehlende Datenpunkte zu entdecken: Fehlt bei einer Person die H√§lfte der Antworten? M√∂chten wir diese ausschliessen?\nDiese k√∂nnen mit dem Package {naniar} relativ schnell sichtbar gemacht werden. Es gibt keine missings in unserem Fall.\n\nnaniar::vis_miss(d)\n\n\n\n\n\n\n\n\n\nBevor Sie das Package verwenden k√∂nnen, m√ºssen Sie dies erst herunterladen. Sie k√∂nnen dies unter dem Reiter Tools &gt; Install Packages ... tun oder in der Konsole mit install.packages(\"naniar\").\n\nF√ºr die Analyse schliessen wir alle Reaktionszeiten unter 100ms und √ºber 8 Sekunden aus.\n\n# zu schnelle und zu langsame Antworten ausschliessen\nd &lt;- d |&gt;\n    filter(rt &gt; 0.099 & rt &lt; 8)\n\nWir berechnen nun f√ºr die kommenden Grafiken die Anzahl Trials pro Person, die accuracy, sowie die mittlere Reaktionszeit f√ºr die Bedingungen congruent und incongruent (wie im Kapitel Aggregierte Statistiken beschrieben).\n\n# Daten gruppieren:  Anzahl Trials, Accuracy und mittlere Reaktionszeit berechnen\nacc_rt_individual &lt;- d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\nacc_rt_individual\n\n# A tibble: 468 √ó 6\n# Groups:   id [234]\n   id      condition       N ncorrect accuracy median_rt\n   &lt;fct&gt;   &lt;fct&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 sub-001 congruent      60       56    0.933     0.487\n 2 sub-001 incongruent    60       55    0.917     0.535\n 3 sub-002 congruent      60       60    1         0.544\n 4 sub-002 incongruent    60       54    0.9       0.619\n 5 sub-003 congruent      60       59    0.983     0.704\n 6 sub-003 incongruent    60       59    0.983     0.708\n 7 sub-004 congruent      60       60    1         0.606\n 8 sub-004 incongruent    60       49    0.817     0.778\n 9 sub-005 congruent      60       58    0.967     0.616\n10 sub-005 incongruent    60       35    0.583     0.863\n# ‚Ñπ 458 more rows\n\n\nNachdem wir Trials ohne Antwort ausgeschlossen haben, interessiert es uns, wie viele Trials jede Versuchsperson gel√∂st hat:\n\n# Plot: Anzahl Trials pro Bedingung f√ºr jede Versuchsperson \nacc_rt_individual |&gt; \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einf√ºgen\n    theme_minimal()\n\n\n\n\n\n\n\n\nWir k√∂nnten alle Personen ausschliessen, die weniger als 40 g√ºltige Trials hatten (in unserem Beispiel nicht n√∂tig, da alle gen√ºgend Trials haben).\n\n\n\n\n\n\nCode: Daten ausschliessen\n\n\n\n\n\n\n# Datensatz mit allen Ids, welche zuwenig Trials hatten\nn_exclusions &lt;- acc_rt_individual |&gt;\n    filter(N &lt; 40) \n\n# Aus dem Hauptdatensatz diese Ids ausschliessen\nd &lt;- d |&gt;\n    filter(!id %in% n_exclusions$id) \n\n# Check\nd_acc_rt_individual &lt;- d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\n\nd_acc_rt_individual |&gt; \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einf√ºgen\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.1.2 Extreme Datenpunkte (Ausreisser)\nWir k√∂nnen Visualisierungen auch verwenden, um extreme Datenpunkte zu identifizieren. Daf√ºr teilen wir hier die Accuracywerte in 3 Gruppen ein und plotten diese:\n\n# Trials nach accuracy einteilen\nd_acc_rt_individual_grouped &lt;- d_acc_rt_individual %&gt;% \n  mutate(\n    performance = case_when(\n      accuracy &gt; 0.75 ~ \"good\",\n      accuracy &lt; 0.40 ~ \"bad\",\n      TRUE ~ \"ok\") %&gt;% \n      factor(levels = c(\"good\", \"ok\", \"bad\")))\n\n# Outlier visualisieren\nd_acc_rt_individual_grouped %&gt;% \n    ggplot(aes(x = id, y = accuracy, color = performance, shape = performance)) +\n    geom_point(size = 2, alpha = 0.6) + \n    geom_point(data = filter(d_acc_rt_individual_grouped, performance != \"OK\"), \n               alpha = 0.9) + \n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray40\", \"steelblue\", \"red\")) +\n    geom_hline(yintercept = 0.33, linetype='dotted', col = 'black')+\n    annotate(\"text\", x = \"sub-100\", y = 0.33, label = \"chance level\", vjust = -1, size = 3) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nDasselbe k√∂nnte man f√ºr die Reaktionszeiten machen. Informationen dazu, wie Ausreisser in Reaktionszeiten gefunden und visualisiert werden k√∂nnen, finden Sie hier.\n\n\n\n12.1.3 Werte l√∂schen\nEs k√∂nnen einzelne Trials oder auch die gesamten Daten einer Versuchsperson ausgeschlossen werden, weil z.B. die Accuracy zu tief war, fehlende Werte bestanden, etc.\nHierbei ist wichtig:\n\nDatenpunkte werden nie aus den Rohdaten gel√∂scht, sondern nur aus dem aktuell geladenen Datensatz, welcher f√ºr die Analysen verwendet und neu abgespeichert wurde. So k√∂nnen wir uns immer noch umentscheiden und verlieren nicht die Information, welche Daten gefehlt haben.\nDadurch, dass die Datenverarbeitung in R mit reproduzierbarem Code geschrieben ist, k√∂nnen wir immer √ºberpr√ºfen, ob ein Fehler in unserer Datenverarbeitung zu den missings gef√ºhrt hat und diesen evtl. korrigieren.\nEs macht nicht immer Sinn die Trials mit missing data zu l√∂schen! Dies muss von Fall zu Fall entschieden werden. Wenn Versuchspersonen zum Beispiel teilweise zu lange brauchten um eine Aufgabe zu l√∂sen, dann ist das eine wichtige Information, wird diese rausgel√∂scht, wird die Leistung der Versuchsperson systematisch √ºbersch√§tzt.\n\nIn unserem Beispiel macht es Sinn, die drei Versuchspersonen, die extrem tiefe Accuracy hatten (wahrscheinlich weil sie die Aufgabe falsch verstanden hatten) vor den Analysen aus dem Datensatz auszuschliessen.Zuerst schauen wir uns an, welche Versuchspersonen sehr tiefe accuracy-Werte hatten:\n\nacc_rt_individual |&gt;\n    filter(accuracy &lt; 0.33) # 0.33 ist das chance level\n\n# A tibble: 3 √ó 6\n# Groups:   id [3]\n  id      condition       N ncorrect accuracy median_rt\n  &lt;fct&gt;   &lt;fct&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 sub-009 incongruent    60        4   0.0667     1.25 \n2 sub-180 incongruent    60        1   0.0167     0.653\n3 sub-201 incongruent    60        1   0.0167     0.629\n\n\nDann schliessen wir diese 3 Personen aus. Hierbei empfiehlt es sich, den Code so zu kommentieren, dass man sp√§ter direkt sieht, weshalb eine Person ausgeschlossen wurde.\n\n# Aussschluss dieser Personen\nd &lt;- d |&gt;\n    filter(id != \"sub-009\") |&gt; # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n    filter(id != \"sub-180\") |&gt; # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n    filter(id != \"sub-201\") # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n\n\n\n12.1.4 Verlaufseffekte: Erm√ºdung und Lernen\nVerlaufseffekte sind relevant, wenn man z.B. Erm√ºdungs- oder Lerneffekte ausschliessen m√∂chte. Sie k√∂nnten aber auch inhaltlich interessant sein, z.B. in einem Trainingskontext, wenn man sich daf√ºr interessiert, wie viele Trials n√∂tig sind, damit sich jemand in einer Aufgabe verbessert.\nIn unserem Experiment m√∂chten wir sicher sein, dass die Performanz sich √ºber die Zeit hinweg nicht zu stark ver√§ndert. Hierzu k√∂nnen wir beispielsweise die accuracy plotten:\n\nd_acc_rt_trial &lt;- d |&gt;\n    group_by(condition, trial) |&gt;\n    summarise(\n        accuracy = mean(corr),\n        median_rt = median(rt)\n        )\n\nd_acc_rt_trial |&gt;\n    ggplot(aes(x = trial, y = accuracy, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nOder wir k√∂nnen uns die Reaktionszeiten √ºber die Zeit hinweg anschauen.\n\nd_acc_rt_trial |&gt;\n    ggplot(aes(x = trial, y = median_rt, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nDas tun wir hier f√ºr 3 Versuchspersonen.\n\n# Plot: Reaktionszeit √ºber die Trials hinweg (f√ºr 3 Versuchspersonen)\nd |&gt;\n    filter(id %in% c(\"sub-001\", \"sub-100\", \"sub-150\")) |&gt;\n    ggplot(aes(x = trial, y = rt, color = condition)) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_point(alpha = 0.5) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ id) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n12.1.5 Aufgabenschwierigkeit und Performanz der Versuchspersonen\nBevor wir die Daten analysieren, m√∂chten wir wissen, ob die Personen die Aufgabe einigermassen gut l√∂sen konnten (und wollten). In unserem Experiment erwarten wir eine Genauigkeit (accuracy) √ºber dem Rateniveau von 33%. Wir plotten hierf√ºr die accuracy f√ºr jede Person und Bedingung.\n\n# Plot accuracy per person and condition\np1 &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Proportion correct\",\n         title = \"Accuracy\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np2 &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = median_rt, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\nlibrary(patchwork)\n\np1 + p2\n\n\n\n\n\n\n\n\nUnd wir interessieren uns, wie sich die accuracy zwischen den Bedingungen unterscheidet. Das zeigt uns, ob die Instruktion eine Wirkung hatte. Daf√ºr f√ºgen wir Linien ein, die die accuracy- Werte pro Versuchsperson verbindet:\n\np3 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = condition, y = accuracy, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Proportion correct\",\n         title = \"Accuracy\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np4 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = condition, y = median_rt, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np3 + p4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on: Datenqualit√§t\n\n\n\nBesprechen Sie miteinander, was Sie nun √ºber unsere Daten wissen.\n\nHaben die Versuchspersonen die Aufgaben l√∂sen k√∂nnen?\nWar die Aufgabe zu einfach, zu schwierig?\nDenken Sie, die Personen waren motiviert?\nWelche Datens√§tze / Trials m√∂chten wir ausschliessen? (Achtung: Dies m√ºsste eigentlich vor dem Anschauen der Daten entschieden werden, um zu verhindern, dass man Datenpunkte ausschliesst, welche die Hypothese nicht best√§tigen.)\nWie gut eignen sich die Daten, um die Forschungsfrage zu beantworten?\nWas k√∂nnte bei einem n√§chsten Experiment besser gemacht werden?",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#analyse-daten-zusammenfassen-und-explorieren",
    "href": "data_visualization_2.html#analyse-daten-zusammenfassen-und-explorieren",
    "title": "12¬† Grundlagen der Datenvisualisierung",
    "section": "12.2 Analyse: Daten zusammenfassen und explorieren",
    "text": "12.2 Analyse: Daten zusammenfassen und explorieren\nGrafiken k√∂nnen einerseits eine Erg√§nzung zur statistischen Datenanalyse sein, wie auch die Resultate der Analysen (bspw. gesch√§tzte Parameterwerte) visualisieren. Sie haben den Vorteil, dass Informationen √ºber Daten oder Analyseergebnisse gleichzeitig ersichtlich sind, sie k√∂nnen also vom Betrachtenden direkt verglichen werden.\nWir m√∂chten die Daten hinsichtlich der Forschungsfragen visualisieren. Die Grafiken m√ºssen vor allem pr√§zise und informativ sein. Um Schl√ºsse aus Daten ziehen zu k√∂nnen, m√ºssen diese zusammengefasst werden. Dazu eignen sich Lagemasse oder Masse der zentralen Tendenz, also beispielsweise der Mittelwert, Median oder Modus. Gleichzeitig ist es wichtig, dass auch Verteilungsmasse berichtet werden, wie Standardabweichungen oder Standardfehler. Wir k√∂nnen auch mit Werte aus statistischen Modellen, wie Parametersch√§tzungen und Konfidenzintervalle, grafisch darstellen.\nMit Hilfe von Visualisierungen k√∂nnen z.B. Aussagen k√∂nnen gemacht werden √ºber:\n\nVerteilung der Daten\nZusammenh√§nge von Variablen (Korrelationen, Zeitverl√§ufe)\nVergleiche und Unterschiede von Gruppen / Bedingungen\n\n\n12.2.1 Verteilung der Rohdaten\nDaten von neurowissenschaftlichen Studien k√∂nnen wichtige Informationen enthalten, die ohne Grafiken √ºbersehen werden k√∂nnen (Rousselet, Pernet, and Wilcox (2017)). Das Visualisieren kann Muster zum Vorschein bringen, die durch statistische Auswertungen nicht sichtbar sind. Die Wichtigkeit von Datenvisualisierung f√ºr das Entdecken von Mustern in den Daten zeigte Francis Anscombe 1973 mit dem Anscombe‚Äôs Quartet. Dies diente als Inspiration f√ºr das Erstellen des ‚Äúk√ºnstlichen‚Äù Datensatzes DatasaurusDozen, welchen wir in der letzten Veranstaltung visualisiert haben. Verschiedene Rohwerte, k√∂nnen dieselben Mittelwerte, Standardabweichungen und Korrelationen ergeben. Nur wenn man die Rohwerte plottet erkennt man, wie unterschiedlich die Datenpunkte verteilt sind.\nDies wird ersichtlich, wenn wir die Mittelwerte und Standardabweichungen f√ºr jede Gruppe berechnen und plotten:\n\n# load DatasaurusDozen dataset\ndino_data &lt;- read.csv(\"data/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition))\n\n# Plot mean and standard deviation for value 1 per condition \ndino_data |&gt;   \n    group_by(condition) |&gt;\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1)) |&gt;\n    ggplot(mapping = aes(x = mean_value1,\n                     y = condition)) +\n    geom_point() +\n    geom_errorbar(aes(xmin = mean_value1 - sd_value1, \n                      xmax = mean_value1 + sd_value1), \n                  width = 0.2) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nUnd dann die Rohwerte visualisieren:\n\n# Plot raw values\ndino_data |&gt; \n    ggplot(aes(x = value1, y = value2)) +\n    geom_point(size = 1) +\n    facet_wrap(~condition) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nHier sehen Sie das Ganze animiert:\n\n\n\nDatensatz und Visualisierung von Matejka and Fitzmaurice (2017)\n\n\n\n\n12.2.2 Zentrale Tendenz und Verteilungsmasse\nMasse der zentralen Tendenz sind beispielsweise der Mittelwert, der Median und Modus. Wenn wir uns daf√ºr interessieren, wie sich die accuracy in Bezug auf alle Teilnehmenden verh√§lt, schauen wir uns die zentrale Tendenz √ºber alle Personen hinweg an. Es sollte nie nur die zentrale Tendenz, sondern immer auch ein passendes Verteilungsmass berichtet werden.\nWie oben schon gezeigt k√∂nnen wir dies z.B. mit Boxplots umsetzen Diese zeigen uns den Median und die Quartile sowie Ausreisser an. Eine andere M√∂glichkeit Verteilungen anzuzeigen sind die Violinplots. Hier wurden mit geom_jitter() auch die Mittelwerte der einzelnen Personen im Plot eingef√ºgt.\n\n# Boxplot\np_boxplot &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.25, width = 0.2) +\n    geom_boxplot(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Boxplot\",\n         x = \"Congruency\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n# Violin Plot\np_violin &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.5, width = 0.2) +\n    geom_violin(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Violin Plot\",\n         x = \"Congruency\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np_boxplot + p_violin\n\n\n\n\n\n\n\n\nDas Package {ggridges} bietet die M√∂glichkeit die Verteilungen zu plotten. Mehr Informationen hierzu finden Sie hier in der Dokumentation.\n\nlibrary(ggridges)\np5 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = accuracy, y = condition, fill = condition)) + geom_density_ridges2(scale = 0.5, alpha = 0.5) +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Accuracy\",\n         x = \"Proportion corect\",\n         y = \"Congruency\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np6 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = median_rt, y = condition, fill = condition)) + geom_density_ridges2(scale = 1, alpha = 0.5) +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Median Response Time\",\n         x = \"Median Response Time [s]\",\n         y = \"Congruency\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np5 + p6\n\n\n\n\n\n\n\n\n\n\n12.2.3 Aggregierte Statistiken\nWenn wir Mittelwerte und Standardfehler angeben m√∂chten k√∂nnen wir dies wie folgt tun. Wichtig ist hier, dass wir within-subject Standardfehler berechnen. Genaueres zu den Unterschieden zwischen within- und between-subject Standardfehlern finden Sie hier. Wir verwenden das Package {Rmisc}. Achtung: Da dieses jedoch wegen der Namen der Funktionen oft Namens-Konflikte ausl√∂st, laden wir Rmisc nicht mit der library()-Funktion, sondern stellen es einfach vor die ben√∂tigte Funktion, z.B. so Rmisc::summarySEwithin().\n\nd_acc_within &lt;- d |&gt;\n    Rmisc::summarySEwithin(measurevar = \"corr\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np7 &lt;- d_acc_within |&gt;\n    ggplot(aes(x = condition, y = corr, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = corr-se, ymax = corr+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Accuracy\",\n         x = \"Congruency\",\n         y = \"Accuracy\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n\nd_rt_within &lt;- d |&gt;\n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np8 &lt;- d_rt_within |&gt;\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Median Response Time\",\n         x = \"Congruency\",\n         y = \"Median Response Time [s]\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np7 + p8\n\n\n\n\n\n\n\n\n\nHier finden Sie weitere Code-Beispiele f√ºr das Plotten von Verteilungsmassen.\nHier finden Sie Informationen, wie Reaktionszeiten zusammengefasst und visualisiert werden k√∂nnten.\n\n\n\n12.2.4 Visualisieren von Modellsch√§tzungen\nWenn f√ºr die statistische Analyse ein Modell gesch√§tzt wurde, kann auch dies visualisiert werden. Auf diese Form der Visualisierung wird in diesem Kapitel aber nicht eingegangen.\n\nsjPlot: Package zum Plotten von Fixed Effects\nsee: Package zum Visualisieren von Statistischen Modellen",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#kommunikation-forschungsergebnisse-visualisieren",
    "href": "data_visualization_2.html#kommunikation-forschungsergebnisse-visualisieren",
    "title": "12¬† Grundlagen der Datenvisualisierung",
    "section": "12.3 Kommunikation: Forschungsergebnisse visualisieren",
    "text": "12.3 Kommunikation: Forschungsergebnisse visualisieren\nKommunikation der Ergebnisse findet vor allem in den wissenschaftlichen Artikeln, Postern oder Pr√§sentationen statt. Bei Visualisierungen die der Kommunkation dienen sind folgende Merkmale wichtig:\n\n12.3.1 Beschriftungen\nDie genaue Beschriftung und deren Lesbarkeit ist f√ºr diese Form von Grafiken zentral. Achten Sie sich auf Folgendes:\n\nDie Achsenbeschriftungen enthalten die verwendete Variable in Klartext (nicht den R Variablennamen) und wenn zutreffend auch die Masseinheit (z.B. Response Time [ms]). Beschriftungen k√∂nnen Sie einf√ºgen mit labs().\n\n\np_boxplot +\nlabs(title = \"Der Titel der Grafik\", \n     subtitle = \"Der Subtitel der Grafik\",\n     x = \"hier kommt Label x [Masseinheit]\", \n     y = \"hier kommt Label y [Masseinheit]\",\n     caption = \" Hier kommt eine Caption\")\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's fill values.\n\n\n\n\n\n\n\n\n\n\nFarben / Formen usw. werden in einer Legende den Gruppen zugeordnet (Ausnahme: wenn Daten von einzelnen Personen geplottet werden, wird die Versuchspersonennummer nicht aufgef√ºhrt).\nMasse der zentralen Tendenz und Varianzmasse werden beschrieben (z.B. Standardfehler oder Standardabweichung?)\n\n\n\n12.3.2 F√ºnf Merkmale einer guten Grafik\nEs gibt unz√§hlige Optionen die eigenen Daten zu visualisieren. Folgende Prinzipien helfen beim Erstellen einer informativen Grafik, die zur Kommunikation der Ergebnisse dient.\n\nDie Punkte 3-5 wurden aus dem Buch ‚ÄúThe Visual Display of Quantitative Information‚Äù von Edward Tufte, 1986 entnommen.\n\n\n1. Eine Frage beantworten\nJede Grafik sollte mindestens eine teilweise aber auch mehrere Fragen beantworten.\nüëâ Welche Frage m√∂chte ich beantworten? Welche Form der Visualisierung beantwortet diese Frage am besten?\nHierbei kann es hilfreich sein den ‚ÄúArbeitstitel‚Äù der Grafik als Frage zu formulieren.\n\n\n2. Zielgruppe ber√ºcksichtigen\nBeim Erstellen der Grafik sollte beachtet werden, an wen sich die Grafik richtet. F√ºr eine Pr√§sentation m√ºssen die Achsenbeschriftungen vergr√∂ssert und die Grafik simpel gehalten werden. In einem wissenschaftlichen Artikel kann die Grafik komplexer gestaltet werden, da die Lesenden sich mehr Zeit zum Anschauen nehmen k√∂nnen. Zudem sollten hier die Vorgaben des Journals ber√ºcksichtigt werden. Auch wichtig ist das Verwenden von ‚Äúfarbenblind-freundlichen‚Äù Palletten, rot und gr√ºn ist z.B. eine schlechte Wahl.\nüëâ F√ºr welchen Zweck / f√ºr wen erstelle ich die Grafik? Wie ist das Vorwissen des Zielpublikums?\n\nF√ºr einen Fachartikel lohnt es sich, zu Beginn die Vorgaben der Fachzeitschrift zu ber√ºcksichtigen.\n\n\n\n3. Die Daten zeigen\nDas t√∂nt simpel, wird aber oft nicht ber√ºcksichtigt. Bei einer Grafik geht es in erster Linie um die Daten. Es sollte die simpelste Form gew√§hlt werden, welche die Informationen vermittelt. Oft braucht es keine ausgefallenen Grafikideen oder neuartigen Formate. Hierbei ist es wichtig, die Art der Daten zu ber√ºcksichtigen: Wie viele Variablen sind es? Sind diese kontinuierlich (z.B. Reaktionszeiten) oder diskret (z.B. Experimentalbedingungen)? Wie viele Dimensionen haben meine Daten? Mit zwei Achsen lassen sich zwei Dimensionen darstellen, zus√§tzlich k√∂nnen mit Farben und Formen noch weitere Dimensionen abgebildet werden (z.B. Millisekunden, Bedingung 1 und Bedingung 2). Es k√∂nnen Rohwerte geplottet werden oder summary statistics (z.B. Mittelwerte, Standardabweichungen)\nüëâ Welche Art Grafik eignet sich f√ºr meine Frage und meine Daten? Schauen Sie z.B. hier nach oder nutzen Sie das esquisse-Package.\n\nBeispiele f√ºr verschiedenen Plots in R sind z.B. histogram, boxplot, violin plot, scatter plot / correlogram, jitter plot, raincloud plot, percentiles / shift functions, area chart, heat map.\n\n\n\n4. Optimieren des data-ink ratios\nDas Daten-Tinte-Verh√§ltnis sollte so optimal wie m√∂glich sein. Das bedeutet, das idealerweise jeder Strich, jeder Punkt, jedes Textfeld Information beinhaltet. Alles was keine Information transportiert oder nur wiederholt kann weggelassen werden.\nüëâ Was kann ich weglassen?\n\nIn R kann zum Schluss des Plots + theme_minimal() hinzugef√ºgt werden, dies entfernt u.a. den grauen Hintergrund. Das Grau des Hintergrunds ist Farbe (ink), welche keine Information transportiert, das Weglassen l√§sst die Grafik ruhiger wirken.\n\n\n\n5. Feedback einholen und revidieren\nDas Erstellen einer guten Grafik ist iterativ, das heisst, sie wird immer wieder √ºberarbeitet, bis sie die Information m√∂glichst einfach, genau aber klar kommuniziert. Hierbei ist Feedback oft unerl√§sslich.\nüëâ Was denken andere √ºber Ihre Grafik?\n\n\n\n\n\n\nMatejka, Justin, and George Fitzmaurice. 2017. ‚ÄúSame Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.‚Äù In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 1290‚Äì94. Denver Colorado USA: ACM. https://doi.org/10.1145/3025453.3025912.\n\n\nRousselet, Guillaume A., Cyril R. Pernet, and Rand R. Wilcox. 2017. ‚ÄúBeyond Differences in Means: Robust Graphical Methods to Compare Two Groups in Neuroscience.‚Äù European Journal of Neuroscience 46 (2): 1738‚Äì48. https://doi.org/10.1111/ejn.13610.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#footnotes",
    "href": "data_visualization_2.html#footnotes",
    "title": "12¬† Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "F√ºr das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und w√§hlen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. F√ºr das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner k√∂nnen einwandfrei verwendet werden!‚Ü©Ô∏é",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "uebung_3.html",
    "href": "uebung_3.html",
    "title": "√úbung 3",
    "section": "",
    "text": "Auftrag\nTeil A: Datapreprocessing-Pipeline  Erstellen Sie eine automatisierte Datenverarbeitungs-Pipeline, die die Daten des Random Dot Experiments einlesen und vorverarbeiten.\nTeil B: Datenvisualisieren Erstellen Sie einen Plot der Random Dot Daten. Verwenden Sie dazu ggplot(). Alle Plots und der entsprechende Code werden in der Galerie auf der Kurshomepage anonym ver√∂ffentlicht.\nWichtig:",
    "crumbs": [
      "Datenvisualisieren",
      "√úbung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#auftrag",
    "href": "uebung_3.html#auftrag",
    "title": "√úbung 3",
    "section": "",
    "text": "Information zum Arbeiten in Kleingruppen:\n\n√úbungen d√ºrfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen m√ºssen die √úbung auf Ilias hochladen, um die √úbung zu bestehen.\nDie Files von Gruppenarbeiten m√ºssen folgendermassen benannt werden, damit wir sehen, welche √úbungsabgaben zusammengeh√∂ren: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_1_GW_EW.R. Geben Sie bei allen Files die Initialen in derselben Reihenfolge an.\n\nArbeitsanweisung unter dem Unterkapitel Vorgehen:\n\nLesen Sie die Anweisungen genau durch und geben Sie die Dateien in diesem Format ab (z.B. Benennung der Dateien).\nArbeiten Sie entlang der Arbeitsanweisung, um den Prozess zu vereinfachen.",
    "crumbs": [
      "Datenvisualisieren",
      "√úbung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#vorgehen",
    "href": "uebung_3.html#vorgehen",
    "title": "√úbung 3",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nDownload und Setup\n\nLaden Sie das R-Project uebung-3 herunter und entzippen Sie den Ordner. Im data-Ordner finden Sie die Einzeldateien vom Experiment.\nAchtung: Sie m√ºssen nur die Daten des Random Dot Experiments einlesen, vorverarbeiten und visualisieren. Die Daten des Stroop Experiments wurden in der Veranstaltung bearbeitet.\n\n\n\nA. Datapreprocessing-Pipeline\n\n\n\n\n\n\nTipp\n\n\n\nAm besten erstellen Sie zuerst f√ºr einen Datensatz einen funktionierenden Vorverarbeitungsablauf. Dann erstellen Sie eine Funktion f√ºr diesen Ablauf. In einem letzten Schritt automatisieren Sie dann diesen Ablauf f√ºr alle Datens√§tze im Datenordner indem Sie eine Liste mit allen Filenamen erstellen. Sie k√∂nnen sich an dem Automatisierungsbeispiel mit dem Stroop Datensatz orientieren.\nDas Einlesen kann eine Weile dauern, es sind sehr viele Datens√§tze.\n\n\n\nErstellen Sie ein neues .R-File und speichern Sie dieses unter preprocessing_random_dot.R im Projekt-Ordner. Sie k√∂nnen auch ein RNotebook erstellen! Falls Sie in einer Gruppe arbeiten speichern Sie dieses mit den Initialen ab, z.B. preprocessing_random_dot_initialen_initialen_initialen.R.\na. Packages laden: Laden Sie das Package {tidyverse}.\nb. Daten einlesen (read.csv())\nc.¬†Daten filtern, so dass nur Experimenttrials im Datensatz sind, keine √úbungsaufgaben. (filter())\nd.¬†Erstellen zwei neuer Variablen namens trial (diese Variable gibt die Trialnummer startend mit 1 an und initials (diese Variable gibt Ihre Initialen an) mit (mutate()). Falls Sie in einer Gruppe arbeiten, geben Sie mehrere Initialen in den Variablen initals1, initials2 und initials3 an.\ne. Datensatz vereinfachen: Der Datensatz soll in dieser Reihenfolge folgende Informationen/Variablennamen enthalten (select()):\n  - Versuchspersonenidentifikation (`id`)\n  - Trialnummer (`trial`)\n  - Bewegungsrichtung der Punkte (`direction`)\n  - Instruktionsbedingung (`condition`)\n  - Korrekte Antwort f√ºr diesen Trial (`corrAns`)\n  - Antwort der Versuchsperson (`resp`), \n  - war die Antwort der Versuchsperson korrekt? (`corr`)\n  - Antwortzeit der Versuchsperson (`rt`)\n  - Initialen der ausf√ºhrenden Person (`initials`)\nf.¬†Automatisieren\n\nErstellen Sie nun eine Funktion, die dies f√ºr alle Random Dot Datens√§tze ausf√ºhrt und einen aggregierten Datensatz erstellt. Hier finden Sie ein Anwendungsbeispiel dazu.\n\ng. Erstellter Datensatz kontrollieren:\n\nL√∂schen Sie nun alle Variablen in der RStudio Umgebung (Environment) mit dem Besen-Icon oben rechts und f√ºhren Sie den Code nochmals aus. Wenn alles funktioniert, fahren Sie weiter.\n\nh. Datensatz speichern:\n\nDatensatz f√ºr Ilias: Speichern Sie den neuen Datensatz (der jetzt alle Datens√§tze vorverarbeitet und zusammengef√ºgt enth√§lt) als .csv-File namens dataset_random_dot_clean_initialen.csv in Ihren data-Ordner.\nDatensatz f√ºrs Visualisieren: Speichern Sie den Datensatz als dataset_random_dot_clean.csv im data-Ordner ab.\n\ni. Gespeicherten Datensatz kontrollieren:\n\nIhr Datensatz sollte nun wie untenstehend aussehen. Benutzen Sie dazu in Ihrem Code den Sie abgeben zwingend die Funktion glimpse(). (Ohne glimpse() ist Ihre Abgabe ung√ºltig.)\n\n\n\n\nRows: 28,680\nColumns: 8\n$ id        &lt;chr&gt; \"sub-001\", \"sub-001\", \"sub-001\", \"sub-001\", \"sub-001\", \"sub-‚Ä¶\n$ trial     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1‚Ä¶\n$ direction &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"right\", ‚Ä¶\n$ condition &lt;chr&gt; \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed‚Ä¶\n$ corrAns   &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"right\", ‚Ä¶\n$ resp      &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"left\", \"‚Ä¶\n$ corr      &lt;int&gt; 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, ‚Ä¶\n$ rt        &lt;dbl&gt; 49.83123, 49.61717, 49.31203, 49.57549, 50.58607, 49.55812, ‚Ä¶\n\n\n\n\nB. Datenvisualisieren\n\nIm Ordner finden Sie eine Datei namens initialen_plot.R. √ñffnen Sie die die Datei initialen_plot.R. Der Inhalt dieser Datei muss gleich aussehen, wie im Beispiel unten.\n√Ñndern Sie den Namen der Datei initialen_plot.R, indem Sie Ihre Initialen (oder mehrere: initialen_initialen_initialen_plot.R) einsetzen. Das File muss korrekt benannt werden f√ºr eine g√ºltige Abgabe!\nDer Code auf von Zeile 1 bis Zeile 8 darf nicht ver√§ndert werden!\nF√ºgen Sie den Code f√ºr Ihre Abbildung ab Zeile 9 ein.\nDer eingef√ºgte Code muss die Abbildung erstellen (vgl. Zeile 9-12) und anzeigen (vgl. Zeile 12).\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(...) +\n    ...\np\n\n\nDer Plot muss Folgendes beinhalten:\n\nBeides, Rohdaten UND mind. 1 zusammenfassendes Mass(z.B. Mittelwert mit Standardabweichungen, Box-/Violinplot, etc.). TIPP: Mehrere Geoms k√∂nnen √ºbereinander gelegt werden.\nMind. 2 unterschiedliche Farben (schwarz und weiss ausgenommen).\nBeschriftungen: Titel, Subtitel, Achsenbeschriftungen, (optional: Captions)\nDer Subtitel beinhaltet die Frage, welche der Plot beantwortet.\n\nEin Theme verwenden.\nOptional: Facets verwenden.\n\n\n\n\nHochladen der Dateien auf Ilias\nLaden Sie folgende Dateien unter √úbung 3 auf Ilias hoch:\n\ndataset_random_dot_clean_initialen.csv-File\npreprocessing_random_dot_initialen_initialen_initialen.R\ninitialen_initialen_initialen_plot.R\n.jpg oder .png (oder anderes Bildformat) Ihres Plots\n\n\n\n\n\n\n\nWichtig\n\n\n\nIhr Plot und der dazugeh√∂rige Code wird in der Galerie Gruppe 1 und Galerie Gruppe 2 anonym ver√∂ffentlich. Deshalb ist es wichtig, dass die oben aufgelisteten Voraussetzungen erf√ºllt sind.",
    "crumbs": [
      "Datenvisualisieren",
      "√úbung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#abgabetermin",
    "href": "uebung_3.html#abgabetermin",
    "title": "√úbung 3",
    "section": "Abgabetermin",
    "text": "Abgabetermin\nDer Abgabetermin f√ºr diese √úbung ist der 18. April 2025 (Nachholtermin: 21. Mai 2025).",
    "crumbs": [
      "Datenvisualisieren",
      "√úbung 3"
    ]
  },
  {
    "objectID": "plots_group1.html",
    "href": "plots_group1.html",
    "title": "Plot Gallery - Group 1",
    "section": "",
    "text": "PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n# Packages laden\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nd &lt;- d |&gt;\n    mutate(across(where(is.character), as.factor)) |&gt;\n    mutate(corr = as.factor(corr))\n\n# Ausschliessen von zu kurzer & langer Reaktionszeit [s]\nd_clean &lt;- d |&gt;\n    filter(!is.na(rt), rt &gt; 0.1 & rt &lt; 12)\n\n# Fehlende Werte\nnaniar::vis_miss(d_clean)\n\n# condition_con umbenennen\nd_clean &lt;- d_clean %&gt;%\n  rename(`Korrektheit der Antwort` = corr)\n    \n\n# mittlere Reaktionszeit berechnen\nmean_data &lt;- d_clean %&gt;%\n  group_by(`Korrektheit der Antwort`, condition) %&gt;%\n  summarise(mean_rt = mean(rt, na.rm = TRUE), .groups = \"drop\")\n\n# Grafik f√ºr Daten von Random-Dot-Experiment\nggplot(data = d_clean, aes(\n         x = condition, \n         y = rt, \n         group = factor(`Korrektheit der Antwort`), # Faktor f√ºr Gruppierung\n         fill = `Korrektheit der Antwort`)) + \n   \n  # Rohdaten als Punkte\n  geom_jitter(position = position_dodge(width = 0.8), \n              alpha = 0.5, \n              color = \"black\") +\n   \n  # Mittelwerte als Balken\n  geom_bar(stat = \"summary\", fun = mean, \n           position = position_dodge(width = 0.8), \n           width = 0.7) +\n \n  # Zahlen zu Mittelwert-Balken hinzuf√ºgen\n  stat_summary(fun = mean,\n               geom = \"text\",\n               aes(label = round(..y.., 1)),\n               position = position_dodge(width = 0.8),\n               vjust = +2,\n               color = \"black\",\n               size = 3.5) +\n  \n  # Farbgebung und Legenden-Beschriftung\n  scale_fill_manual(values = c(\"darkviolet\", \"pink\"),\n                  labels = c(`1` = \"korrekte Antwort\", `0` = \"falsche Antwort\")) +\n\n  # Titel und Achsen-Beschriftungen\n  labs(title = \"Random-Dot-Test\",\n       subtitle = \"Gibt es Reaktionszeit-Unterschiede bei korrekter Antwort abh√§ngig von Condition?\",\n       x = \"Condition\", \n       y = \"Reaktionszeit [s]\",\n       fill = \"Korrektheit der Antwort\") + \n  \n  # Theme\n  theme_bw()\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#Variablen als Faktoren definieren\nd &lt;- d |&gt; \n  mutate(condition = factor(condition, levels = c(\"accuracy\", \"speed\")), \n        corr = factor(corr, levels = c(\"1\", \"0\"), labels = c(\"richtige Antwort\", \"falsche Antwort\")))\n\n#Beginn Plot \np = d |&gt;\n  ggplot(mapping = aes(x = condition, y = rt, fill = corr)) + #globales mapping\n  geom_jitter(alpha = 0.2) + #Rohdaten\n  geom_violin(alpha = 0.7) + #zusammenfassendes Mass (Verteilung mit Violin Plot)\n  # Mittelwert + Standardabweichung (zusammenfassendes Mass):\n  stat_summary(fun = mean, geom = \"point\", position = position_dodge(0.9), size = 2, shape = 4, color = \"red\") + \n  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = \"errorbar\", position = position_dodge(0.9), width = 0.2) +\n  # Beschriftung & Theme\n  labs(\n    title = \"Reaktionszeiten in Abh√§ngigkeit von Instruktion und Korrektheit\",\n    subtitle = \"Ver√§ndert sich die Reaktionszeit abh√§ngig von Instruktionsbedingung und Korrektheit der Antwort?\",\n    x = \"Instruktion\",\n    y = \"Reaktionszeit (s)\",\n    fill = \"Korrektheit der Antwort\"\n  ) +\n  scale_fill_manual(values = c(\"seagreen\", \"lightblue\")) +\n  theme_minimal()\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv') \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nacc_rt_individual &lt;- d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt))\n\np &lt;- acc_rt_individual |&gt;\n    ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(width = 0.1, alpha = 0.4, size = 1.8, height = 0) +\n    geom_boxplot(width = 0.3, color = \"black\", linewidth = 0.4, fill = NA) +\n    scale_color_manual(values = c(genau = \"darkturquoise\",\n                                  schnell = \"deeppink\"))+\n    labs(\n        title = \"Genauigkeit der Vpn im Random Dot Experiment\",\n        subtitle = \"Unterscheidet sich die Genauigkeit der Vpn zwischen den Bedingungen?\",\n        x = \"Bedingung\",\n        y = \"Anteil richtiger Antworten\"\n\n    ) +\n    theme_minimal(base_size = 14) +\n    theme(legend.position = \"none\")\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#Fragestellung: Sind Personen in der speed condition wirklich schneller als\n#in der accuracy condition?\n\ndfilter &lt;- d |&gt;\n    filter(!is.na(rt)) |&gt; #fehlende Werte von rt entfernen\n    filter(rt &gt; 0.099 & rt &lt; 8) |&gt; #zu tiefe und hohe rt Werte entfernen\n    group_by(condition, id) |&gt;\n    summarise(mean_rt = mean(rt), #f√ºr jede Person die mittlere rt berechnen\n              accuracy = mean(corr)) |&gt; #wie viel % der Antworten waren richtig pro Person\n    filter(accuracy &gt; 0.5) #Werte unterhalb der Ratewahrscheinlichkeit entfernen\n\n\np = dfilter |&gt;\n    ggplot(aes(x = condition,\n               y = mean_rt,\n               color = condition,\n               fill = condition)) +\n    geom_violin(alpha = 0.5, width = 0.5, color = \"black\") +\n    geom_jitter(width = 0.1, alpha = 0.1, color = \"black\") +\n    scale_fill_manual(values = c(accuracy = \"violetred\",\n                                 speed = \"cornflowerblue\"),\n                      name = \"Instruktion\",\n                      labels = c(speed = \"So schnell wie m√∂glich\",\n                                 accuracy = \"So genau wie m√∂glich\")) +\n    scale_x_discrete(labels = c(speed = \"Schnelligkeit\",\n                                accuracy = \"Genauigkeit\")) +\n    labs(title = \"Reaktionszeiten nach Bedingung\",\n         y = \"Reaktionszeit [ms]\",\n         x = \"Instruktion\",\n         subtitle = \"Wie ver√§ndert sich die Reaktionsgeschwindigkeit \\nbei unterschiedlichen Instruktionen?\") +\n    theme_classic(base_size = 12)\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(patchwork)\n\ndata &lt;- d |&gt;\n  group_by(trial, condition) |&gt;\n  summarise(\n    N = n(),\n    ncorrect = sum(corr),\n    accuracy = mean(corr),\n    median_rt = median(rt))\n\n\np1 = data |&gt;\n    ggplot(data = data,\n           mapping = aes(x = condition, \n                         y = median_rt, \n                         color = condition)) +\n             geom_jitter(size = 3, alpha = 0.4, \n                         width = 0.2, height = 0) + \n             geom_violin(width = 0.2, alpha = 0, color = 'grey1') + \n             scale_color_manual(values = c(accuracy = \"darkorchid3\", \n                                           speed = \"yellow3\")) + \n  labs(x = 'Bedingung',\n       y = 'Reaktionszeit',\n       title = 'Speed-Accuracy-Trade-Off',\n       subtitle = 'Wie ver√§ndern sich die Reaktionszeit und Accuracy in Abh√§ngigkeit der Bedingung?') +\n  theme_minimal(base_size = 10) + \n  theme(legend.position = 'none')\n\np2 = data |&gt; \n  ggplot(data = data, \n         mapping = aes(x = condition, \n                       y = accuracy,\n                       color = condition)) +\n  geom_jitter(size = 3, alpha = 0.4, \n              width = 0.2, height = 0) +\n  geom_violin(width = 0.2, alpha = 0, color = 'grey1') + \n  scale_color_manual(values = c(accuracy = 'darkorchid3',\n                                speed = 'yellow3')) + \n  labs(x = 'Bedingung', \n       y = 'Accuracy') +\n  theme_minimal() + \n  theme(legend.position = 'none')\n\n  \np1 + p2\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd &lt;- d |&gt;\n  mutate(condition = as.factor(condition))\n#glimpse(d)\n#hist(d$rt)\n\nd_plot &lt;- d |&gt;\n  select(id, condition, corr, rt) |&gt;\n  filter(rt &lt;= 12)\n#hist(d_plot$rt)\n\n\n#Reaktionszeiten pro Bedingung\nd_summary_rt &lt;- d_plot |&gt;\n  group_by(condition) |&gt;\n  summarise(mean_rt = mean(rt, na.rm = TRUE),\n            sd_rt = sd(rt, na.rm = TRUE)) |&gt;\n  ungroup()\n#glimpse(d_summary_rt)\n\n#Reaktionszeiten pro Person + Bedingung\nd_summary_id &lt;- d_plot |&gt;\n  group_by(id, condition) |&gt;\n  summarise(mean_rt_id = mean(rt, na.rm = TRUE)) |&gt;\n  ungroup()\n#glimpse(d_summary_id)\n\n\n#Plot f√ºr Reaktionszeiten pro Bedingung\np_rt = d |&gt;\n  ggplot(data = d_plot,\n         mapping = aes(x = condition,\n                       y = rt)) +\n  geom_jitter(data = d_summary_id,\n              mapping = aes(x = condition,\n                            y = mean_rt_id,\n                            group = id),\n              alpha = 1, width = 0.2, color = \"pink\") +\n  geom_boxplot(alpha = 0.25, width = 0.7) + #auch mal mit geom_violin versuchen\n  geom_pointrange(data = d_summary_rt,\n                  aes(x = condition,\n                      y = mean_rt,\n                      ymin = mean_rt - sd_rt,\n                      ymax = mean_rt + sd_rt),\n                  color = \"olivedrab\",\n                  size = 1) +\n  labs(title = \"Reaktionszeiten nach Bedingung\",\n       subtitle = \"Unterscheidet sich die Reaktionszeit nach Bedingung?\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit [s]\") +\n  theme_minimal()\n#p_rt\n\n\n\n#Accuracy pro Person + Bedingung\nd_accuracy_id &lt;- d_plot |&gt;\n  group_by(id, condition) |&gt;\n  summarise(mean_acc_id = mean(corr, na.rm = TRUE)) |&gt;\n  ungroup()\n#hist(d_accuracy_id$mean_acc_id)\n\n#VP, die &lt; 0.4\nd_accuracy_filter &lt;- d_accuracy_id |&gt;\n  filter(mean_acc_id &lt; 0.4)\nd_accuracy_noid &lt;- d_plot |&gt;\n  filter(!id %in% c(\"sub-014\", \"sub-076\", \"sub-128\"))\n\nd_accuracy_clean &lt;- d_accuracy_noid |&gt;\n  group_by(condition) |&gt;\n  summarise(mean_acc = mean(corr, na.rm = TRUE),\n            se_acc = sd(corr, na.rm = TRUE) / sqrt(n())) |&gt;\n  ungroup()\n#glimpse(d_accuracy_clean)\n\n\n#Plot f√ºr Accuracy -&gt; Filter nach accuracy fehlt noch\np_accuracy = d |&gt;\n  ggplot(data = d_accuracy_clean,\n         mapping = aes(x = condition,\n                       y = mean_acc,\n                       fill = condition)) +\n  geom_col(width = 0.5) +\n  geom_errorbar(mapping = aes(ymin = mean_acc - se_acc,\n                              ymax = mean_acc + se_acc,\n                              width = 0.4)) +\n  labs(title = \"Accuracy nach Bedingung\",\n       subtitle = \"Unterscheidet sich die Accuracy nach Bedingung?\",\n       x = \"Bedingung\",\n       y = \"Accuracy\",\n       fill = \"Bedingung\") +\n  theme_minimal()\n#p_accuracy\n\nlibrary(patchwork)\np_rt / p_accuracy\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd &lt;- read_csv(\"data/dataset_random_dot_clean.csv\") \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np &lt;- d |&gt; \n  ggplot(aes(x = condition, y = rt, fill = condition)) +\n  geom_violin(alpha = 0.3, color = NA, width = 0.6) +\n  geom_jitter(width = 0.15, alpha = 0.2, color = \"black\", size = 0.8) +\n  stat_summary(fun = mean, geom = \"point\", shape = 21, fill = \"white\", size = 3, stroke = 1) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.15, color = \"black\") +\n  labs(title = \"Antwortzeiten im Random Dot Experiment\",\n       subtitle = \"Unterscheidet sich die Reaktionszeit je nach Instruktion (Speed vs Accuracy)?\",\n       x = \"Instruktionsbedingung\",\n       y = \"Reaktionszeit [ms]\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\")\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv') \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(naniar)\nnaniar::vis_miss(d)\n\n\n\np = d |&gt;\n  filter(rt &gt; 0.001, rt &lt; 12) |&gt;\n  ggplot(aes(x = corr, y = rt, fill = condition)) +\n  geom_boxplot(alpha = 0.4, outlier.shape = NA) +  # Boxplot\n  geom_jitter(width = 0.2, alpha = 0.05, color = \"black\") +  # Rohdaten\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 3, color = \"red\") +\n  facet_wrap(~condition) +\n  scale_fill_manual(values = c(\"skyblue3\", \"seagreen\")) + # Farben\n  labs( # Beschriftungen\n    title = \"Reaktionszeitvergleich und Anzahl \n    korrekter Antworten nach Bedingungen\",\n    x = \"0 = Falsch, 1 = Richtig\",\n    y = \"Reaktionszeit (in Sekunden)\",\n    subtitle = \"Unterscheidet sich die Anzahl korrekter Antworten wenn man schnell\n    reagieren musste im Vergleich zu wenn man genau antworten musste?\") +\n  scale_y_continuous(breaks = seq(0,12, by = 2)) +\n  scale_x_continuous(breaks = seq(0,1, by = 1)) +\n  theme_minimal(base_size = 13) # Theme\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n  filter(rt &gt;= 0.2 & rt &lt;= 120) |&gt; \n  ggplot(aes(x = factor(condition, levels = c(\"accuracy\", \"speed\"), labels = c(\"Genauigkeit\", \"Geschwindigkeit\")),\n             y = rt, \n             color = factor(corr, levels = c(0, 1), labels = c(\"Falsch\", \"Richtig\"))))+\n  facet_wrap(~ corr, labeller = as_labeller(c(\"0\" = \"Falsch\", \"1\" = \"Richtig\")))+\n  geom_jitter(alpha = 0.4, width = 0.4)+\n  geom_boxplot(color = \"black\")+\n  labs(title = \"Random Dot Experiment: Reaktionszeiten nach Antwortkorrektheit und Experimentalbedingung\", \n       subtitle = \"Sind richtige Antworten mit l√§ngeren Reaktionszeiten verbunden, unabh√§ngig von der Instruktion?\",\n       x = \"Experimentalbedingungen (Instruktion)\", \n       y = \"Reaktionszeit in Sekunden\",\n       color = \"Korrektheit der Antwort\",\n       caption = \"Reaktionszeiten unter 0.2 s und √ºber 120 s wurden entfernt\")+\n  scale_color_manual(values = c(\"Falsch\" = \"red\", \"Richtig\" = \"darkgreen\"))+\n  theme_bw()\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('/data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n# Durchschnittliche Korrektheit & Reaktionszeit pro Bedingung berechnen\nd_summary &lt;- d |&gt;\n    group_by(condition) |&gt;\n    summarise(\n        mean_corr = mean(corr, na.rm = TRUE),\n        mean_rt = mean(rt, na.rm = TRUE)  # Durchschnittliche Reaktionszeit\n    )\n\n# Plot mit Balkendiagramm und RT als Text auf den Balken\np &lt;- ggplot(d_summary, aes(x = condition, y = mean_corr, fill = condition)) +\n    geom_col() +  # Balkendiagramm f√ºr Korrektheit\n    geom_text(aes(label = paste0(\"Reaktionszeit Durchschnitt:\\n\",round(mean_rt, 2), \" ms\")), vjust = 2, color = \"black\", size = 4, alpha = 0.7) +  # RT als Text auf den Balken\n    scale_fill_manual(values = c(\"orange\",\"lightblue\")) +\n    labs(\n        title = \"Random Dot\",\n        subtitle = \"Einfluss der Instruktion auf die G√ºte der Reaktion\",\n        x = \"Instruktion\",\n        y = \"G√ºte der Reaktion\",\n        fill = \"Instruktion\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"none\")  # Entferne die Legende, da die 'condition' bereits durch die Farben dargestellt wird\n\n# Plot anzeigen\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n\n\nd10 &lt;- d |&gt; \n  filter(rt &lt;= 10)\n#d10\n\n\nggplot(data = d10,\n       mapping = aes(x = condition, \n                     y = rt, \n                     color = factor(corr))) +\n  geom_jitter(width = 0.4, alpha = 0.5) +\n  scale_color_manual(name = \"Antwort\",\n                     labels = c(\"Falsch\", \"Richtig\"),\n                     values = c(\"#cb4335\", \"#82e0aa\")) +\n  geom_boxplot(width = 0.3) +\n  labs(title = \"Auswertung Random Dot Experiment\",\n       subtitle = \"Gibt es einen Unterschied in den Reaktionszeiten zwischen den beiden Bedingungen\n       und unterscheiden sie sich abh√§ngig von der Korrektheit der Antworten?\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeiten\") +\n  scale_x_discrete(labels = c(\"accuracy\" = \"Genauigkeit\",\n                              \"speed\" = \"Geschwindigkeit\")) +\n  theme_minimal()\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n  \n\n# Frage: Gibt es in den beiden Bedingungen Lern- oder eher Erm√ºdungseffekte?\n\n# Werte ausschliessen\nd &lt;- d |&gt; \n  filter(!is.na(rt)) |&gt; # fehlende Werte \n  filter(rt &gt; 0.099 & rt &lt; 10) # zu schnelle/langsame Antworten\n\n\nrt_Werte &lt;- d |&gt; \n  group_by(id, trial, rt, condition)|&gt;\n  summarise(N = n(),\n            accuracy = mean(corr))\n\n# Personen unter chance level ausschliessen\nrt_Werte &lt;- rt_Werte |&gt; \n  filter(accuracy &gt;= 0.5) \n\n# visualisieren\np &lt;- rt_Werte |&gt; \n  ggplot(aes(x = trial, y = rt, color = condition)) +\n  geom_point(size = 0.5, alpha = 0.4) +\n  scale_color_manual(values = c(speed = \"peachpuff4\",\n                                accuracy = \"cadetblue\")) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"grey30\") +\n  facet_wrap(~ condition) +\n  labs(x = \"Trial\",\n       y = \"Reaktionsgeschwindigkeit (s)\",\n       title = \"Verlaufseffekte\",\n       subtitle = \"Gibt es Lern- bzw. Erm√ºdungseffekte in den beiden Bedingungen?\") +\n  theme_test() +\n  theme(legend.position = \"none\")\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv') \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(ggplot2)\n\nd_filtered &lt;- d |&gt; \n  filter(rt &lt;= 12)\n\nggplot(d_filtered) +\n  aes(x = condition, y = rt, fill = condition) +\n  geom_boxplot() +\n  scale_fill_hue(direction = 1) +\n  labs(\n    x = \"Condition\",\n    y = \"Reaction time \",\n    title = \"√úbung 3: Daten visualisieren \",\n    subtitle = \"Reaction time under speed and accuracy condition\",\n    fill = \"Condition\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 3L)) +\n  ylim(0, 12)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd &lt;- d |&gt;\n  filter(rt &lt; 5)\n\nacc_rt_vpn &lt;- d |&gt;\ngroup_by(id, condition) |&gt;\n  summarise(\n    N = n(),\n    ncorrect = sum(corr),\n    accuracy = mean(corr),\n    mean_rt = mean(rt)\n  )\nacc_rt_vpn\n\nplot &lt;- acc_rt_vpn |&gt;\n  ggplot(mapping = aes(x = condition,\n                       y = mean_rt,\n                       colour = condition,\n                       fill = condition)) +\n  geom_boxplot() +\n  scale_fill_manual(values = c( \"accuracy\" = \"pink\",\n                                \"speed\" = \"lightblue\")) +\n  scale_colour_manual(values = c(\"accuracy\" = \"pink\",\n                                 \"speed\" = \"lightblue\")) + \n  geom_jitter(colour = \"cyan4\", width = 0.2, size = 1.8, alpha = 0.4) +\n  geom_hline(yintercept = 5) +\n  theme_light() +\n  labs(x = \"Bedingung\",\n       y = \"Mittelwert der Reaktionszeit\",\n       condition = \"Bedingung\",\n       title = \"Reaktionszeit: Accuracy vs. Speed\",\n       subtitle = \"Unterscheiden sich die Reaktionszeiten zwischen der Bedingung Accuracy und der Bedingung Speed?\")\n\nplot\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np &lt;- d |&gt; \n  ggplot(aes(x = direction, y = rt, fill = direction)) +\n  \n  # Violinplot f√ºr Verteilung\n  geom_violin(trim = FALSE, alpha = 0.6, color = NA) +\n  \n  # Rohdatenpunkte ‚Äì etwas kleiner & transparenter\n  geom_jitter(width = 0.15, size = 0.6, alpha = 0.15, color = \"gray40\") +\n  \n  # Mittelwert sichtbar machen: gr√∂√üer, mit dickem Rand\n  stat_summary(\n    fun = mean,\n    geom = \"point\",\n    shape = 21,\n    size = 4.5,\n    fill = \"white\",\n    stroke = 1.1,\n    color = \"black\"\n  ) +\n  \n  # Standardfehler (Error Bars)\n  stat_summary(\n    fun.data = mean_se,\n    geom = \"errorbar\",\n    width = 0.2,\n    color = \"black\"\n  ) +\n  \n  # Farben: skyblue & orchid\n  scale_fill_manual(values = c(\"skyblue\", \"orchid\")) +\n  \n  # Titel, Subtitle, Achsenbeschriftungen\n  labs(\n    title = \"Reaktionszeiten im Random-Dot-Experiment\",\n    subtitle = \"Unterscheiden sich Reaktionszeiten zwischen Bewegungsrichtungen?\",\n    x = \"Bewegungsrichtung\",\n    y = \"Reaktionszeit (ms)\",\n    fill = \"Richtung\"\n  ) +\n  \n  # Klarer, moderner Stil\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15),\n    plot.subtitle = element_text(size = 11),\n    axis.title = element_text(size = 12),\n    legend.position = \"top\"\n  )\n\n# Plot anzeigen\nprint(p)\n\n# Plot erstellen\np &lt;- d |&gt; \n  ggplot(aes(x = direction, y = rt, fill = direction)) +\n  \n  # Violinplot f√ºr Verteilung\n  geom_violin(trim = FALSE, alpha = 0.6, color = NA) +\n  \n  # Rohdatenpunkte (leicht transparent, nicht zu gro√ü)\n  geom_jitter(width = 0.15, size = 0.6, alpha = 0.15, color = \"gray40\") +\n  \n  # Mittelwert sichtbar machen (wei√ü, mit schwarzem Rand)\n  stat_summary(\n    fun = mean,\n    geom = \"point\",\n    shape = 21,\n    size = 4.5,\n    fill = \"white\",\n    stroke = 1.1,\n    color = \"black\"\n  ) +\n  \n  # Standardfehler als Errorbars\n  stat_summary(\n    fun.data = mean_se,\n    geom = \"errorbar\",\n    width = 0.2,\n    color = \"black\"\n  ) +\n  \n  # Farben setzen: skyblue & orchid\n  scale_fill_manual(values = c(\"skyblue\", \"orchid\")) +\n  \n  # Titel, Subtitle, Achsenbeschriftungen\n  labs(\n    title = \"Reaktionszeiten im Random-Dot-Experiment\",\n    subtitle = \"Unterscheiden sich Reaktionszeiten zwischen Bewegungsrichtungen?\",\n    x = \"Bewegungsrichtung\",\n    y = \"Reaktionszeit (ms)\",\n    fill = \"Richtung\"\n  ) +\n  \n  # Theme mit wei√üem Hintergrund und feinen Gitterlinien\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15),\n    plot.subtitle = element_text(size = 11),\n    axis.title = element_text(size = 12),\n    legend.position = \"top\",\n    \n    # Wei√üer Hintergrund\n    panel.background = element_rect(fill = \"white\", color = NA),\n    plot.background = element_rect(fill = \"white\", color = NA),\n    \n    # Dezente Gitterlinien\n    panel.grid.major = element_line(color = \"gray85\"),\n    panel.grid.minor = element_blank()\n  )\n\n# Plot anzeigen\nprint(p)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n\n## Graphik um Verteilung der Daten zu schauen und event. Ausreisser raus\n\nggplot(d, aes(x = id, y = rt)) +\n  geom_boxplot(outlier.color = \"red\", outlier.shape = 8, alpha = 0.6) +\n  labs(\n    title = \"Ausreissercheck: Reaktionszeit pro Versuchsperson\",\n    x = \"ID\",\n    y = \"Reaktionszeit (ms)\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(axis.text.x = element_blank())\n\n## Ich filtere die 2 Ausreisser raus indem ich &gt;1000ms Reaktionszeit rausnehme (danach n=238)\nd_clean = d |&gt; \n  filter(rt &lt;= 1000)\n\n## Mache erst eine Summary um √ºbersicht der Daten zu bekommen\nsummary_table &lt;- d_clean |&gt;\n  group_by(condition) |&gt;\n  summarise(\n    trials = n(),\n    mean_rt = mean(rt, na.rm = TRUE),\n    sd_rt = sd(rt, na.rm = TRUE),\n    accuracy_rate = mean(corr, na.rm = TRUE),  # Anteil korrekter Antworten\n    .groups = \"drop\"\n  )\n\n#print(summary_table)\n\n## PLOT (Rohdaten + MW/SD )\n\n# Ich filtere zuerst nur korrekte Antworten f√ºr meinen Plot\nd_corr &lt;- d_clean %&gt;% filter(corr == 1)\n\nggplot() +\n geom_jitter( \n    data = d_corr,\n    aes(x = condition, y = rt, color = condition),# Rohdatenpunkte\n    alpha = 0.2,\n    width = 0.2,\n    size = 1,\n    show.legend = FALSE\n  ) +\n  geom_point(\n    data = summary_table,\n    aes(x = condition, y = mean_rt),  # Mittelwertpunkte\n    shape = 18,\n    size = 3,\n    color = \"black\"\n  ) +\n  geom_errorbar(\n    data = summary_table,\n    aes(x = condition, ymin = mean_rt - sd_rt, ymax = mean_rt + sd_rt),# SD-Balken\n    width = 0.2,\n    color = \"black\"\n  ) +\n  scale_color_manual(values = c(\"speed\" = \"turquoise\", \"accuracy\" = \"orange\")) +# Farben\n  # Achsen, Titel etc.\n  labs(\n    title = \"Reaktionszeiten im Random Dot Experiment\",\n    subtitle = \"Unterscheiden sich die Reaktionszeiten zwischen Speed- und Accuracy-Bedingung?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Reaktionszeit (ms)\",\n    caption = \"n= 238 | Nur korrekte Antworten | Ausreisser (&gt;1000 ms) entfernt | Balken = MW + SD\"\n  ) +\n  # Theme\n  theme_minimal()  +\ntheme( plot.caption = element_text(hjust = 0)  # Links ausrichten\n  )\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv') \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(aes(x = condition, y = rt, color = condition)) + #Rohdaten nach Bed. gruppiert\n    geom_jitter(alpha = 0.4, width = 0.5, size = 1) +\n    geom_violin(alpha = 0.4, width = 0.2, color = \"black\") + #Zusammenfassendes Mass\n    scale_color_manual(values = c(accuracy = \"deeppink\",\n                                  speed = \"darkcyan\")) +\n    labs(\n        x = \"Instruction Condition\",\n        y = \"Reaction Time (ms)\",\n        title = \"Impact of Instruction Type on Reaction Speed\",\n        subtitle = \"Does Emphasis on Accuracy vs. Speed Affect Reaction Times?\") +\n    theme_linedraw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nd$corr_label &lt;- ifelse(d$corr == 1, \"correct\", \"incorrect\")\nfill_colors &lt;- c(\"correct\" = \"#B8E186\", \"incorrect\" = \"#DE77AE\")  \npoint_colors &lt;- c(\"correct\" = \"#4DAC26\", \"incorrect\" = \"#D01C8B\") \n\np = d |&gt;\n    filter(rt &lt;= 12) |&gt;\n    ggplot(aes(x = condition, y = rt, fill = corr_label)) +\n    geom_violin(\n        position = position_dodge(0.9),\n        trim = FALSE,\n        alpha = 0.6\n    ) +\n    geom_jitter(\n        aes(color = corr_label),\n        size = 0.6,\n        alpha = 0.15,\n        position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.9)\n    ) +\n    stat_summary(\n        fun = mean,\n        geom = \"crossbar\",\n        width = 0.4,\n        fatten = 2,\n        color = \"black\",\n        position = position_dodge(0.9)\n    ) +\n    scale_fill_manual(values = fill_colors, name = \"Antwort\") +\n    scale_color_manual(values = point_colors, guide = \"none\") +\n    labs(\n        title = \"Reaktionszeiten nach Instruktion und Antwortgenauigkeit\",\n        subtitle = \"Beeinflusst die Instruktion (Speed vs Accuracy), wie schnell und korrekt geantwortet wird?\",\n        x = \"Instruktion\",\n        y = \"Reaktionszeit (s)\"\n    ) +\n    theme_minimal() +\n    theme(\n        plot.title = element_text(size = 14, face = \"bold\"),\n        plot.subtitle = element_text(size = 12, face = \"italic\"),\n        axis.text.x = element_text(size = 12),\n        legend.position = \"top\"\n    )\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(aes(x = condition, y = rt, fill = condition)) + \n             geom_violin(trim = FALSE, alpha = 0.6) +\n             geom_boxplot(width = 0.2, color = \"black\", alpha = 0.5) +\n             stat_summary(fun = \"mean\", geom = \"point\", shape = 18, size = 3, color = \"red\") +\n             labs(\n               title = \"Verteilung der Reaktionszeiten nach Bedingung\",\n               subtitle = \"Welche Bedingung f√ºhrt zu schnelleren Reaktionszeiten?\",\n               x = \"Bedingung\",\n               y = \"Reaktionszeit (Sekunden)\",\n               caption = \"Datenquelle: Random Dot Experiment\"\n             ) +\n             scale_fill_manual(values = c(\"blue\", \"green\")) +\n             theme_minimal() +\n             theme(\n               plot.title = element_text(hjust = 0.5),\n               plot.subtitle = element_text(hjust = 0.5),\n               plot.caption = element_text(size = 8, face = \"italic\")\n             )\n          p\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n\np = d |&gt;\n  ggplot(aes(x = condition, y = rt, color = condition)) +\n  geom_point(size = 2, alpha = 0.5, position = position_jitter(width = 0.2)) +\n  geom_boxplot(aes(fill = condition), alpha = 0.3, width = 0.4) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  scale_fill_manual(values = c(\"blue\", \"red\")) +\n  labs(\n    title = \"Antwortzeiten nach Instruktionsbedingung\",\n    subtitle = \"Wie unterscheiden sich die Antwortzeiten zwischen den Instruktionsbedingungen?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Antwortzeit (s)\"\n  ) +\n  theme_minimal()\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nagg_data &lt;- d |&gt;\n  filter(rt &lt; 10) |&gt;\n  group_by(id, condition) |&gt;\n  summarise(mean_rt = mean(rt, na.rm = TRUE), .groups = \"drop\")\n\np &lt;- agg_data |&gt;\n  ggplot(aes(x = condition, y = mean_rt, color = condition)) +\n  geom_jitter(size = 3, alpha = 0.4, \n              width = 0.2, height = 0) +\n  geom_boxplot(width = 0.5, alpha = 0, color = \"black\") +\n  scale_color_manual(values = c(speed = \"skyblue\",\n                                accuracy = \"tomato\")) +  \n  stat_summary(fun = mean, geom = \"point\", size = 4, shape = 18) +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.2) +  \n  labs(\n    title = \"Reaktionszeiten nach Bedingung\",\n    subtitle = \"Gibt es einen Unterschied zwischen den Bedingungen?\",\n    x = \"Bedingung\",\n    y = \"Mittlere Reaktionszeit (s)\",\n    color = \"Bedingung\"\n  ) +\n  theme_minimal()\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code: Code von Leo Rieder und Vivienne Sch√§ublin\n\nd &lt;- read.csv(\"data/dataset_random_dot_clean.csv\") %&gt;%\n  mutate(condition = as.factor(condition)) # Variable condition zu Faktor konvertieren (wieso? ist das nicht schon der Fall?)\n\n#glimpse(d)\n\n# Ein Plot erstellen f√ºr die Fragestellung: Ist die Reaktionszeit in der Speed-Bedingung k√ºrzer?\nggplot(data = d,\n       mapping = aes(x = condition,\n                     y = rt)) +\n  geom_jitter(width = 0.4, color= \"#009ACD\", alpha = 0.3) + \n  geom_boxplot(width = 0.2, color= \"#FF34B3\", alpha = 0.5) + # Boxplot-Farbe und transparenz, Boxplot als 2. Aufgelistet, dass es √ºber den blauen Rohdatenpunkten erscheint und transparent, dass Rohdaten sichtbar bleiben.\n  labs(title = \"Vergleich der Reaktionszeiten zwischen den beiden Bedingungen\", \n       subtitle = \"Ist die Reaktionszeit in der Speed-Bedingung k√ºrzer?\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit (ms)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5), # Den Titel und Subtitel mittig ausrichten\n        plot.subtitle = element_text(hjust = 0.5))\n\n\n# Zahlen zum Boxplot: hier k√∂nnen die Werte vom Mean und der SD ausgegeben werden\nunique(d$condition)\n# Mean und AD f√ºr die Bedingung speed berechnen\nd_speed &lt;- d %&gt;% \n  filter(condition == \"speed\")\n\nd_speed_summary &lt;- d_speed %&gt;% \n  summarise(mean_rt = mean(rt),\n            sd_value = sd(rt))\n#glimpse(d_speed_summary)\n\n# Mean und SD f√ºr die Bedingung accuracy berechenen\nd_accuracy &lt;- d %&gt;% \n  filter(condition == \"accuracy\")\n\nd_accuracy_summary &lt;- d_accuracy %&gt;% \n  summarise(mean_rt = mean(rt),\n                  sd_value = sd(rt))\n#glimpse(d_accuracy_summary)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\np = d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(N = n(), ncorrect = sum(corr), accuracy = mean(corr), median_rt = median(rt)) |&gt;\n    ggplot(mapping = aes(x = condition, y = accuracy, colour = condition)) +\n    geom_boxplot(width = 0.3) +\n    geom_jitter(width = 0.1) +\n    scale_colour_manual(labels = c(accuracy = \"genau\", speed = \"schnell\"), \n                        values = c(accuracy = \"mediumseagreen\", speed = \"coral\")) +\n    scale_x_discrete(labels = c(accuracy = \"genau\", speed = \"schnell\")) +\n    labs(title = \"Exaktheit der Versuchspersonen im Random Dot Experiment\",\n         subtitle = \"Beeinflusst die Art der Bedingung die Exaktheit der Versuchspersonen?\",\n         x = \"Bedingung\",\n         y = \"Anteil korrekter Antworten\") +\n    theme_classic()\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nd_corr &lt;- d %&gt;%\n  filter(corr == 1) %&gt;%\n  group_by(direction) %&gt;%\n  mutate(id = row_number())  # Jeder Punkt bekommt eine y-Position\n\n# Zusammenfassung\nsummary_d &lt;- d_corr %&gt;%\n  group_by(direction) %&gt;%\n  summarise(count = n())\n\n# Plot\np &lt;- ggplot() +\n  # Rohdaten\n  geom_point(data = d_corr, aes(x = direction, y = id), \n             position = position_jitter(width = 0.2), \n             shape=21, \n             fill=\"lightgrey\", \n             color=\"black\", \n             alpha = 0.1, ) +\n  # Liniendiagramm mit Punkten\n  geom_line(data = summary_d, aes(x = direction, y = count, group = 1), color = \"lightblue\", size = 1.5) +\n  geom_point(data = summary_d, aes(x = direction, y = count), color = \"lightpink\", size = 4) +\n  #Beschriftung\n  labs(\n    title = \"Einfluss der Bewegungsrichtung auf richtige Antworten\",\n    subtitle = \"Welche Seite produziert mehr richtige Antworten?\",\n    x = \"Bewegungsrichtung\",\n    y = \"Anzahl richtiger Antworten\"\n  ) +\n  theme_minimal()\n        \np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n#str(d)\n\n# Daten filtern: Reaktionszeiten &lt;= 12 Sekunden\nd_filtered &lt;- d %&gt;%\n  filter(rt &lt;= 12)\n\nd_filtered$condition &lt;- factor(d_filtered$condition, levels = c(\"accuracy\", \"speed\"))\n\n\n\np &lt;- ggplot(d_filtered, aes(x = condition, y = rt, color = condition)) +\n  geom_violin(trim = FALSE, fill = NA, size = 1.2) +\n  geom_jitter(width = 0.2, alpha = 0.6) +\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 4, color = \"darkred\") +\n  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1),\n               geom = \"errorbar\", width = 0.2, color = \"darkred\") +\n  scale_color_manual(values = c(\"accuracy\" = \"#1f78b4\", \"speed\" = \"#33a02c\")) +\n  labs(\n    title = \"Reaktionszeiten nach Instruktionstyp\",\n    subtitle = \"Wie ver√§ndert sich das Entscheidungsverhalten von Menschen, je nachdem wie sie instruiert wurden?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Reaktionszeit (Sekunden)\",\n    color = \"Bedingung\"\n  ) +\n  theme_minimal(base_size = 14)\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse) \nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(aes(x = condition, y = rt, color = condition)) + #Rohdaten nach Bed. gruppiert\n    geom_jitter(alpha = 0.4, width = 0.5, size = 1) +\n    geom_violin(alpha = 0.4, width = 0.2, color = \"black\") + #Zusammenfassendes Mass\n    scale_color_manual(values = c(accuracy = \"#FFB6C1\",\n                                  speed = \"#ADD8E6\")) +\n    labs(\n        x = \"Instruction Condition\",\n        y = \"Reaction Time (ms)\",\n        title = \"Impact of Instruction Type on Reaction Speed\",\n        subtitle = \"Does Emphasis on Accuracy vs. Speed Affect Reaction Times?\") +\n    theme_linedraw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n# Mittelwert Reaktionszeit berechnen\nmean_rt &lt;- mean(d$rt, na.rm = TRUE)\n#mean_rt\n\n# Reaktionszeit bereinigen ‚Äì sehr schnelle oder sehr langsame ausschlie√üen\nd &lt;- d |&gt; \n  filter(rt &gt; 0.1, rt &lt; 8)\n\n# Plot erstellen\np &lt;- d |&gt;\n  ggplot(aes(x = condition, y = rt, fill = condition)) +\n  geom_jitter(width = 0.25, alpha = 0.3, size = 1.5, color = \"gray30\") +\n  geom_violin(alpha = 0.4, trim = FALSE) +\n  stat_summary(fun = mean, geom = \"point\", size = 2, color = \"black\") +\n  labs(\n    title = \"Instruktion beeinflusst Reaktionsgeschwindigkeit\",\n    subtitle = \"Sind Reaktionen bei Speed schneller als bei Accuracy?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Reaktionszeit (Sekunden)\"\n  ) +\n  scale_fill_manual(values = c(\"tomato\", \"skyblue3\")) +\n  theme_light(base_size = 13)\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#Datensatz einlesen und Variablen konvertieren\nd_AW &lt;- d |&gt; filter(rt &lt; 12) |&gt;\n  mutate(\n    condition = as.factor(condition), # Variable condition zu Faktor konvertieren\n    corr = as.factor(corr)) # Variable corr zu Faktor konvertieren\n\n\n\n#Plot erstellen\n#Labels umbenennen\nfacet_labels &lt;- c(\"accuracy\" = \"Genauigkeit\", \"speed\" = \"Geschwindigkeit\")\ncondition_labels &lt;- c(\"0\" = \"falsch\", \"1\" = \"richtig\")\n\n#Plot Design\np = d_AW |&gt;\n  ggplot(aes(x = corr, y = rt)) +\n  geom_jitter(alpha = 0.2, color = \"gray\") +\n  geom_boxplot(aes(fill = corr)) +\n  labs(x = \"Bedingungen\",\n       y = \"Reaktionszeit in [s]\",\n       title = \"Vergleich Bedingungen\",\n       subtitle = \"Wie f√§llt die Reaktionszeit bei falschen\\nbzw. richtigen Antworten aus?\",\n       caption = \"falsch bzw. richtig = gegebene Antwort // braun: MW +/- 1SD\") +\n  stat_summary(fun.data = mean_sdl, #+/- 1 Standardabweichung darstellen\n               fun.args = list(mult = 1), \n               geom = \"errorbar\", \n               color = \"chocolate4\",\n               width = 0.2) +\n  stat_summary(fun = mean,\n               geom = \"point\", #Standardabweichung darstellen\n               color = \"chocolate4\", \n               shape = 18) +\n  scale_y_continuous(breaks = seq(0, 12, by = 2)) + #y-Achse Intervall √§ndern\n  scale_x_discrete(labels = condition_labels) +  #x-Achsen-Beschriftung √§ndern\n  scale_fill_manual(values = c('0' = 'peachpuff1', '1' = 'paleturquoise1')) + #0 = falsch, 1 = richtig\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5), #zentrieren von Titel\n        plot.subtitle = element_text(hjust = 0.5), #zentrieren von Subtitel\n        plot.caption = element_text(hjust = 0.5)) + #zentrieren von Caption\n  facet_wrap(~condition, labeller = labeller(condition = facet_labels))\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n  ggplot(aes(x = corr, y =rt, fill= condition)) +\n  geom_violin(alpha = 0.7, linetype = 7, show.legend = FALSE) + # Zusammenfassendes Mass Violinplot \n  geom_jitter(width = 0.2, alpha = 0.05, color = \"black\", show.legend = FALSE) + # Rohdaten \n  stat_summary(fun = mean, geom = \"point\", shape = 3, size = 4, color = \"red\", show.legend = FALSE) +\n  facet_wrap(~condition) +\n  scale_fill_manual(values = c(\"skyblue\", \"red2\"))  + # Mind. 2 unterschiedliche Farben (schwarz und weiss ausgenommen)\n  theme_minimal(base_size = 14) + # Theme verwenden\n  scale_x_continuous(breaks = seq(0,1, by = 1)) + # Beschriftungen: Achsenbeschriftungen\n  scale_y_continuous(breaks = seq(0,12, by = 1)) +\n  theme(legend.position = \"right\") +\n  labs( # Beschriftungen: Titel, Subtitel\n    title = \"Reaktionszeit nach Bedingung und Korrektheit\",\n    subtitle = \"Wie unterscheiden sich die Verteilungen der Reaktionszeiten zwischen den Bedingungen?\", \n    x = \"0 = Falsche Antworten, 1 = Richtige Antworten\",\n    y = \"Reaktionszeit in Sekunden\",\n    caption = \"\",\n    tag = \"\"\n  )\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd_filtered &lt;- d %&gt;%\n    filter((rt &lt; 12) & (rt &gt; 0.1))\n\n#glimpse(d_filtered)\n\nd_filtered_summary &lt;- d_filtered %&gt;%\n    summarise(mean_corr = mean(corr),\n              sd_corr = sd(corr),\n              mean_rt = mean(rt),\n              sd_rt = mean(rt))\n\n#glimpse(d_filtered_summary)\n\np = d_filtered |&gt;\n    ggplot(data = d_filtered,\n           mapping = aes(x = corr,\n                         y = rt)) +\n        geom_boxplot(width = 0.3) +\n        geom_jitter(width = 0.1) +\n        geom_hline(data = d_filtered_summary,\n                   mapping = aes(yintercept = mean_rt),\n                     colour = 'red') +\n        geom_hline(data = d_filtered_summary,\n           mapping = aes(yintercept = mean_rt + sd_rt),\n           linetype = 'dashed',\n           colour = 'red') +\n        geom_hline(data = d_filtered_summary,\n            mapping = aes(yintercept = mean_rt - sd_rt),\n            linetype = 'dashed',\n            colour = 'red') +\n        geom_vline(data = d_filtered_summary,\n            mapping = aes(xintercept = mean_corr),\n            colour = 'blue') +\n        geom_vline(data = d_filtered_summary,\n            mapping = aes(xintercept = mean_corr + sd_corr),\n            linetype = 'dashed',\n            colour = 'blue') +\n        geom_vline(data = d_filtered_summary,\n            mapping = aes(xintercept = mean_corr - sd_corr),\n            linetype = 'dashed',\n            colour = 'blue') +\n        labs(title = \"Random-Dot Experiment Boxplot\",\n             subtitle = \"Abh√§ngigkeit der Genauigkeit von der Entscheidungszeit\",\n             caption = \"Rot: Mittelwert der Entscheidungszeit, Blau: Mittelwert der Genauigkeit, Gestrichelt: Jeweilige Standardabweichung\",\n             y = \"Entscheidungszeit [s]\",\n             x = \"Genauigkeit [0,1]\") +\n        theme_minimal()\np\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv(\"data/dataset_random_dot_clean.csv\") \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n  ggplot(aes(x = corr, y = rt, fill = condition)) +\n  geom_boxplot(alpha = 0.4, outlier.shape = NA) +  # Hier wird Boxplot erstellt. Mit Alpha = 0.4 werden die Punkte ahlbtransparent dargestellt. \n                                                  # Outlier.shapte = NA =&gt; Ausreisser werden nicht extra angezeigt.\n  geom_jitter(width = 0.2, alpha = 0.05, color = \"royalblue\") +  # Rohdaten werden hier dargestellt mit Geomjitter\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 3, color = \"darkturquoise\") +  # Mittelwert wird als Extra-Punkt eingef√ºgt\n  facet_wrap(~condition) + # erstellt separate Plots f√ºr jede Bedingung nebeneinander\n  scale_fill_manual(values = c(\"lightgreen\", \"blueviolet\")) +  # Zwei Farben f√ºr Bedingungen\n  labs(\n    title = \"Random-Dot-Test\",\n    subtitle = \"H√§ngen Reaktionszeit und Genauigkeit von der Instruktionsbedingung ab?\",\n    x = \"0 = Falsch, 1 = Richtig\",\n    y = \"Reaktionszeit (in Sekunden)\",\n    caption = \"\"\n  ) +\n  scale_y_continuous(breaks = seq(0, 12, by = 2)) +\n  scale_x_continuous(breaks = seq(0, 1, by = 1)) +\n  theme_minimal(base_size = 13)\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\nRows: 15,315\nColumns: 8\n$ id        &lt;chr&gt; \"sub-007\", \"sub-007\", \"sub-007\", \"sub-007\", \"sub-007\", \"sub-‚Ä¶\n$ trial     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1‚Ä¶\n$ direction &lt;chr&gt; \"right\", \"left\", \"left\", \"right\", \"left\", \"right\", \"left\", \"‚Ä¶\n$ condition &lt;chr&gt; \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed‚Ä¶\n$ corrAns   &lt;chr&gt; \"right\", \"left\", \"left\", \"right\", \"left\", \"right\", \"left\", \"‚Ä¶\n$ resp      &lt;chr&gt; \"right\", \"right\", \"left\", \"right\", \"right\", \"left\", \"left\", ‚Ä¶\n$ corr      &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, ‚Ä¶\n$ rt        &lt;dbl&gt; 0.6537022, 0.5821858, 1.3868371, 0.9550371, 0.4990127, 0.692‚Ä¶\n\n\nRows: 1\nColumns: 2\n$ mean_rt_corr &lt;dbl&gt; 1.943695\n$ sd_rt_corr   &lt;dbl&gt; 1.892218\n\n\n\n\n\n\n\n\n\n\n\n\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd_filtered &lt;- d %&gt;%\n    filter((rt &lt; 12) & (rt &gt; 0.1))\n\nglimpse(d_filtered)\n\nd_filtered_corr &lt;- d_filtered %&gt;%\n    filter(corr == 1)\n\nd_filtered_incorr &lt;- d_filtered %&gt;%\n    filter(corr == 0)\n\nd_filtered_summary_corr &lt;- d_filtered_corr %&gt;%\n    summarise(mean_rt_corr = mean(rt),\n              sd_rt_corr = sd(rt))\n\nglimpse(d_filtered_summary_corr)\n\nd_filtered_summary_incorr &lt;- d_filtered_incorr %&gt;%\n    summarise(mean_rt_incorr = mean(rt),\n              sd_rt_incorr = sd(rt))\n\np = d_filtered |&gt;\n    ggplot(data = d_filtered,\n           mapping = aes(x = corr,\n                         y = rt)) +\n        geom_boxplot(width = 0.3) +\n        geom_jitter(width = 0.1) +\n        geom_hline(data = d_filtered_summary_corr,\n                   mapping = aes(yintercept = mean_rt_corr),\n                     colour = 'green') +\n        geom_hline(data = d_filtered_summary_corr,\n           mapping = aes(yintercept = mean_rt_corr + sd_rt_corr),\n           linetype = 'dashed',\n           colour = 'green') +\n        geom_hline(data = d_filtered_summary_corr,\n            mapping = aes(yintercept = mean_rt_corr - sd_rt_corr),\n            linetype = 'dashed',\n            colour = 'green') +\n        geom_hline(data = d_filtered_summary_incorr,\n            mapping = aes(yintercept = mean_rt_incorr),\n            colour = 'red') +\n        geom_hline(data = d_filtered_summary_incorr,\n            mapping = aes(yintercept = mean_rt_incorr + sd_rt_incorr),\n            linetype = 'dashed',\n            colour = 'red') +\n        geom_hline(data = d_filtered_summary_incorr,\n            mapping = aes(yintercept = mean_rt_incorr - sd_rt_incorr),\n            linetype = 'dashed',\n            colour = 'red') +\n        labs(title = \"Abh√§ngigkeit der Korrektheit von der Entscheidungszeit\",\n             subtitle = \"Wie unterscheiden sich die Reaktionszeiten der Korrekten Antworten, von den Inkorrekten?\",\n             caption = \"Gr√ºn: Mittelwert der Entscheidungszeit f√ºr korrekte Antworten\\nRot: Mittelwert der Entscheidungszeit f√ºr inkorrekte Antworten\\nGestrichelt: Jeweilige Standardabweichung\",\n             y = \"Entscheidungszeit [s]\",\n             x = \"Korrektheit [0,1]\") +\n        theme_minimal()\np + scale_x_continuous(breaks=seq(0,1,by=1))\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n  ggplot(aes(x = corr, y =rt, fill= condition)) +\n  geom_violin(alpha = 0.7, linetype = 7, show.legend = FALSE) + # Zusammenfassendes Mass Violinplot \n  geom_jitter(width = 0.2, alpha = 0.05, color = \"black\", show.legend = FALSE) + # Rohdaten \n  stat_summary(fun = mean, geom = \"point\", shape = 3, size = 4, color = \"red\", show.legend = FALSE) +\n  facet_wrap(~condition) +\n  scale_fill_manual(values = c(\"skyblue\", \"red2\"))  + # Mind. 2 unterschiedliche Farben (schwarz und weiss ausgenommen)\n  theme_minimal(base_size = 14) + # Theme verwenden\n  scale_x_continuous(breaks = seq(0,1, by = 1)) + # Beschriftungen: Achsenbeschriftungen\n  scale_y_continuous(breaks = seq(0,12, by = 1)) +\n  theme(legend.position = \"right\") +\n  labs( # Beschriftungen: Titel, Subtitel\n    title = \"Reaktionszeit nach Bedingung und Korrektheit\",\n    subtitle = \"Wie unterscheiden sich die Verteilungen der Reaktionszeiten zwischen den Bedingungen?\", \n    x = \"0 = Falsche Antworten, 1 = Richtige Antworten\",\n    y = \"Reaktionszeit in Sekunden\",\n    caption = \"\",\n    tag = \"\"\n  )\np",
    "crumbs": [
      "Datenvisualisieren",
      "Plot Gallery - Group 1"
    ]
  },
  {
    "objectID": "plots_group2.html",
    "href": "plots_group2.html",
    "title": "Plot Gallery - Group 2",
    "section": "",
    "text": "PlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n#install.packages(\"ggimage\")\nlibrary(ggimage)\nlibrary(magick)\nlibrary(png)\nlibrary(grid)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(tibble)\n\nd &lt;- d |&gt;\n  mutate(\n    is_accuracy = condition == \"accuracy\",\n    is_speed = condition == \"speed\")\n\nd &lt;- d |&gt;\n  filter(rt &lt; 10)\n\nd_summary &lt;- d |&gt;\n  group_by(condition, corr) |&gt;\n  summarise(avg_rt = mean(rt), .groups = \"drop\") |&gt;\n  mutate(image = ifelse(corr == 1, \"1.png\", \"0.png\"))\n\npp = d |&gt;\n  ggplot(aes(x = condition, y = rt)) +\n  \n  \n# Rohwert Datenpunkte\n  geom_jitter(aes(color = as.factor(corr)),\n              position = position_jitterdodge(jitter.width = 0.7, dodge.width = 1),\n              show.legend = FALSE,\n              alpha = 0.2,\n              size = 1.5) +\n  \n# Violinen mit Mean & SD\n  geom_violin(aes(fill = as.factor(corr)),\n              position = position_dodge(width = 1),\n              draw_quantiles = c(0.25, 0.5, 0.75),\n              alpha = 0.5,\n              width = 0.5,\n              color = alpha(\"#434255\", 0.5))+\n  \n  geom_image(data = d_summary,\n             aes(x = condition, y = avg_rt, image = image),\n             size = 0.05,\n             position = position_dodge(width = 1)) +\n  \n  # Beschriftung Skalen\n  ## Violinen\n  scale_fill_manual(values = c(\"0\" = \"#277B74\", \"1\" = \"#B8696D\"),\n                    labels = c(\"Falsch\", \"Richtig\"),\n                    name = \"\") +\n  \n  ## #f98052orange, #8088D3blau\n  \n  ## Jitter\n  scale_color_manual(values = c(\"0\" = \"#277B74\", \"1\" = \"#B8696D\")) +\n\n  \n  # Captions & Themes\n  labs(title = \"Random Dot Task\",\n       subtitle = \"Wie unterscheiden sich die Conditions in ihren Reaktionszeiten?\",\n       x = \"Condition\",\n       y = \"Reaktionszeit [s]\") +\n  \n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        plot.title = element_text(hjust = 0.5,\n                                  face = \"bold\",\n                                  color = \"#277B74\",\n                                  size = 14),\n        plot.subtitle = element_text(hjust = 0.5,\n                                     size = 11))\n\n# Dummy-Daten f√ºr die Bildlegende\nlegend_images &lt;- tibble(x = 1:2,\n                        y = 1,\n                        label = c(\"\", \"\"),\n                        image = c(\"1.png\", \"0.png\"))\n\n# Plot f√ºr die Bildlegende\nimage_legend &lt;- ggplot(legend_images, aes(x = x, y = y)) +\n  \n  geom_image(aes(image = image), \n             size = 0.5) +\n  geom_text(aes(label = label), \n            vjust = 3, \n            size = 4) +\n  xlim(0.0000000001, 3.02) + \n  ylim(0.5, 1.3) +\n  ggtitle(\"Durchschnitt RT\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 10))\n\n\nTHE_plot &lt;- pp / image_legend + plot_layout(heights = c(4, 1))\nTHE_plot\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n##Loading packages \nlibrary(ggimage)\n# install.packages(\"remotes\")\n# remotes::install_github(\"MatthewBJane/ThemePark\")\nlibrary(ThemePark)\nlibrary(magick)\nlibrary(png)\nlibrary(grid)\n\n#Preparing data for plotting\nmean_data &lt;- d |&gt; filter(rt &gt; 0.099 & rt &lt; 12) |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)) |&gt;\n          ungroup()\n\nmean_data &lt;- mean_data |&gt;\n  group_by(condition) |&gt;\n  mutate(overall_accuracy = mean(accuracy), \n  overall_rt = mean(median_rt))|&gt;\n  ungroup()\n\nplot_data &lt;- mean_data |&gt; \n  mutate(image = \"clownfish.png\",\n         image2 = \"shark.png\")\n\nimg = png::readPNG(\"darla.png\") %&gt;%\n  rasterGrob(interpolate = TRUE) \nimg_1 &lt;- readPNG(\"coral.png\")\n\n#Creating plot\nnemo_plot &lt;- ggplot(data = plot_data, \n       mapping = aes(x = accuracy, y = median_rt))+\n  annotation_custom(rasterGrob(img_1, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) + \n    geom_violin(draw_quantiles = c(0.25, 0.5, 0.75), color = \"black\", fill = \"yellow\") +\n           geom_image(aes(image=image), size = 0.06) +\n       facet_wrap(~condition) +\n  geom_image(aes(image = image2, x = overall_accuracy, y = overall_rt), size = 0.22) +\n  labs(title = \"speed-accuracy-trade-off\",  \n         subtitle = \"Wie h√§ngen die Reaktionszeit und die Accuracy zusammen?\", \n        x = \"Accuracy\", \n        y = \"Reaktionszeit\") +\n  coord_cartesian(clip = \"off\") +\n  annotation_custom(img, x = 1.2, y = 13, ymax = 15.8, xmax = 2) +\n      theme_nemo()\nnemo_plot\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n\nRows: 28680 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (5): id, direction, condition, corrAns, resp\ndbl (3): trial, corr, rt\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd_filtered &lt;- d %&gt;% filter(rt &lt;= 120)\np = d |&gt;\n  ggplot(data = d_filtered,\n         mapping = aes(x = condition, y = rt/10)) +\n  # Enhanced boxplots with more harmonious colors\n  geom_boxplot(aes(fill = condition), \n               alpha = 0.7,              \n               outlier.shape = NA, \n               width = 0.5,\n               lwd = 0.8,                \n               fatten = 1.2) +           \n  geom_jitter(aes(color = condition), \n              width = 0.15, \n              alpha = 0.5,               \n              size = 0.7) +              \n  stat_summary(fun = mean, \n               geom = \"point\", \n               shape = 23, \n               size = 4, \n               color = \"black\", \n               fill = \"#FFD700\") +  # More refined gold color for the diamond\n  # Harmonious color palette: complementary blues and purples\n  scale_color_manual(values = c(\"speed\" = \"#3B7A9E\", \"accuracy\" = \"#7A559E\")) +\n  scale_fill_manual(values = c(\"speed\" = \"#5F9AB8\", \"accuracy\" = \"#9C7CB8\")) +\n  labs(title = \"Verteilung der Reaktionszeiten nach Bedingungen\",\n       subtitle = \"Unterscheiden sich die Reaktionszeiten zwischen den beiden Bedingungen?\",\n       x = \"Instruktionsbedingung\",\n       y = \"Reaktionszeit (s)\") +\n  theme_bw() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 11, color = \"grey30\"),\n    axis.title = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.border = element_rect(color = \"grey70\", size = 1)\n  )\np\n\n\n\n\n\n\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n# Reaktionszeiten filtern (realistische Werte zwischen 0.1 und 8 Sekunden)\nd &lt;- d |&gt; \n  filter(rt &gt; 0.1 & rt &lt; 8)\n\n# Plot erstellen\np = d |&gt;\n  ggplot(aes(x = condition, y = rt, color = condition)) +\n  geom_jitter(width = 0.2, alpha = 0.4, size = 2) +\n  geom_boxplot(width = 0.4, alpha = 0, color = \"black\", outlier.shape = NA) +\n  stat_summary(fun = mean, geom = \"point\", shape = 21, size = 3, fill = \"gold\", color = \"black\") +\n  scale_color_manual(values = c(\"darkred\", \"darkgreen\")) +\n  labs(\n    title = \"Reaktionszeiten unter Speed- vs. Accuracy-Instruktion\",\n    subtitle = \"Beeinflusst die Instruktion die mittlere Reaktionszeit?\",\n    x = \"Instruktion\",\n    y = \"Reaktionszeit (Sekunden)\",\n    color = \"Instruktion\"\n  ) +\n  theme_minimal(base_size = 14)\n\n# Plot anzeigen\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\nd &lt;- read.csv(\"data/dataset_random_dot_clean.csv\") %&gt;%\n    mutate(resp = as.factor(resp))\n\n\n\n\np &lt;- d %&gt;%\n    ggplot(aes(x = resp, y = rt, fill = resp)) +\n    geom_violin(trim = FALSE, alpha = 0.5, color = NA) +  # Verteilung\n    geom_jitter(aes(color = resp), width = 0.15, alpha = 0.3, size = 1.5) +  # Rohdatenpunkte\n    stat_summary(fun = mean, geom = \"point\", shape = 21, size = 3.5, fill = \"white\", color = \"black\", stroke = 1) +  # Mittelwert\n    stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.1, color = \"black\") +  # Standardfehler\n    labs(\n        title = \"Reaktionszeiten in Abh√§ngigkeit der Antwort\",\n        subtitle = \"Beeinflusst die gegebene Antwort (linke vs. rechte Taste) die Reaktionszeit?\",\n        x = \"Antwort (Taste)\",\n        y = \"Reaktionszeit (ms)\",\n        color = \"Antwort\",\n        fill = \"Antwort\"\n    ) +\n    scale_fill_manual(values = c(\"#9E5E9E\", \"#39BEBE\")) +  # Neue F√ºllfarben\n    scale_color_manual(values = c(\"#C28CCC\", \"#7FDAD7\")) +  # Neue Punktfarben\n    theme_minimal(base_size = 12) +\n    coord_cartesian(ylim = c(0, 0300))  # Ausrei√üer optisch begrenzen\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Paketen laden\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Mittelwerte pro VPN berechnen\nd1 &lt;- d %&gt;%\n  group_by(id) %&gt;%\n  summarise(mean_corr = mean(corr),\n            mean_rt = mean(rt)) %&gt;%\n  filter(mean_rt &lt; 12)\n\n#richtiger Datensatz mit Mittelwerten\nd2 &lt;- d %&gt;%\n  group_by(id) %&gt;%\n  mutate(mean_corr = mean(corr, na.rm = TRUE),\n         mean_rt = mean(rt, na.rm = TRUE)) %&gt;%\n  filter(mean_rt &lt; 12)\n\n#Plots\n\np &lt;- ggplot(d2, aes(x = condition, y = rt, color = condition)) +                      #Struktur der grafische Darstellung\n  geom_jitter(width = 0.2, alpha = 0.6, size = 1.5) +                                 #Rohdaten\n  geom_boxplot(aes(fill = condition), alpha = 0.3, color = \"black\") +                 #zusammenfassendes Mass\n  scale_color_manual(values = c(\"violetred\", \"olivedrab3\")) +                         #Farben f√ºr Rohdaten\n  scale_fill_manual(values = c(\"violetred\", \"olivedrab3\")) +                          #Farben f√ºr zusammenfassendes Mass  \n  labs( title = \"Reaktionszeit pro experimenteller Bedingung\",                        #Beschriftungen\n        subtitle = \"Wie ver√§ndert sich die Reaktionszeit je nach Versuchsbedingung?\",\n        x = \"Bedingung\",\n        y = \"Reaktionszeit (s)\",\n        caption = \"Random Dot Experiment\") +\n  theme_light() +                                                                     #Theme\n  facet_wrap(~ direction)                                                             #Optional: Facets\n\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv(\"data/dataset_random_dot_clean.csv\")\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nd_clean &lt;- d |&gt; \n  filter(rt &lt; 3)\n\nd$rt = d$rt / 1000\n\np = d_clean |&gt;\n  ggplot(aes(x = condition, y = rt, color = condition)) +  \n  geom_jitter(alpha = 0.5, width = 0.2) +  \n  geom_violin(alpha = 0.3, aes(fill = condition), show.legend = FALSE) +  \n  geom_boxplot(width = 0.2, outlier.shape = NA, color = \"black\") +  \n  labs(\n    title = \"Reaktionszeiten in verschiedenen Bedingungen\",\n    subtitle = \"Gibt es Unterschiede in den Reaktionszeiten zwischen den Bedingungen?\",\n    x = \"Bedingung\",\n    y = \"Reaktionszeit (s)\",\n    caption = \"Datenquelle: dataset_random_dot_clean_Initialen.csv\"\n  ) +\n  theme_minimal() +  \n  scale_color_manual(values = c(\"blue\", \"red\", \"green\")) +  \n  scale_fill_manual(values = c(\"blue\", \"red\", \"green\")) +\n  scale_y_continuous(breaks = seq(0, 3, by = 0.5), limits = c(0, 3))\np\nprint(p)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n\np &lt;- d |&gt;\n  ggplot(aes(x = condition, y = rt, color = condition)) +\n  geom_jitter(alpha = 0.3, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 18, size = 4, color = \"black\") +\n  stat_summary(fun.data = mean_se, geom = \"errorbar\", width = 0.15, color = \"black\") +\n  labs(\n    title = \"Reaktionszeiten in Abh√§ngigkeit der Instruktion\",\n    subtitle = \"Beeinflusst die Aufgabeninstruktion (Schnelligkeit vs. Genauigkeit) die Reaktionszeit?\",\n    x = \"Instruktion\",\n    y = \"Reaktionszeit (s)\",\n    color = \"Instruktion\"\n  ) +\n  theme_minimal() +\n  ylim(0.1, 12)  \n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n[1] 51.2217\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#mittelwert reaktionszeit\nmean_rt &lt;- mean(d$rt, na.rm = TRUE)\nmean_rt\n\n#ausreisser filtern\n# zu schnelle und zu langsame Antworten ausschliessen\nd &lt;- d |&gt;\n  filter(rt &gt; 0.099 & rt &lt; 10)\n\n\n#code f√ºr GGPLOT\np = d |&gt;\n  ggplot(aes(x = condition, y = rt, color = condition)) +\n  geom_jitter(width = 0.2, alpha = 0.4, size = 2) +\n  geom_boxplot(width= 0.4, alpha= 0, color=\"black\") +\n  scale_color_manual(values = c(\"darkorange\", \"steelblue\")) +\n  labs(\n    title = \"Reaktionszeiten unter Speed- vs. Accuracy-Instruktion\",\n    subtitle = \"Beeinflusst die Instruktion die Reaktionszeit?\",\n    x = \"Instruktion\",\n    y = \"Reaktionszeit (Sekunden)\",\n    color = \"Instruktion\") +\n  theme_minimal(base_size = 14)\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nlibrary(\"ggpubr\")\n\np = d |&gt;\n  filter(rt &gt; 0.099 & rt &lt; 12) |&gt;\n    ggplot(d,\n           mapping = aes(x = condition, y = rt, color = condition, fill = condition)) +\n  geom_jitter(width = 0.1, alpha = 0.2, size = 1.2) +\n  geom_boxplot (alpha = 0.4, width = 0.5, outlier.shape = NA) +\n  labs(\n    title = \"Reaktionszeiten in Speed- vs. Accuracy-Bedingung\",\n    subtitle = \"F√ºhrt die Instruktion 'Speed' zu k√ºrzeren Reaktionszeiten als 'Accuracy'?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Reaktionszeit (Sekunden)\",\n    caption = \"Daten aus dem Random-Dot-Paradigma. Punkte = einzelne Trials.\"\n  ) +\n  scale_color_manual(values = c(\"speed\" = \"#E63946\", \"accuracy\" = \"#1D3557\")) +\n  scale_fill_manual(values = c(\"speed\" = \"#E63946\", \"accuracy\" = \"#1D3557\")) +\n  theme_pubclean()\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n##Bei Unklarheiten wurde f√ºr diese Abgabe zur Unterst√ºtzung Chatgpt verwendet.\nmeans &lt;- d |&gt;\n  group_by(condition, trial) |&gt;\n  summarise(mean_acc = mean(corr),sd_acc = sd(corr),\n            .groups = \"drop\"\n  )\n\n# Schritt 2: Plot bauen (Rohdaten + Mittelwertlinie)\np &lt;- ggplot(d, aes(x = trial, y = corr, color = condition)) +\n  geom_jitter(width = 0.05, height = 0.05, alpha = 0.05, size = 0.05) +  # Rohdaten\n  \n  geom_ribbon(data = means, aes(x = trial, ymin = mean_acc - sd_acc, ymax = mean_acc + sd_acc, fill = condition),\n              alpha = 0.2, color = NA, inherit.aes = FALSE) +\n  \n  geom_line(data = means, aes(x = trial, y = mean_acc, color = condition), linewidth = 0.05) +  # Mittelwert\n  geom_point(data = means, aes(x = trial, y = mean_acc, color = condition), size = 0.5) +\n  \n  scale_color_manual(values = c(\"darkorange\", \"royalblue\")) +\n  scale_fill_manual(values = c(\"darkorange\", \"royalblue\")) +\n  \n  labs(\n    title = \"Genauigkeitsverlauf im Dot-Experiment\",\n    subtitle = \"Wie ver√§ndert sich die Genauigkeit \n    √ºber die Durchg√§nge hinweg?\",\n    x = \"Durchgang (Trial)\",\n    y = \"Antwort korrekt (0 = falsch, 1 = richtig)\",\n    caption = \"Datenquelle: dataset_random_dot_clean.csv\"\n  ) +\n  facet_wrap(~ condition) +\n  theme_minimal(base_size = 12)\n\n# Plot anzeigen\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\ndfilt &lt;- d |&gt;\n  filter(rt &gt; 0.099 & rt &lt; 10)\n\np = dfilt |&gt;\n  ggplot(aes(x= condition, y= rt, color = condition)) +\n  geom_jitter(size = 3, alpha = 0.4, \n              width = 0.2, height = 0) +\n  geom_violin(alpha = 0, width = 1, color = \"black\") +\n  scale_color_manual(values = c(accuracy = \"skyblue3\",\n                                speed = \"tomato3\")) +\n  labs(x = \"Bedingung\",\n       y = \"Reaktionszeit [s]\",\n       title = \"Reaktionszeiten (RZn)\",\n       subtitle = \"Unterscheiden sich die RZn der beiden Bedingungen?\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n  ggplot(mapping = aes(x = condition,\n                       y = rt )) + \n         geom_jitter(width = 0.3, alpha = 0.6, color = \"green\") + \n  geom_violin(width = 0.3, alpha = 0.5, color = \"blue\") +\n  labs(title = \"Eine sch√∂ne Zusammenfassung\",\n       subtitle  = \"Wie verh√§lt sich die Reaktionszeit zur Bedingung\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit\") +\n  theme_dark()\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\nmean_values &lt;- d |&gt; \n  filter(!is.na(rt), rt &gt; 0.1, rt &lt; 12) |&gt; \n  group_by(condition) |&gt; \n  summarise(mean_rt = mean(rt))\nmean_values$condition &lt;- factor(mean_values$condition, levels = c(\"accuracy\", \"speed\"))\n\n\np = d |&gt; \n  filter(!is.na(rt), rt &gt; 0.1, rt &lt; 12) |&gt; \n  ggplot(aes(y = rt, x = condition, fill = condition)) + \n  geom_violin(alpha = 0.5) + \n  geom_boxplot(alpha = 0.2, width = 0.4, outlier.shape = NA,) +\n  geom_point(data = mean_values, aes(x = condition, y = mean_rt), \n             size = 3) +  \n  geom_line(data = mean_values, aes(x = as.numeric(condition), y = mean_rt, group = 1), \n            size = 1, linetype = \"dashed\") +\n  labs(title = \"Reaktionszeiten im Random-Dot-Experiment\",\n       subtitle = \"Unterscheiden sich die durchschnittlichen Reaktionszeiten zwischen den Bedingungen?\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit (s)\",\n       color = \"Bedingung\") + \n  scale_fill_manual(values = c(\"blue\", \"red\")) +  \n  scale_color_manual(values = c(\"blue\", \"red\")) + \n  theme_minimal() +\n  coord_cartesian(ylim = c(0, 12)) + \n  theme(legend.position = \"none\")\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd &lt;- read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#Frage: is the accuracy of direction sig. lower in the speed condition?\n\nd &lt;- d %&gt;%\n  filter(rt &gt;= 100, rt &lt;= 12000)\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Beispiel: Gruppiere nach Bedingung\ndf_summary &lt;- d %&gt;%\n  group_by(condition) %&gt;%\n  summarise(\n    mean_speed = mean(rt),\n    sd_speed = sd(rt)\n  )\n\nggplot(d, aes(x = condition, y = rt, color = condition)) +\n  # Rohdaten\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  \n  # Mittelwert + SD\n  stat_summary(fun = mean, geom = \"point\", size = 3, color = \"red\") +\n  stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), \n               geom = \"errorbar\", width = 0.2, color = \"red\") +\n  \n  # Farben & Theme\n  scale_color_brewer(palette = \"Set2\") +\n  theme_minimal() +\n  \n  # Beschriftungen\n  labs(\n    title = \"Reaktionszeiten pro Bedingung\",\n    subtitle = \"Unterscheiden sich die Reaktionszeiten je nach Bedingung?\",\n    x = \"Bedingung\",\n    y = \"Reaktionszeit (ms)\",\n    color = \"Bedingung\",\n    caption = \"Rohdaten + Mittelwerte mit Standardabweichung\"\n  )\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 252 √ó 5\n# Groups:   id [126]\n   id      condition trial ncorrect mean_rt\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 sub-007 accuracy     60       41   1.23 \n 2 sub-007 speed        60       40   0.942\n 3 sub-010 accuracy     60       60   1.01 \n 4 sub-010 speed        60       60   0.636\n 5 sub-011 accuracy     60       55   1.28 \n 6 sub-011 speed        60       54   0.535\n 7 sub-012 accuracy     60       58   0.611\n 8 sub-012 speed        60       59   0.650\n 9 sub-014 accuracy     60       43   2.60 \n10 sub-014 speed        59       22   3.01 \n# ‚Ñπ 242 more rows\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np &lt;- d |&gt;\n    filter(rt &gt; 0.099 & rt &lt; 8)\n\np &lt;- p|&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        trial = n(),\n        ncorrect = sum(corr),\n        mean_rt = mean(rt)\n)\n\np &lt;- ggplot(aes(x = condition, y = mean_rt, color = condition))+\n    geom_jitter(size = 3, alpha = 0.4,\n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.3, alpha = 0.05, color = \"black\") +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                  incongruent = \"tomato3\")) +\n    labs(x = \"id\",\n         y = \"Mittlere Reaktionszeit\",\n         title = \"Reaktionszeiten\",\n         subtitle = \"War die Reaktionszeit schneller bei falschen antworten\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nd_filter &lt;- d %&gt;%\n  filter(rt &lt;= 120)\n\nsp = d |&gt;\n  ggplot(data = d_filter, mapping = aes(x = condition, y =rt)) +\n  geom_violin(alpha = 0.9, fill = \"skyblue\", trim = TRUE) + \n  geom_jitter(width = 0.2, alpha = 0.2, size = 0.2) +\n  stat_summary(fun = \"mean\", geom = \"point\", shape = 23, size = 3, color = \"blue\", fill = \"violet\") +\n  labs(title = \"√úbung 3\", \n       subtitle = \"Verteilung der Reaktionszeit nach Bedingung\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit\") +\n  theme_minimal()\n\nsp\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n#install.packages(\"ggpubr\")\n#library(ggpubr)\n\nsummary_d &lt;- d |&gt;\n  group_by(condition,id) |&gt;\n  summarise(mean_acc= mean(corr))\n\n\n#t.test(mean_acc ~ condition, data = summary_d, paired = TRUE)\n\n\n\np= summary_d |&gt;\n  ggplot(mapping = aes(x = condition,y = mean_acc, fill= condition)) +\n  geom_boxplot(alpha = 0.5, outlier.shape = NA, width = 0.4) +\n  geom_jitter(width = 0.01, size = 0.4, alpha = 0.3) +\n  stat_summary(fun = mean, geom = \"crossbar\", color = \"darkred\", size = 0.5)+\n  labs(\n    title = \"Random-Dot Paradigma\",\n    subtitle = \"Gab es signifikant mehr richtige Antworten in der \\nAccuracy-Bedingung als in der Speed-Bedingung? \",\n    x = \"Bedingung\",\n    y = \"Korrekte Antworten\"\n  ) +\n  scale_fill_manual(values = c(\"speed\" = \"steelblue\", \"accuracy\" = \"tomato\"))+\n  theme_minimal() +\n  stat_compare_means(\n    comparisons = list(c(\"speed\", \"accuracy\")),\n    method = \"t.test\",\n    paired = TRUE,\n    label = \"p.signif\",  \n    label.y = 0.7       \n  )\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nd &lt;- d |&gt;\n    filter(rt &gt; 0.1 & rt &lt; 12)\n\np1  = d |&gt; \n  group_by(condition) |&gt; \n  summarise(accuracy = mean(corr, na.rm = TRUE)) |&gt; \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  labs(title = \"Trefferquote pro Bedingung\",\n       subtitle = \"Wie hoch ist die durchschnittliche Trefferquote pro Bedingung?\",\n       x = \"Bedingung\", y = \"Trefferquote\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#FF5733\", \"#3498DB\"))  # Orange & Blau\n\n\n## 2. Reaktionszeit pro Bedingung\np2 = d |&gt; \n  ggplot(aes(x = condition, y = rt, fill = condition)) +\n  geom_boxplot(alpha = 0.5) +\n  geom_jitter(width = 0.2, aes(color = condition), alpha = 0.5) +\n  labs(title = \"Reaktionszeit pro Bedingung\",\n       subtitle = \"Wie unterscheiden sich die Reaktionszeiten pro Bedingung?\",\n       x = \"Bedingung\", y = \"Reaktionszeit (s)\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"#FF5733\", \"#3498DB\")) +\n  scale_color_manual(values = c(\"#FF5733\", \"#3498DB\"))\n\n\n#Reaktionszeit √ºber Trials\np3 = d |&gt; \n  ggplot(aes(x = trial, y = rt, group = id, color = condition)) +\n  geom_line(alpha = 0.5) +\n  geom_point(alpha = 0.5) +\n  labs(title = \"Reaktionszeit √ºber Trials\",\n       subtitle = \"Ver√§ndert sich die Reaktionszeit im Verlauf des Experiments?\",\n       x = \"Trial\", y = \"Reaktionszeit (s)\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"#FF5733\", \"#3498DB\"))\n\n\n# Plots kombinieren mit patchwork\nlibrary(patchwork)\n\np = p1 / p2 / p3\n\n# Endg√ºltigen Plot anzeigen\nprint(p)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\n# Metbrewer hat colour palettes, die von ber√ºhmten Kunstwerken inspiriert sind,\n# Und ich finde sie sehr h√ºbsch :)\n#install.packages(\"MetBrewer\")\nlibrary(MetBrewer)\n\n# violin plot, Ausreisser in der Reaktionszeit werden herausgefiltert\np = d |&gt;\n    filter(rt&lt;12) |&gt;\n    ggplot(aes(x = direction, y = rt, fill = direction)) +\n    geom_violin(width = 1) +\n    geom_boxplot(width=0.1, alpha=0.4) +\n    geom_jitter(color=\"royalblue4\", size=0.4, alpha=0.2) +\n    labs(title = \"Reaktionszeiten nach Richtung\",\n         subtitle = \"Sind Menschen schneller in eine bestimmte Richtung?\",\n         x = \"Richtung\",\n         y = \"Reaktionszeiten (s)\") +\n    theme_bw() +\n    # Klimt ist eine der Farbpaletten, und direction gibt an, welche Farben gew√§hlt werden\n    scale_fill_manual(values=met.brewer(\"Klimt\", direction = -1))\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\nd_filter &lt;- d %&gt;%\n  filter(rt &lt;= 120)\n\nsp = d |&gt;\n  ggplot(data = d_filter, mapping = aes(x = condition, y =rt)) +\n  geom_violin(alpha = 0.9, fill = \"skyblue\", trim = TRUE) + \n  geom_jitter(width = 0.2, alpha = 0.2, size = 0.2) +\n  stat_summary(fun = \"mean\", geom = \"point\", shape = 23, size = 3, color = \"blue\", fill = \"violet\") +\n  labs(title = \"√úbung 3\", \n       subtitle = \"Verteilung der Reaktionszeit nach Bedingung\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit\") +\n  theme_minimal()\n\nsp\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Ein Plot erstellen f√ºr die Fragestellung: Ist die Reaktionszeit in der Speed-Bedingung k√ºrzer?\n\nd &lt;- d %&gt;% filter(rt &lt;=12)|&gt; # nur Reaktionszeiten unter 12ms \nggplot(data = d,\n       mapping = aes(x = condition,\n                     y = rt)) +\n  geom_jitter(width = 0.4, color= \"#009ACD\", alpha = 0.3) + \n  geom_boxplot(width = 0.2, color= \"#FF34B3\", alpha = 0.5) + # Boxplot-Farbe und transparenz, Boxplot als 2. Aufgelistet, dass es √ºber den blauen Rohdatenpunkten erscheint und transparent, dass Rohdaten sichtbar bleiben.\n  labs(title = \"Vergleich der Reaktionszeiten zwischen den beiden Bedingungen\", \n       subtitle = \"Ist die Reaktionszeit in der Speed-Bedingung k√ºrzer?\",\n       x = \"Bedingung\",\n       y = \"Reaktionszeit (ms)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5), # Den Titel und Subtitel mittig ausrichten\n        plot.subtitle = element_text(hjust = 0.5))\n\n\n# Zahlen zum Boxplot: hier k√∂nnen die Werte vom Mean und der SD ausgegeben werden\nunique(d$condition)\n# Mean und AD f√ºr die Bedingung speed berechnen\nd_speed &lt;- d %&gt;% \n  filter(condition == \"speed\")\n\nd_speed_summary &lt;- d_speed %&gt;% \n  summarise(mean_rt = mean(rt),\n            sd_value = sd(rt))\nglimpse(d_speed_summary)\n\n# Mean und SD f√ºr die Bedingung accuracy berechenen\nd_accuracy &lt;- d %&gt;% \n  filter(condition == \"accuracy\")\n\nd_accuracy_summary &lt;- d_accuracy %&gt;% \n  summarise(mean_rt = mean(rt),\n                  sd_value = sd(rt))\nglimpse(d_accuracy_summary)\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(aes(x = condition, y = rt, color = condition)) + #Rohdaten nach Bed. gruppiert\n    geom_jitter(alpha = 0.4, width = 0.5, size = 1) +\n    geom_violin(alpha = 0.4, width = 0.2, color = \"black\") + #Zusammenfassendes Mass\n    scale_color_manual(values = c(accuracy = \"deeppink\",\n                                  speed = \"darkcyan\")) +\n    labs(\n        x = \"Instruction Condition\",\n        y = \"Reaction Time (ms)\",\n        title = \"Impact of Instruction Type on Reaction Speed\",\n        subtitle = \"Does Emphasis on Accuracy vs. Speed Affect Reaction Times?\") +\n    theme_linedraw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\np\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht ver√§ndert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv') \n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\npreplot &lt;- d |&gt;\n  group_by(condition) %&gt;%\n  summarise(\n    Reaktionszeit = mean(rt, na.rm = TRUE),\n    sd_rt = sd(rt, na.rm = TRUE)\n  )\n\np = ggplot(d, aes(x = condition, y = rt, fill = condition)) +\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"gray70\") + # Rohdaten\n  geom_boxplot(alpha = 0.4, outlier.shape = NA, color = \"gray10\") +  # Boxplot ohne Ausrei√üer  \n  geom_point(data = preplot, aes(x = condition, y = Reaktionszeit), \n             shape = 18, size = 4, color = \"darkblue\", inherit.aes = FALSE) +  # Mittelwert,\n  scale_fill_manual(values = c(\"speed\" = \"#E69F00\", \"accuracy\" = \"#56B4E9\")) +\n  labs(\n    title = \"Reaktionszeiten im Random dot Experiment\",\n    subtitle = \"Unterscheidet sich die Reaktionszeit je nach Instruktion (Speed vs. Accuracy)?\",\n    x = \"Instruktionsbedingung\",\n    y = \"Reaktionszeit (in ms)\",\n    caption = \"Die Quadrate bezeichnen den Mittelwert in der jeweiligen Bedingung\"\n    )  +\n  ylim(0,70) +\n  theme_minimal()\np",
    "crumbs": [
      "Datenvisualisieren",
      "Plot Gallery - Group 2"
    ]
  },
  {
    "objectID": "intro_analysis.html",
    "href": "intro_analysis.html",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "",
    "text": "13.1 Herausforderungen in der Analyse von neurowissenschaftlichen Daten\nNeurowissenschaftliche Datens√§tze bringen oft folgende Herausforderungen in der Datenanalyse mit sich:\nZiel ist es, trotz diesen Umst√§nden, m√∂glichst viel Information aus den vorhandenen Daten zu gewinnen. Hierbei spielt die Analysemethode eine wichtige Rolle.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "intro_analysis.html#herausforderungen-in-der-analyse-von-neurowissenschaftlichen-daten",
    "href": "intro_analysis.html#herausforderungen-in-der-analyse-von-neurowissenschaftlichen-daten",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "",
    "text": "Kleine Stichprobengr√∂ssen (z.B. aufgrund teurer Datenerhebung oder Patientengruppen die schwieriger zu rekrutieren sind).\nHeterogenit√§t / Rauschen (z.B. weil der zu untersuchende Prozess schwierig zu isolieren ist, weil Personen sich sehr unterschiedlich verhalten)\nTeure Datenerhebung und damit hoher Druck Resultate zu generieren sowie oft keine M√∂glichkeit das Experiment zu wiederholen (wichtig daher die gute Planung der Analyse sowie Vermeidung von inkonklusive Resultaten)\nVorgehen bei nicht-signifikanten/nicht-konklusiven Ergebnissen (Research waste, publication bias/file drawer effect)\n\n\nIm Artikel Power failure: why small sample size undermines the reliability of neuroscience von Button et al.¬†2013 finden Sie einen Artikel √ºber die Problematik von kleinen Stichprobengr√∂ssen in Neuroscience\n\n\n\nAbsence of evidence oder Evidence of absence?\nBei Nullhypothesen-Signifikanztests (NHST) wird eine bin√§re Entscheidung getroffen: Der Hypothesentest kann entweder ein signifikantes oder ein nicht signifikantes Ergebnis haben. Kann kein Effekt gefunden werden besteht die Notwendigkeit zu unterscheiden zwischen den zwei M√∂glichkeiten: - Absence of evidence: Es ist unklar ob es einen Effekt gibt oder nicht. Die Ergebnisse des Verfahrens sind inkonklusiv. - Evidence of absence: Es ist klar, dass es keinen Effekt gibt. Die Daten zeigen dies deutlich.\nZum Unterscheiden dieser zwei F√§lle eignen sich die typischen NHSTs oft weniger, gerade wenn die Power nicht sehr hoch war. Bayesianische Statistik (z.B. bei begrenzten Datens√§tzen) sowie frequentistische √Ñquivalenztests (zwei entgegengesetzte NHSTs zum Testen von Nullunterschieden) sind Ans√§tze, um zwischen absence of evidence und evidence of absence zu unterscheiden.\nWir werden uns in den folgenden Veranstaltungen deshalb damit auseinandersetzen,\n\nwelche Annahmen hinter statistischen Verfahren stecken.\nwelche Fragen mit Bayesianischer Statistik beantwortet werden k√∂nnen.\nwie Nullunterschiede statistisch getestet werden k√∂nnen.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "intro_analysis.html#vorbereitung",
    "href": "intro_analysis.html#vorbereitung",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "13.2 Vorbereitung",
    "text": "13.2 Vorbereitung\n\n\n\n\n\n\nHands-on: Reaktivierung Statistikwissen\n\n\n\n1. Besprechen Sie in kleinen Gruppen folgende Fragen:\n\nWas ist eine Null-, was eine Alternativhypothese?\nWas bedeutet die Distanz zwischen den beiden Mittelwerten?\nWas ist statistische Power?\nWelche Rolle spielt die Stichprobengr√∂sse?\nWas ist ein p-Wert?\nWas sind Typ I und Typ II Fehler?\nWelche Fragen k√∂nnen Sie mit einem Nullhypothesen- Signifikanztest (NHST) beantworten?\n\n2. K√∂nnen Sie die Begrifflichkeiten in dieser Grafik einordnen?\n\n\n√úberlegen Sie sich, was Null- und Alternativhypothese in unseren beiden Kursexperimenten (Stroop und Random Dot) sein k√∂nnen.\n\n[10 Minuten]\n\n\n\nSie k√∂nnen zur Beantwortung dieser Fragen z.B. die Interaktive Visualisierung ‚ÄúUnderstanding Statistical Power and Significance Testing‚Äù nutzen.\n\n\n\n\n\n\n\nProjekt und Daten herunterladen\n\n\n\nHier finden Sie die Daten zum herunterladen.\nLesen Sie anschliessend die Daten ein:\n\n## Daten einlesen\nlibrary(tidyverse)\nd_stroop &lt;- read_csv(\"data/dataset_stroop_clean.csv\") |&gt;\n    mutate(across(where(is.character), as.factor)) |&gt; # zu Faktoren machen\n    filter(rt &lt; 4 & rt &gt;= 0.1) |&gt; # nur Antworten zwischen 100 und 4000ms einbeziehen\n    filter(corr == 1) |&gt; # nur korrekte Antworten einbeziehen\n    na.omit() # Messungen mit missings weglassen",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "intro_analysis.html#datengenerierende-prozesse",
    "href": "intro_analysis.html#datengenerierende-prozesse",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "13.3 Datengenerierende Prozesse",
    "text": "13.3 Datengenerierende Prozesse\nNach dem Data Cleaning und Preprocessing geht es darum, welche Informationen die Daten √ºber den zu untersuchenden Prozess beinhalten. Anhand der Daten sollen also R√ºckschl√ºsse auf den datengenerierenden Prozess, der zu diesen Daten gef√ºhrt hat gezogen werden.\nBei jeder Datenanalyse m√ºssen zahlreiche Annahmen getroffen werden. Um diese explizit zu machen und auch die Datenanalyse zu planen, hilft oft eine grafische Darstellung. Directed Acyclic Graphs (DAGs) sind eine Variante hierf√ºr.\n\n13.3.1 Directed Acyclic Graphs (DAGs)\nEin DAG (directed acyclic graph) eignet sich f√ºr die Darstellung komplexer Zusammenh√§nge in Daten und Prozessen. Mit einem DAG kann veranschaulicht werden, welche Variablen einander beeinflussen. Die Kreise (nodes) werden f√ºr einzelne Elemente verwendet und die Pfeile (arrows oder edges) beschreiben die Beziehung zwischen den Elementen. Die Darstellung beschreibt einen Prozess also mit gerichteten (directed) und nicht zyklischen (acyclic) Beziehungen.\nWir k√∂nnen beispielsweise annehmen, dass die Farbe-Wort-Kongruenz im Stroop Task beeinflusst, wie schnell die Aufgabe gel√∂st werden kann.\nEin DAG kann mit folgenden Schritten erstellt werden:\n\n1. Beobachtete Variable bestimmen\nDie beobachtete Variable nennen wir hier \\(y\\). Der Kreis ist grau eingef√§rbt, weil die Werte in dieser Variable gemessen wurden bzw. bekannt sind.\nIn unserem Beispiel haben wir die Reaktionszeit gemessen. Im Datensatz enth√§lt die Variable rt die Information, wie schnell eine Person in jedem Trial geantwortet hat.\n\n\n2. Verteilung bestimmen\nEs muss festgelegt werden, welche Verteilung die Daten \\(y\\) am besten beschreibt. Eine Verteilung ist immer nur eine Ann√§herung. Die gemessenen Daten entsprechen dieser Annahme eigentlich nie perfekt. Es geht darum eine Verteilung zu finden die gut genug zu den Daten passt. Jede Verteilung hat Parameter, die gesch√§tzt werden k√∂nnen. Es gibt Verteilungen, welche durch einen Parameter definiert werden, andere brauchen mehrere Parameter.\nEine sehr h√§ufig verwendete Verteilung in statistischen Analysen ist die Normalverteilung. Die Annahme einer Normalverteilung erm√∂glicht es uns, mit nur 2 Parametern die Daten in der Variable zu beschreiben: Dem Mittelwert (\\(\\mu\\)) und der Standardabweichung (\\(\\sigma\\)). Nat√ºrlich ist das nur eine Ann√§herung, aber meistens eine gen√ºgend Gute!\n\nHier im Distribution Zoo werden Verteilungen, zugrundeliegende Daten sowie Code und Formeln zusammengefasst.\n\n\nUm die Verteilung unserer Datenpunkte zu bestimmen bzw. zu √ºberpr√ºfen k√∂nnen die Daten in R geplottet werden, z.B. mit geom_histogram(). Das Argument binwidth = bestimmt, wie breit ein Balken wird (hier 50 ms).\n\nd_stroop |&gt;\n    ggplot(aes(x = rt)) +\n    geom_histogram(colour=\"black\", fill = \"white\", \n                   binwidth = 0.05, \n                   alpha = 0.5) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nDiese Verteilung k√∂nnte beispielsweise mit einer Normalverteilung beschrieben werden. Der Mittelwert und die Standardabweichung k√∂nnen wir mit R berechnen:\n\n# clean dataset first\nmu = mean(d_stroop$rt)\nmu\n\n[1] 0.7465929\n\nsigma = sd(d_stroop$rt)\nsigma\n\n[1] 0.3455337\n\n\nUm zu schauen, wie gut diese Normalverteilung mit den Parametern \\(\\mu\\) = 0.7465929 und \\(\\sigma\\) = 0.3455337 unsere Daten beschreibt, k√∂nnen wir die Daten und simulierte Daten mit der angenommenenen Verteilung √ºbereinander plotten:\n\nd_stroop |&gt;\n    ggplot(aes(x = rt)) +\n    geom_histogram(colour=\"black\", fill = \"white\", \n                   binwidth = 0.05, \n                   alpha = 0.5) +\n    geom_histogram(aes(x = rnorm(1:length(rt), mu, sigma)),\n                   binwidth = 0.05,\n                   alpha = 0.2) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nWir k√∂nnen auch density-Plots daf√ºr nutzen:\n\nd_stroop |&gt;\n    ggplot(aes(x = rt)) +\n    geom_density(colour=\"black\", fill = \"white\") +\n    geom_density(aes(x = rnorm(1:length(rt), mu, sigma)),\n                 fill=\"grey\",\n                 alpha = 0.2) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on: Verteilungen\n\n\n\n\nWelche Daten stammen aus unseren Daten, welche entsprechen der Normalverteilung \\(N(0.747, 0.346)\\) ?\nWie gut passt die Annahme der Normalverteilung f√ºr unsere Reaktionszeitdaten? Wo passt sie gut? Wo nicht?\nFinden Sie auf Distribution Zoo eine passendere Verteilung?\nPr√ºfen Sie Ihre Verteilung, indem Sie unten an den obigen Plot diese Verteilung mit gew√§hlten Parametern folgenden Code einf√ºgen.\n\nW√§hlen Sie dazu eine Verteilung und passende Parameter auf Distribution Zoo aus.\nSchauen Sie unter dem Reiter Code mit welcher Funktion die Daten in R generiert werden k√∂nnen. W√§hlen Sie Language: R und Property: random sample of size n aus.\nKopieren Sie die Funktion und ersetzen Sie rnorm(1:length(rt), mu, sigma) in unserem R-Code f√ºr das Histogram oder den Density-Plot mit Ihrer neuen Funktion. Das n m√ºssen Sie wieder 1:length(rt) nennen.\n\n\n[10 Minuten]\n\n\nBei Reaktionszeiten ist die Verteilung gar nicht so einfach anzupassen: Hier finden Sie ‚Äúbesser‚Äù geeignete Verteilungen, sowie die M√∂glichkeit f√ºr einen vorgegebenen Datensatz oder Ihre eigenen Daten Parameterwerte anzupassen.\n\n\n3. Weitere Einflussfaktoren\nIn einem DAG k√∂nnen auch weitere Informationen, zum Beispiel Bedingungen sowie Messwiederholungen, hinzugef√ºgt werden.\n\\(\\mu\\) kann sich zum Beispiel in Abh√§ngigkeit der Bedingung (condition) ver√§ndern, also je nachdem ob die angezeigte Farbe kongruent war oder nicht.\nWenn wir nun den Einfluss der Bedingung untersuchen m√∂chten, k√∂nnten wir uns fragen, wie stark diese eine Ver√§nderung im Wert \\(\\mu\\) bewirkt. Genau dies tun wir z.B. bei Mittelwertsvergleichen wie z.B. bei t-Tests.\n\n\n\n\n\n\nHands-on: DAG zeichnen\n\n\n\nWie w√ºrde ein DAG f√ºr die accuracy (Korrektheit) der Stroop-Daten aussehen?\nGehen Sie wie folgt vor:\n\nWas ist bekannt/wurde gemessen?\nWelche Verteilung beschreibt die Daten gut?\nWelche Parameter m√ºssen gesch√§tzt werden?\n\n[5 Minuten]",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "intro_analysis.html#datensimulation",
    "href": "intro_analysis.html#datensimulation",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "13.4 Datensimulation",
    "text": "13.4 Datensimulation\nSich Gedanken zum datengenerierenden Prozess zu machen (wie beispielsweise mit einem aufgezeichneten Modell) hilft nicht nur in der Planung der Datenanalyse, sondern erm√∂glicht u.a. auch das Simulieren von Daten.\nM√∂gliche Schritte in der Datensimulation \n\nShiny-App f√ºr Datensimulation\n\nDatensimulation ist n√ºtzlich f√ºr:\n\nDie Vorbereitung von Pr√§registrationen und Registered Reports\nTesten/Debugging von Analysekripten (weil die ground truth bekannt ist)\nPower f√ºr komplexe Modelle sch√§tzen\nErstellen von reproduzierbaren Beispielsdatens√§tzen (f√ºr Demos, Lehre, oder wenn echte Datens√§tze nicht ver√∂ffentlicht werden k√∂nnen)\nPrior distribution checks in der Bayesianischen Statistik\nVerstehen von Modellen und Statistik\n\n\nWeitere Infos zu Datensimulation\n\nUm Hypothesen zu testen, m√ºssen selbstverst√§ndlich nicht simulierte Daten erhoben werden! 2",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "intro_analysis.html#footnotes",
    "href": "intro_analysis.html#footnotes",
    "title": "13¬† Datengenerierende Prozesse",
    "section": "",
    "text": "Uns kann beispielsweise die Aufmerksamkeitsleistung interessieren, welche wir mit einem Testverfahren f√ºr Aufmerksamkeit zu messen versuchen. Eine Neurowissenschaftlerin, welche sich f√ºr den Prozess von Aufmerksamkeit interessiert, w√ºrde versuchen die Aufmerksamkeitsleistung von vielen Leuten unter verschiedenen Bedingungen zu messen um zu untersuchen, durch was Aufmerksamkeit beeinflusst wird. Ein klinischer Neuropsychologe hingegen h√§tte vielleicht das Ziel festzustellen, ob die Aufmerksamkeitsleistung einer Person von der Norm abweicht, beispielsweise weil sie durch einen Unfall eine Kopfverletzung erlitten hat. Beide messen Daten und beide ziehen aus den gemessenen Daten R√ºckschl√ºsse auf eine unterliegende Eigenschaft eines Prozesses oder einer Person.‚Ü©Ô∏é\nhttps://www.science.org/content/article/dutch-university-sacks-social-psychologist-over-faked-data‚Ü©Ô∏é",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Datengenerierende Prozesse</span>"
    ]
  },
  {
    "objectID": "parameterestimates.html",
    "href": "parameterestimates.html",
    "title": "14¬† Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik",
    "section": "",
    "text": "14.1 Frequentistische und Bayesianische Parametersch√§tzung\nIn der Frequentistischen Statistik wird angenommen, dass ein Parameter einen wahren (aber unbekannten) Wert hat. Die frequentistische Parametersch√§tzung ergibt eine Punktsch√§tzung: Der gesch√§tzte Parameter hat damit genau einen Wert und keine Wahrscheinlichkeitsverteilung. Daher d√ºrfen keine Aussagen √ºber eine Wahrscheinlichkeitsverteilung des Parameters bzw. die Wahrscheinlichkeit eines Parameterswerts gemacht werden. Nur Ereignisse die wiederholt werden k√∂nnen eine Wahrscheinlichkeit (eine H√§ufigkeitsverteilung) haben.\nIn der Bayesianischen Statistik hingegen wird f√ºr jeden m√∂glichen Parameterwert gesch√§tzt, wie wahrscheinlich dieser einzelne Wert ist in Anbetracht der Vorannahmen (Priors) und der Daten. Das bedeutet, wir erhalten f√ºr jeden dieser Werte gleichzeitig auch eine Wahrscheinlichkeit mit der dieser zutrifft. Die Zusammenfassung aller gesch√§tzten Werte und deren Wahrscheinlichkeiten wird in der Posterior-Verteilung zusammengefasst. Die Posterior Wahrscheinlichkeit beschreibt unser degree of belief, also unser aktuelles Wissen dar√ºber, wie wahrscheinlich dieser Parameterwert wirklich hinter den Daten steckt.\nWir schauen uns die unterschiedlichen Ans√§tze der Parametersch√§tzung im Folgenden an einem Beispiel an. Wir haben bei einer Person z.B. beobachtet, dass sie in 15 von 20 Trials korrekt geantwortet hat.\ncorrect &lt;- 15 # Anzahl korrekter Antworten\ntrials &lt;- 20 # Anzahl Trials insgesamt",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik</span>"
    ]
  },
  {
    "objectID": "parameterestimates.html#frequentistische-und-bayesianische-parametersch√§tzung",
    "href": "parameterestimates.html#frequentistische-und-bayesianische-parametersch√§tzung",
    "title": "14¬† Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik",
    "section": "",
    "text": "Hands-on: Frequentistisch oder Bayesianisch?\n\n\n\nOrdnen Sie die untenstehenden Aussagen dem frequentistischen bzw. dem baysianischen Ansatz zu:\n\n‚ÄúDer Mittelwert liegt mit 95%-iger Wahrscheinlichkeit zwischen 0.75 und 0.85 Sekunden.‚Äù\n‚ÄúWenn das Experiment 100 Mal wiederholt wird, ist der wahre Mittelwert in 95% der Konfidenzintervalle enthalten.‚Äù\n\n\n\n\n\n\n14.1.1 Maximum-Likelihood Sch√§tzung\n\\(\\theta\\) ist der Parameterwert unter dem die beobachteten Daten am wahrscheinlichsten entstanden sind. Die beste Punktsch√§tzung des Parameters \\(\\theta\\), die wir machen k√∂nnen, wenn wir nur die Daten betrachten, und kein weiteres Vorwissen ber√ºcksichtigen, ist die Maximum-Likelihood Sch√§tzung.\nM√∂chten wir also z.B. sch√§tzen mit welcher Wahrscheinlichkeit die Person beim n√§chsten Trial eine richtige Antwort gibt, k√∂nnen wir dies aus den bisherigen Trials berechnen:\n\\[\\theta = correct / all \\]\nWenn die Person in insgesamt 20 Trials 15 Mal richtig geantwortet hat, w√§re die Sch√§tzung\n\\(\\theta = 15 / 20 = 0.75\\)\n\ntheta &lt;- correct / trials\ntheta\n\n[1] 0.75\n\n\nWir erhalten eine Punktsch√§tzung (einen Wert), die uns angibt mit welcher Wahrscheinlichkeit die Person beim n√§chsten Trial richtig antworten wird, n√§mlich 0.75 bzw. sie wird in 3/4 der F√§lle richtig antworten.\nWenn man ganz viele Male diese Spiele wiederholen w√ºrde, dann w√ºrde man diese Messung am wahrscheinlichsten reproduzieren k√∂nnen, wenn man f√ºr \\(\\theta\\) den Wert 0.75 einsetzt.\nDer grosse Nachteil einer Punktsch√§tzung ist es, dass wir keine Wahrscheinlichkeitsverteilung erhalten. Es g√§be auch noch viele andere Parameterwerte, die dieses Ergebnis von 15 korrekten Antworten in 20 Trials hervorbringen k√∂nnten, z.B. \\(\\theta = 0.73\\) oder \\(\\theta = 0.78\\). Diese werden bei der Punktsch√§tzung nicht beachtet.\nUm das zu veranschaulichen plotten wir die Wahrscheinlichkeit von 15 korrekten Antworten in 20 Trials f√ºr alle Werte welche \\(\\theta\\) annehmen k√∂nnte. Diese Werte liegen zwischen 0 und 1, da wir von einer Wahrscheinlichkeit sprechen.\n\nlibrary(tidyverse)\n\n# seed setzen f√ºr reproduzierbare ergebnisse\nset.seed(42) \n\n# daten generieren\nd &lt;- tibble(x = seq(from = 0, to = 1, by = .01)) |&gt;\n    mutate(density = dbinom(15, 20, x))\n\nd |&gt;\n    ggplot(aes(x = x, ymin = 0, ymax = density)) +\n    geom_ribbon(alpha = 0.5, fill = \"steelblue\") +\n    geom_vline(xintercept = theta, linetype = 2, linewidth = 1.2) +\n    scale_y_continuous(NULL, breaks = NULL) +\n    coord_cartesian(xlim = c(0, 1)) +\n    labs(x = expression(paste(\"Gesch√§tzter Wert von \", theta))) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nDie Punktsch√§tzung von \\(\\theta\\) wird mit der schwarzen gestrichelten Linie dargestellt. Die hellblaue Fl√§che zeigt, wie wahrscheinlich die einzelnen Werte jeweils sind (hier abgebildet sehen Sie relative Wahrscheinlichkeiten).\n\n\n\n\n\n\nHands-on: Punktsch√§tzung\n\n\n\nDiskutieren Sie in kleinen Gruppen, wie sinnvoll es ist sich hier auf einen Wert festzulegen:\n\nWie genau denken Sie bildet die Punktsch√§tzung die Realit√§t ab?\nWie viel wahrscheinlicher ist das berechnete \\(\\theta = 0.75\\) im Vergleich zu \\(\\theta = 0.70\\)?\nWas kann das Sch√§tzen der Wahrscheinlichkeit f√ºr alle Parameterwerte f√ºr einen Mehrwert bringen?\nWo kann eine Punktsch√§tzung einen Mehrwert haben?\n\n\n\n\n\n14.1.2 Posterior-Sch√§tzung in der Bayesianischen Statistik\nIn der Bayesianischen Statistik wird die Wahrscheinkeitslehre angewandt, um die Wahrscheinlichkeit von Parameterwerten zu berechnen. Es wird f√ºr jeden m√∂glichen Parameterwert die Wahrscheinlichkeit gesch√§tzt mit der dieser Parameterwert die Daten generiert hat. Im Gegensatz zu der Frequentistischen Statistik wird hier also nicht eine Punktsch√§tzung vorgenommen (ein ‚Äúwahrer Wert‚Äù gesch√§tzt), sondern es wird ein Verteilung gesch√§tzt.\n\nDie Posterior-Verteilung beschreibt, wie wahrscheinlich verschiedene Werte eines unbekannten Parameters sind ‚Äì basierend auf Vorwissen (Prior) und den beobachteten Daten.\n\nDass der Posterior √ºber alle m√∂glichen Parameterwerte integriert wird, ist eine gr√∂sse St√§rke der Bayesianischen Statistik. So wird der ganze M√∂glichkeitsraum beschrieben. Es wird nicht nur der wahrscheinlichste Parameterwert ber√ºcksichtigt wie bei der Punktsch√§tzung, sondern durch das Einbeziehen der ganzen Parameterverteilung k√∂nnen auch Nebenoptima und ‚Äúfast‚Äù genauso wahrscheinliche Werte einbezogen werden.\nUm die Posterior-Verteilung, also die Wahrscheinlichkeit aller Parameterwerte, zu berechnen wird in der Bayesianischen Statistik das Bayes Theorem verwendet.\n\n\n\n\n\n\nBayes Theorem\n\n\n\nDas Bayes Theorem gibt die Formel f√ºr eine bedingte Wahrscheinlichkeit \\(P(A|B)\\) an.\n\\[ P(A|B) = \\frac{P(B|A)‚ãÖP(A)}{P(B)} \\]\nDas kann gelesen werden als: ‚ÄúDie Wahrscheinlichkeit eines Ereignisses \\(A\\) unter der Bedingung, dass ein Ereignis \\(B\\) wahr ist, ist gleich der a priori Wahrscheinlichkeit, dass \\(A\\) wahr ist, multipliziert mit der Wahrscheinlichkeit, dass \\(B\\) eintritt, wenn \\(A\\) wahr ist. Dividiert wird das Ganze durch die Wahrscheinlichkeit, dass \\(B\\) eintritt, egal ob \\(A\\) wahr oder falsch ist.‚Äù\n\n\nDas bedeutet, um eine Bayesianische Parametersch√§tzung zu machen, m√ºssen wir Vorwissen integrieren. Dies tun wir in Form einer Prior-Verteilung. Ein simple Variante ist, den Prior ist so zu w√§hlen, dass er allen m√∂glichen Werten dieselbe Wahrscheinlichkeit zuschreibt (wie in der Grafik unten). Diese Verteilung wird uniform genannt. Ein uniformer Prior ist aber selten empfehlenswert, da er zu breit und uniformativ ist.\nParametersch√§tzung\n\n\n\n\n\n\n\nHands-on: Bayesianische Parametersch√§tzung in JASP\n\n\n\nAktivieren Sie in JASP das Modul Learn Bayes. W√§hlen Sie unter Learn Bayes &gt; Binomial Estimation mit der Einstellung Enter Sequence.\n1. Modell: Stellen Sie sich vor, sie untersuchen eine Person, welche behauptet, extrasensorische F√§higkeiten zu besitzen. Diese Person behauptet, dass sie bevor eine M√ºnze aufgeworfen wurde vorhersagen kann, auf welcher Seite die M√ºnze landet: Kopf oder Zahl).\n\nWie werden die Daten verteilt sein? Welchen Parameter sch√§tzen wir? Wie sieht das DAG aus?\nWie w√ºrden Sie die Behauptung der Person √ºberpr√ºfen?\n\n2. Daten erheben: Sie werfen die M√ºnze 20 mal und die Person macht x korrekte Vorhersagen.\n\nGlauben Sie, dass die Person √ºber extra-sensorische F√§higkeiten verf√ºgt? Sind Sie skeptisch?\nUnter den Dropdown Menus Model, Prior and Posterior Distributions und Plots gibt es verschiedene Checkboxes. Versuchen Sie herauszufinden, was diese bewirken.\n\n3. Vorwissen / Prior definieren.\n\nWie k√∂nnen Sie Ihr Vorwissen in die Analyse einbeziehen? Wie verbinden Sie Ihr Vorwissen mit den beobachteten Daten?\nWelcher Prior bedeutet was (vgl. Bild unten)?\nPassen Sie Ihren Prior f√ºr \\(\\theta\\) in JASP an.\n\nBeta Verteilungen",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik</span>"
    ]
  },
  {
    "objectID": "parameterestimates.html#zusammenfassen-von-posteriors",
    "href": "parameterestimates.html#zusammenfassen-von-posteriors",
    "title": "14¬† Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik",
    "section": "14.2 Zusammenfassen von Posteriors",
    "text": "14.2 Zusammenfassen von Posteriors\nDer Vorteil einer Posterior-Verteilung im Vergleich zu einer Punktsch√§tzung ist es, dass wir damit Aussagen zu der Wahrscheinlichkeit eines Parameterwertes machen k√∂nnen. Da Posterior-Verteilungen oft komplex sind, fassen wir sie mit Hilfe von Kennzahlen zusammen.\nTypische Zusammenfassungen sind Mittelwert, Median, Modus und Intervalle (Credible Intervals). Hier einige Beispiele, zu m√∂glichen Aussagen:\n\nA. \\(\\theta\\) liegt am wahrscheinlichsten bei \\(X\\). (Mittelwert, Median, Modus)\nB. Die Wahrscheinlichkeit, dass \\(\\theta\\) mindestens \\(X\\) ist, liegt bei \\(P_x\\).\nC. Die Wahrscheinlichkeit, dass \\(\\theta\\) kleiner als \\(X\\) ist, liegt bei \\(P_x\\).\nD. Die Wahrscheinlichkeit, dass \\(\\theta\\) zwischen \\(X_{tiefer}\\) und \\(X_{h√∂her}\\) liegt ist \\(P_x\\).\nE. \\(\\theta\\) liegt mit einer Wahrscheinlichkeit von 95% zwischen \\(X_{tiefer}\\) und \\(X_{h√∂her}\\).\nF. \\(\\theta\\) liegt mit einer Wahrscheinlichkeit von 20% ausserhalb des Bereichs zwischen \\(X_{tiefer}\\) und \\(X_{h√∂her}\\).\n\n\n\nGute M√∂glichkeiten zum Zusammenfassen von Posterior-Verteilungen bieten die Plot-Funktionen R-Packages {brms}, {tidybayes} und {bayesplot}.\n\n\n\n\n\n\n\nHands-on: Credible interval vs.¬†confidence interval\n\n\n\nCredible interval ist ein bayesianisches Konzept, das sich vom confidence interval (Konfidenzintervall) in der frequentistischen Statistik unterscheidet. Ein credible interval ist ein Intervall, das eine bestimmte Wahrscheinlichkeit enth√§lt, dass der wahre Parameter innerhalb dieses Intervalls liegt. Dies sollte nicht mit dem Konfidenzintervall verwechselt werden. K√∂nnen Sie sich daran erinnern, wie ein Konfidenzintervall definiert ist? Was ist der Unterschied zwischen einem Konfidenzintervall und einem credible interval?",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik</span>"
    ]
  },
  {
    "objectID": "parameterestimates.html#entscheidung",
    "href": "parameterestimates.html#entscheidung",
    "title": "14¬† Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik",
    "section": "14.3 Entscheidung",
    "text": "14.3 Entscheidung\nAnhand der Posterior-Verteilung eines Parameters kann eine Entscheidung getroffen werden. Wichtig ist hierbei, dass diese Kriterien vor dem Betrachten der Posterior-Verteilungen festgesetzt werden (analog zu den Hypothesen und Signifikanzniveaus bei frequentistischen Verfahren). Beispiele f√ºr Entscheidungskriterien sind:\n\nIm besten Fall werden (unabh√§ngig ob frequentistisch oder bayesianisch analysiert wird) die Hypothesen, Analysen, Entscheidungskriterien, etc. vor der Datenanalyse festgelegt, z.B. durch das Erstellen einer Pr√§registration!\n\n\nWenn 95% der gesch√§tzen Parameterwerte √ºber einem bestimmten Cut-off liegen, ist der Unterschied bedeutsam.\nIst der gesch√§tzte Parameterwert mehr als 2 Einheiten von 0 verschieden, so wird auf einen Unterschied geschlossen.\n\naber auch:\n\nUnterscheiden sich die Posterior-Verteilungen zweier Parametersch√§tzungen nicht zu mehr als 10% wird darauf geschlossen, dass kein Unterschied besteht.\nWeicht der gesch√§tzte Parameterwert weniger als 2 Einheiten von 0 ab, gibt es keinen Unterschied.\n\nHier zeigt sich der Vorteil der Bayesianischen Parametersch√§tzung: Wir k√∂nnen durch das Zusammenfassen der Posterior-Verteilung direkt evidence of absence testen.\n\n\n\n\n\n\nHands-on: Entscheidungen aufgrund von Posterior-Verteilungen\n\n\n\nWie k√∂nnten Entscheidungen aussehen bez√ºglich unserer Stroop oder Random-Dot Daten?\nErstellen Sie je ein Entscheidungskriterium, f√ºr das Erkennen eines Effekts und f√ºr die Abwesenheit eines Effekts.\n\n\n\n14.3.1 Wrap-up\nZusammenfassend kann gesagt werden:\n\nIn der frequentistischen Statistik wird angenommen, dass der Parameter einen wahren Wert hat, den wir aber nicht kennen. Wir erhalten als Resultat eine Punktsch√§tzung f√ºr den Parameter und k√∂nnen keine Aussage √ºber die Wahrscheinlichkeit dieses einen gesch√§tzten Parameterwerts machen. Der 95%-CI (confidence interval) sagt aus, dass bei Wiederholung des Experiments der ‚Äúwahre‚Äù Parameterwert in 95% der Konfidenzintervalle enthalten sein wird.\nIn der bayesianischen Statistik wird angenommen, dass der Parameter eine Wahrscheinlichkeitsverteilung hat, die wir sch√§tzen k√∂nnen. Es muss zus√§tzlich eine Priorverteilung festgelegt werden. Wir erhalten eine Posterior Verteilung f√ºr die Parameterwerte und k√∂nnen eine Aussage √ºber Wahrscheinlichkeit eines Parameterwerts oder eines Modelles machen. Der 95%-CrI (credible interval) enth√§lt zu 95% den ‚Äúwahren‚Äù Parameterwert.\n\n\n‚ÄúWahr‚Äù bedeutet hier, den Parameterwert der (angenommen ein passendes Modell wurde verwendet) zu diesen Daten gef√ºhrt hat.\n\n\n\n\n\n\n\nNote\n\n\n\nIn der Bayesianischen Statistik erhalten wir nach der Anwendung des Satzes von Bayes die sogenannte Posterior-Verteilung. Sie beschreibt, wie wahrscheinlich verschiedene Werte eines unbekannten Parameters sind ‚Äì basierend auf unserem Vorwissen (Prior) und den beobachteten Daten.\n\n\n\n\n14.3.2 Weiterf√ºhrende Informationen\n\nKruschke, J.K., Liddell, T.M. The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin & Review 25, 178‚Äì206 (2018). https://doi.org/10.3758/s13423-016-1221-4",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Parametersch√§tzung: Einf√ºhrung in die Bayesianische Statistik</span>"
    ]
  },
  {
    "objectID": "hypothesistests.html",
    "href": "hypothesistests.html",
    "title": "15¬† Hypothesentests: Bayesianischer \\(t\\)-Test und √Ñquivalenztests (TOSTs)",
    "section": "",
    "text": "15.1 Bayesianische Hypothesentests",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Hypothesentests: Bayesianischer $t$-Test und √Ñquivalenztests (TOSTs)</span>"
    ]
  },
  {
    "objectID": "hypothesistests.html#bayesianische-hypothesentests",
    "href": "hypothesistests.html#bayesianische-hypothesentests",
    "title": "15¬† Hypothesentests: Bayesianischer \\(t\\)-Test und √Ñquivalenztests (TOSTs)",
    "section": "",
    "text": "15.1.1 Modellvergleich\nBeim Modellvergleich interessiert welches Modell die Daten besser erkl√§rt. Die Bayes‚Äôsche Regel kann verwendet werden, um die Wahrscheinlichkeit zweier Modelle \\(\\mathcal{M1}\\) und \\(\\mathcal{M2}\\) zu berechnen (gemittelt √ºber alle m√∂glichen Parameterwerte innerhalb des Modells):\n\\[\np(\\mathcal{M}_1 | y) = \\frac{P(y | \\mathcal{M}_1) p(\\mathcal{M}_1)}{p(y)}\n\\]\nund\n\\[\np(\\mathcal{M}_2 | y) = \\frac{P(y | \\mathcal{M}_2) p(\\mathcal{M}_2)}{p(y)}\n\\]\nHierf√ºr kann das Verh√§ltnis der beiden Wahrscheinlichkeiten (Posterior Odds) berechnet werden: \\(p(\\mathcal{M}_1 | y) / p(\\mathcal{M}_2 | y)\\), was gek√ºrzt folgende Formel ergibt:\n\\[\n\\underbrace{\\frac{p(\\mathcal{M}_1 | y)} {p(\\mathcal{M}_2 | y)}}_\\text{Posterior odds} = \\underbrace{\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}}_\\text{Ratio of marginal likelihoods} \\cdot \\underbrace{ \\frac{p(\\mathcal{M}_1)}{p(\\mathcal{M}_2)}}_\\text{Prior odds}\n\\]\nAuf der linken Seite steht das Verh√§ltnis der a-posteriori Wahrscheinlichkeiten der beiden Modelle, auf der rechten Seite das Verh√§ltnis der Marginal Likelihoods der beiden Modelle, multipliziert mit den a-priori Wahrscheinlichkeiten jedes Modells.\nDie Marginal Likelihoods (auch bekannt als Modell-Evidenz) zeigen, wie gut jedes Modell die Daten erkl√§rt. Diese geben dar√ºber Auskunft, wie wahrscheinlich die Daten sind, wenn wir alle m√∂glichen Parameterwerte ber√ºcksichtigen. Die Marginal Likelihoods sind also die Wahrscheinlichkeit der Daten, gemittelt √ºber alle m√∂glichen Parameterwerte.\n\n\n15.1.2 Bayes Factors\nDie Posterior Odds sagen uns, welches Modell wir a-priori und a-posteriori f√ºr wahrscheinlicher halten. Da unsere a-priori √úberzeugungen aber subjektiv sein k√∂nnen, sind wir eigentlich nur an dem Verh√§ltnis der marginalen Likelihoods interessiert. Wir k√∂nnen annehmen, dass a-priori die beiden Modelle gleichwahrscheinlich sind; das heisst, wir setzen die Prior Odds auf 1 setzen. So erhalten wir den Bayes Factor:\n\\[\n\\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}\n\\]\nWenn \\(P(y | \\mathcal{M}_1)\\) gr√∂sser ist als \\(P(y | \\mathcal{M}_2)\\), dann ist der Bayes Factor gr√∂sser als 1. Falls \\(P(y | \\mathcal{M}_1)\\) kleiner ist als \\(P(y | \\mathcal{M}_2)\\), dann ist der Bayes Factor kleiner als 1. Der Bayes Factor gibt also direkt an, welches Modell die Daten besser erkl√§rt.\nWenn wir zwei Modelle \\(\\mathcal{M}_1\\) und \\(\\mathcal{M}_2\\) vergleichen, wird der Bayes Factor oftmals so geschrieben:\n\\[ BF_{12} = \\frac{P(y | \\mathcal{M}_1)}{P(y | \\mathcal{M}_2)}\\]\n\\(BF_{12}\\) ist also der Bayes Factor f√ºr \\(\\mathcal{M}_1\\) und gibt an um wieviel \\(\\mathcal{M}_1\\) die Daten besser ‚Äúerkl√§rt‚Äù.\nAls Beispiel, wenn wir ein \\(BF_{12} = 5\\) erhalten, bedeutet dies, dass die Daten 5 Mal wahrscheinlicher unter Modell 1 als unter Modell 2 aufgetreten sind. Umgekehrt, wenn \\(BF_{12} = 0.2\\), dann sind die Daten 5 Mal wahrscheinlicher unter Modell 2 aufgetreten.\nWenn wir \\(BF_{12} = 0.2\\) erhalten, ist es einfacher, Z√§hler und Nenner zu vertauschen:\n\\[ BF_{21} = \\frac{P(y | \\mathcal{M}_2)}{P(y | \\mathcal{M}_1)}\\]\nDie folgenden Interpretationen von Bayes Factors werden manchmal verwendet, obwohl es nicht wirklich notwendig ist, diese zu klassifizieren. Bayes Factors sind ein kontinuierliches Mass f√ºr Evidenz.\nZusammenfassend kann gesagt werden:\n\nDer Bayes Factor ist ein Verh√§ltnis zweier konkurrierender statistischer Modelle, die durch ihre Evidenz dargestellt werden, und wird verwendet, um die Unterst√ºtzung f√ºr ein Modell gegen√ºber dem anderen zu quantifizieren. Die fraglichen Modelle k√∂nnen einen gemeinsamen Satz von Parametern haben, z. B. eine Nullhypothese und eine Alternative, dies ist jedoch nicht erforderlich. Zum Beispiel k√∂nnte es sich auch um ein nichtlineares Modell im Vergleich zu seiner linearen N√§herung handeln. Wikipedia\n\nBayes Factors sind eine alternative Methode, um Evidenz zu quantifizieren. Alternativ zu p-Werten bieten Bayes Factors Evidenz f√ºr oder gegen eine Hypothese.\n\n\\(p\\)-Werte sind schwierig zu erkl√§ren, auch f√ºr erfahrene Forschende, wie dieses Video zeigt.\n\n\n\n15.1.3 Bayesianischer \\(t\\)-Test\nWir f√ºhren oft Modellvergleiche zwischen einer Nullhypothese \\(\\mathcal{H}_0\\) und einer alternativen Hypothese \\(\\mathcal{H}_1\\) durch (Die Begriffe ‚ÄúModell‚Äù und ‚ÄúHypothese‚Äù werden synonym verwendet). Eine Nullhypothese bedeutet, dass wir den Wert des Parameters auf einen bestimmten Wert festlegen, z.B. \\(\\theta = 0.5\\). Die alternative Hypothese bedeutet, dass wir den Wert des Parameters nicht festlegen, sondern eine a-priori Verteilung annehmen. Im Gegensatz zu NHST muss die Alternativhypothese spezifiziert werden. Mit anderen Worten, die Parameter m√ºssen eine a-priori Verteilung erhalten.\nIn JASP werden Bayes Factors (BF) so berichtet:\n\\[ BF_{10} = \\frac{P(y | \\mathcal{H}_1)}{P(y | \\mathcal{H}_0)}\\]\nDies ist ein BF f√ºr eine ungerichtete Alternative \\(\\mathcal{H}_1\\) gegen die Nullhypothese \\(\\mathcal{H}_0\\). Wenn wir einen gerichteten Test durchf√ºhren, dann wird der BF entweder so (\\(&gt;0\\)):\n\\[ BF_{+0} = \\frac{P(y | \\mathcal{H}_+)}{P(y | \\mathcal{H}_0)}\\]\noder so (\\(&lt;0\\)) berichtet. \\[ BF_{-0} = \\frac{P(y | \\mathcal{H}_-)}{P(y | \\mathcal{H}_0)}\\]\nWenn wir nun einen BF f√ºr die Nullhypothese wollen, k√∂nnen wir einfach den Kehrwert von \\(BF_{10}\\) nehmen:\n\\[ BF_{01} = \\frac{1}{BF_{10}}\\]\n\n\n\n\n\n\nHands-on: Bayesiansicher \\(t\\)-Test in JASP\n\n\n\n\nLaden Sie hier den Stroop Datensatz herunter. Der Datensatz wurde f√ºr diese Zwecke ins wide-Format angepasst.\nLaden Sie den Datensatz in JASP und schauen Sie ihn an.\nWie k√∂nnte die Forschungsfrage lauten? Was ist die Null- und Alternativhypothese?\nF√ºhren Sie einen Bayesian Paired Sample $t$-Test aus.\nExplorieren Sie die Resultate und welche Optionen Sie f√ºr weitere Einstellungen haben.\n\nWo kann der Prior angepasst werden?\nWo k√∂nnen Hypothesen spezifiziert werden?\nWo k√∂nnen Sie den Posterior anschauen?\nWelche Visualisierungsm√∂glichkeiten haben Sie?\n\nWelche Bayes Factors finden Sie f√ºr die Nullhypothese? Und f√ºr die Alternativhypothese?\n\n\n\n\n\n\n\n\n\nWeiterf√ºhrende Informationen zu Bayesianischem Hypothesentesten\n\n\n\n\nVertiefende Informationen, inkl. Herleitung, zu Bayesianischen Hypothesentest finden Sie hier.\nHier finden Sie eine interaktive Visualisierung.\nbrms ist ein R-Package, welches sich f√ºr Bayesianische Multilevel-Modelle eignet, da JASP relativ rasch an die Grenzen st√∂sst f√ºr komplexere Modelle.",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Hypothesentests: Bayesianischer $t$-Test und √Ñquivalenztests (TOSTs)</span>"
    ]
  },
  {
    "objectID": "hypothesistests.html#√§quivalenztests",
    "href": "hypothesistests.html#√§quivalenztests",
    "title": "15¬† Hypothesentests: Bayesianischer \\(t\\)-Test und √Ñquivalenztests (TOSTs)",
    "section": "15.2 √Ñquivalenztests",
    "text": "15.2 √Ñquivalenztests\nEin nicht signifikanter Nullhypothesensignifikanztest (NHST) bedeutet nicht zwingend, dass kein Unterschied zwischen Gruppen/Bedingungen besteht, nur dass keiner gefunden werden konnte. Bei einer Power von 80% ist betr√§gt die Wahrscheinlichkeit die Nullhypothese f√§lschlicherweise nicht abzulehnen 20%!\nStatt aussschliesslich einen NHST durchzuf√ºhren und gegen die Nullhypothese zu testen, k√∂nnen √Ñquivalenztests, z.B. das ‚ÄúTwo One-Sided Tests‚Äù (TOST) Verfahren durchgef√ºhrt werden. Dabei werden zwei einseitige \\(t\\)-Tests ausgef√ºhrt, um zu testen, ob der Mittelwertsunterschied innerhalb eines gewissen Rahmens liegt.\nDieser Rahmen muss von den Forschenden festgelegt werden und bezeichnet die kleinstm√∂glichste interessierende Effekt: Smallest Effect Size of Interest (SESOI). Mit dem TOST-Verfahren wird festgestellt, ob der gefundene Unterschied √ºberraschend gering ist, wenn ein Effekt mindestens so gross wie der definierte SESOI tats√§chlich existiert. (Lakens, Scheel & Isager, 2018).\n\nHier finden Sie eine interaktive Visualisierung des √Ñquivalenztests.\n\n\n15.2.1 Festlegen des SESOIs\nDer SESOI wird durch eine untere (lower bound \\(\\Delta\\)L) und obere Grenze (upper bound \\(\\Delta\\)U). Es gibt keine vorgegebenen Regeln f√ºr das Festlegen von SESOIs. Sie m√ºssen von den Forschenden (vor der Datenanalyse) passend f√ºr Fragestellung und Feld festgelegt werden. Daf√ºr gibt es folgende Ans√§tze:\n\nMehr dazu finden Sie hier Lakens et al.¬†2018\n\n\nSubjektive Ans√§tze:\n\nBenchmarks (z.B. Standardisierte Effektgr√∂ssen wie \\(d\\) = 0.5)\nvorherige Studien\nbegr√ºndet in vorhandenen Ressourcen f√ºr die Studie\n\nObjektive Ans√§tze:\n\ntheoretische Begr√ºndungen (z.B. just-noticeable difference, JND)\nbasierend auf quantifizierbaren theoretischen Vorhersagen (z.B. durch computational models)\n\n\n\n\n15.2.2 TOST-Verfahren\nNach dem Festlegen des SESOIs werden zwei einseitige \\(t\\)-Tests durchgef√ºhrt:\n\nTest, ob Unterschied signifikant h√∂her als untere Grenze (\\(\\Delta\\)L)\nTest, ob Unterschied signifikant tiefere als obere Grenze (\\(\\Delta\\)U)\n\nWenn beide signifikant ausfallen sind die Gruppen/Bedingungen √§quivalent. Es muss nicht f√ºr zweifaches Testen korrigiert werden, weil beide Tests signifikant sein m√ºssen, um √Ñquivalenz anzunehmen.\nAnstelle von \\(p\\)-Werten k√∂nnen auch Konfidenzintervalle verwendet werden: Wenn das 90% Konfidenzintervall innerhalb des SESOIs liegt wird √Ñquivalenz angenommen. Das Konfidenzintervall muss festgelegt werden, es k√∂nnte auch z.B. 95%, 87% oder 99% sein (oder eine andere Zahl). Es muss daher zwingend vor dem Test gew√§hlt werden.\n\n\n\n\n\n\nHands-on: √Ñquivalenztests in JASP\n\n\n\n\nDefinieren Sie einen SESOI f√ºr den Unterschied der Reaktionszeiten zwischen der kongruenten und inkongruenten Bedingung im Stroop Task. Was ist \\(\\Delta\\)L, was ist \\(\\Delta\\)U?\nAktivieren Sie in JASP das Modul Equivalence T-Tests.\nSie k√∂nnen wieder dieselben Daten wie vorhin verwenden.\nW√§hlen Sie die passenden Variablen zum Vergleich aus.\nGeben Sie bei Equivalence Region Ihren SESOI ein (in Rohwerten oder standardisiert).\nExplorieren Sie die Resultate und welche Optionen Sie f√ºr weitere Einstellungen haben.\n\n\n\n\n\n\n\n\n\nWeiterf√ºhrende Informationen zu √Ñquivalenztests\n\n\n\n\nVertiefende Informationen finden Sie in diesem Paper.\nHier finden Sie eine interaktive Visualisierung.\nEquivalence-Testing in JASP\nIn Jamovi k√∂nnen √Ñquivalenztest mit dem Modul TOSTER durchgef√ºhrt werden (weitere Informationen)",
    "crumbs": [
      "Datenanalyse",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Hypothesentests: Bayesianischer $t$-Test und √Ñquivalenztests (TOSTs)</span>"
    ]
  },
  {
    "objectID": "uebung_4.html",
    "href": "uebung_4.html",
    "title": "√úbung 4",
    "section": "",
    "text": "Auftrag\nDatenanalyse\nData Report in Form eines Posters erstellen\nWichtig:",
    "crumbs": [
      "Datenanalyse",
      "√úbung 4"
    ]
  },
  {
    "objectID": "uebung_4.html#auftrag",
    "href": "uebung_4.html#auftrag",
    "title": "√úbung 4",
    "section": "",
    "text": "optional: Datenvorverarbeiten in R (z.B. Filtern f√ºr bestimmte Gruppen/F√§lle, nur wenn Bedarf)\nAnalysieren der Daten des Random-Dot Experiments\n\n\n\nPoster erstellen\n\n\n\nInformation zum Arbeiten in Kleingruppen:\n\n√úbungen d√ºrfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen m√ºssen die √úbung auf Ilias hochladen, um die √úbung zu bestehen.\nDie Files von Gruppenarbeiten m√ºssen folgendermassen benannt werden, damit wir sehen, welche √úbungsabgaben zusammengeh√∂ren: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. analyse_GW_EW.jasp. Geben Sie bei allen Files die Initialen in derselben Reihenfolge an.\n\nArbeitsanweisung unter dem Unterkapitel Vorgehen:\n\nLesen Sie die Anweisungen genau durch und geben Sie die Dateien in diesem Format ab (z.B. Benennung der Dateien).\nArbeiten Sie entlang der Arbeitsanweisung, um den Prozess zu vereinfachen.\n\nEs wird eine kleine Poster-Session geben, bei der die Poster angeschaut werden k√∂nnen.\n\nVerkleinern Sie die Schriftgr√∂sse nicht zu sehr. Die Poster werden auf A3-Format von uns ausgedruckt. Bei zu kleiner Schrift wird das schwierig.\nDas Poster darf in Deutsch oder Englisch geschrieben sein.",
    "crumbs": [
      "Datenanalyse",
      "√úbung 4"
    ]
  },
  {
    "objectID": "uebung_4.html#vorgehen",
    "href": "uebung_4.html#vorgehen",
    "title": "√úbung 4",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nDownload und Setup\n\n\n\n\n\n\nDatensatz Update 07.04.2025\n\n\n\nDer Datensatz wurde nochmals vorverarbeitet und hochgeladen.\nInformationen zu den Aussschlusskriterien und Ausschl√ºssen:\n\nAlle Trials mit Reaktionszeiten unter 100ms und √ºber 12 Sekunden wurden ausgeschlossen.\nAlle Personen mit weniger als 50 g√ºltigen Trials (von 60) pro Bedingung wurden ausgeschlossen. (= 3 Personen)\nAlle Personen mit einer Accuracy von weniger als 55% wurden ausgeschlossen. (= 39 Personen)\n\nFalls Sie den Datensatz vor dem 07.04.2025 heruntergeladen haben, k√∂nnen Sie ihn hier nochmals herunterladen (oder via zip-Ordner).\n\nwide Format\nlong Format\n\n\n\n\nLaden Sie die Daten und die Postervorlage hier uebung-4 herunter und entzippen Sie den Ordner. Der Ordner enth√§lt 2 Datens√§tze mit vorverarbeiteten Daten des Random-Dot Experiments:\n\ndata_random_dot_wide.csv: Daten im wide-Format, geeignet f√ºr JASP-Analysen\ndata_random_dot_long.csv: Daten im long-Format, geeignet f√ºr R- oder JASP-Visualisierung (unter Descriptives) (optional)\n\n\nEr enth√§lt eine id-Variable und Variablen(paare):\n\nVersuchspersonenidentifikation (id)\nrt_speed und rt_accuracy: Mittelwerte der Reaktionszeiten f√ºr die Instruktion speed(so schnell wie m√∂glich antworten) und accuracy (so richtig wie m√∂glich antworten) pro Versuchsperson\ncorr_speed und corr_accuracy: Mittelwerte der korrekten Antworten f√ºr die Instruktion speed(so schnell wie m√∂glich antworten) und accuracy (so richtig wie m√∂glich antworten) pro Versuchsperson\nrt_speed_left und rt_speed_right: Mittelwerte der Reaktionszeiten f√ºr die Instruktion speed(so schnell wie m√∂glich antworten), bei Bewegung der Punkte nach links (left) oder gegen rechts (right) pro Versuchsperson\nrt_accuracy_left und rt_accuracy_right: Mittelwerte der Reaktionszeiten f√ºr die Instruktion accuracy(so richtig wie m√∂glich antworten) bei Bewegung der Punkte nach links (left) oder gegen rechts (right) pro Versuchsperson\ncorr_speed_left und corr_speed_right: Mittelwerte der korrekten Antworten f√ºr die Instruktion speed(so schnell wie m√∂glich antworten), bei Bewegung der Punkte nach links (left) oder gegen rechts (right) pro Versuchsperson\ncorr_accuracy_left und corr_accuracy_right: Mittelwerte der korrekten Antworten f√ºr die Instruktion accuracy(so richtig wie m√∂glich antworten), bei Bewegung der Punkte nach links (left) oder gegen rechts (right) pro Versuchsperson\n\n\n\n1. Teil: Poster (Pr√§registration)\nW√§hlen Sie eine Fragestellung und ein Variablenpaar aus.\n\na. Einf√ºhrung/Introduction: Beschreiben Sie\n\nIhre Fragestellung/Forschungsfrage\nRelevanz\nHypothesen (Nullhypothese, Alternativhypothese)\nf√ºgen Sie mind. 1 Referenz ein\n\nb. Methode/Methods: Beschreiben Sie\n\ndas Sample (N)\ndas Experimentalparadigma / den Task\nden Ablauf (evtl. eine Flowchart/ein Stimulusbild etc. einf√ºgen)\nUV(n)\nAV(n)\ndas Analyseverfahren\n\n\nW√§hlen Sie daf√ºr eines dieser Analyseverfahren in JASP aus:\n- Bayesianischer t-Test f√ºr abh√§ngige Stichproben (Paired Samples T-Test)\n- Bayesiansicher t-Test f√ºr unabh√§ngige Stichproben (Independent Samples T-Test)\n- √Ñquivalenztest f√ºr abh√§ngige Stichproben (Equivalence Paired Samples T-Test)\n- √Ñquivalenztest f√ºr unabh√§ngige Stichproben (Equivalence Independent Samples T-Test)\nGeben Sie auch an:\n- f√ºr √Ñquivalenztests: Equivalence Region (2 boundaries, raw/cohens-d?)\n- f√ºr Bayesianische Tests: gew√§hlter Prior (Standard ist ok)\n\n\n2. Teil: Datenanalyse in JASP\n\na. Lesen Sie f√ºr die Analysen das wide-Datenfile in JASP ein\nb. Schauen Sie sich die Deskriptivstatistik an\n\nTipp: Mit den Daten im long Format k√∂nnen Sie in Jasp Descriptives &gt; Raincloud Plots oder in R den esquisser() verwenden.\n\nc. W√§hlen Sie den geplanten Test.\n\nBayesianischer t-Test f√ºr abh√§ngige Stichproben (Paired Samples T-Test)\nBayesiansicher t-Test f√ºr unabh√§ngige Stichproben (Independent Samples T-Test)\n√Ñquivalenztest f√ºr abh√§ngige Stichproben (Equivalence Paired Samples T-Test)\n√Ñquivalenztest f√ºr unabh√§ngige Stichproben (Equivalence Independent Samples T-Test)\n\nd. W√§hlen Sie das geplante Variablenpaar und f√ºhren Sie den Test aus.\n\n\n\n3. Teil: Poster (Ergebnisse)\n\na. Resultate/Results: Berichten Sie die Resultate\n\nf√ºr √Ñquivalenztests: Statistic, t, df, CI90%\nf√ºr Bayesianische Tests: BF10, BF01, Median, CI95%\nF√ºgen Sie mind. 1 Plot ein (aus JASP, R, Esquisser)\nF√ºgen Sie evtl. eine Tabelle ein\nBeschreiben Sie Ihre Resultate in mind. 2 Punkten\n\nb. Diskussion/Discussion:\n\nWelche Schlussfolgerungen k√∂nnen Sie aus Ihrer Analyse ziehen?\nWelche Schlussfolgerungen k√∂nnen Sie aus Ihrer Analyse nicht ziehen? / Welche Limitation(en) hat Ihre Analyse?\n\nWelche Implikation haben Ihre Resultate?\n\n\n\n\nHochladen der Dateien auf Ilias\nLaden Sie folgende Dateien unter √úbung 4 auf Ilias hoch:\n\n.jasp-File\nPoster (.pdf)",
    "crumbs": [
      "Datenanalyse",
      "√úbung 4"
    ]
  },
  {
    "objectID": "uebung_4.html#abgabetermin",
    "href": "uebung_4.html#abgabetermin",
    "title": "√úbung 4",
    "section": "Abgabetermin",
    "text": "Abgabetermin\nDer Abgabetermin f√ºr diese √úbung ist der 08. Mai 2025.",
    "crumbs": [
      "Datenanalyse",
      "√úbung 4"
    ]
  },
  {
    "objectID": "opensci.html",
    "href": "opensci.html",
    "title": "16¬† Getting Started: Open Science and Good Practices",
    "section": "",
    "text": "16.1 Was ist das Problem ?",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Getting Started: Open Science and Good Practices</span>"
    ]
  },
  {
    "objectID": "opensci.html#was-ist-das-problem",
    "href": "opensci.html#was-ist-das-problem",
    "title": "16¬† Getting Started: Open Science and Good Practices",
    "section": "",
    "text": "Reproduzierbarkeitskrise in der Psychologie (und anderen Fachbereichen)\nEin Forschungsteam versuchte, 100 psychologische Studien zu replizieren ‚Äì nur etwa 39 % zeigten denselben Effekt (https://osf.io/ezcuj/)\nHauptgr√ºnde: P-Hacking und mangelnde Transparenz\n\n\n\n\nsource: www.nature.com",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Getting Started: Open Science and Good Practices</span>"
    ]
  },
  {
    "objectID": "opensci.html#open-science",
    "href": "opensci.html#open-science",
    "title": "16¬† Getting Started: Open Science and Good Practices",
    "section": "16.2 Open Science",
    "text": "16.2 Open Science\n\n16.2.1 FAIR Principles\nFAIR ist ein Satz von Leitprinzipien, die Daten n√ºtzlicher machen sollen ‚Äì nicht nur f√ºr andere, sondern auch f√ºr das eigene zuk√ºnftige Ich. FAIR steht f√ºr Findable (auffindbar), Accessible (zug√§nglich), Interoperable (interoperabel) und Reusable (wiederverwendbar).\n\n\n\n\n\n\n\n\nPrinzip\nWas es bedeutet\nBeispiel\n\n\n\n\nF ‚Äì Findable (Auffindbar)\nDaten sollen sowohl f√ºr Menschen als auch f√ºr Computer leicht auffindbar sein. Sie brauchen eine eindeutige Kennung und klare Metadaten (Informationen √ºber die Daten).\nLaden Sie Ihren Datensatz in ein √∂ffentliches Repositorium (z.‚ÄØB. OSF, Zenodo) mit DOI und einem aussagekr√§ftigen Titel hoch.\n\n\nA ‚Äì Accessible (Zug√§nglich)\nSobald Daten gefunden wurden, sollen sie √ºber standardisierte Wege abrufbar sein ‚Äì mit klaren Zugriffsbedingungen.\nAuch wenn der Zugriff eingeschr√§nkt ist, sollten die Metadaten √∂ffentlich sein und der Zugang erkl√§rt werden.\n\n\nI ‚Äì Interoperable (Interoperabel)\nDaten sollen in standardisierten Formaten und Begriffen strukturiert sein, damit sie mit anderen Daten und Tools zusammenarbeiten k√∂nnen.\nVerwenden Sie CSV statt propriet√§rer Formate und sprechende Variablennamen (z.‚ÄØB. ‚Äûalter‚Äú statt ‚Äûa_g3‚Äú).\n\n\nR ‚Äì Reusable (Wiederverwendbar)\nDaten sollen ausreichend dokumentiert sein, damit andere sie korrekt interpretieren und wiederverwenden k√∂nnen.\nF√ºgen Sie eine README-Datei mit Beschreibung der Variablen hinzu und verwenden Sie eine offene Lizenz wie CC-BY.\n\n\n\nsource: https://www.go-fair.org/fair-principles/\n\n\n\nsource: FOSTER Open Science Training Handbook (https://github.com/Open-Science-Training-Handbook)\n\n\n\n\n16.2.2 Reproduzierbarkeit in der Praxis: rMarkdown\n\n\n\n\n\n\nHands-on: rMarkdown selber erstellen\n\n\n\nF√ºr diesen Teil ben√∂tigen Sie ein RProject und die Daten, die Sie erhoben haben:\n\nErstellen Sie ein R Markdown file in R.\nSpeichern Sie dieses file in den selben Ordner als Ihr R Projekt.\nGeben Sie einen Titel und Datum ein.\nKopieren Sie Ihren Code aus √úbung 3 und unterteilen Sie ihn in verschiedene code chunks.\nKommentieren Sie jeden chunk und erstellen Sie eine Outline.\nKlicken Sie auf Knit to HTML.\n√Ñndern Sie die Chunk Optionen ‚Äúinclude‚Äù und ‚Äúecho‚Äù, und klicken Sie wieder auf Knit to HTML. Was bewirkt das? (https://rmarkdown.rstudio.com/lesson-3.html)\n\n\n\nMehr Infos hier: https://rmarkdown.rstudio.com/index.html\n\n\n\nsource: https://imgflip.com/i/1v1jxs",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Getting Started: Open Science and Good Practices</span>"
    ]
  },
  {
    "objectID": "opensci.html#versionskontrolle-zusammenarbeit-mit-git",
    "href": "opensci.html#versionskontrolle-zusammenarbeit-mit-git",
    "title": "16¬† Getting Started: Open Science and Good Practices",
    "section": "16.3 Versionskontrolle & Zusammenarbeit mit Git",
    "text": "16.3 Versionskontrolle & Zusammenarbeit mit Git\nHatten Sie schon einmal eine Datei mit einem Namen wie: final_final_v4_REAL?\n\nGit verfolgt jede √Ñnderung, die Sie an Dateien vornehmen ‚Äì wie eine Zeitmaschine f√ºr Ihr Projekt.\nEs ist eine Cloud-Plattform, um Projekte zu speichern, zu teilen und gemeinsam daran zu arbeiten.\n\n\n\n\n\n\n\nHands-on: Git vs Google Drive/Docs\n\n\n\n\nGehen Sie zur Dokumentation von GitHub oder GitLab\nDiskutieren Sie: Was sind Unterschiede zwischen Git und Google Drive oder anderen ‚Äúklassischen‚Äù Cloud-Plattformen?",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Getting Started: Open Science and Good Practices</span>"
    ]
  },
  {
    "objectID": "opensci.html#preregistration",
    "href": "opensci.html#preregistration",
    "title": "16¬† Getting Started: Open Science and Good Practices",
    "section": "16.4 Preregistration",
    "text": "16.4 Preregistration\n\n16.4.1 Was ist Preregistration ?\n\nEin Dokument, das Ihr Forschungsdesign und Ihre Analyse im Voraus festlegt ‚Äì also bevor Sie das Projekt tats√§chlich beginnen (z.‚ÄØB. bevor Sie mit der Datenerhebung starten)\nEs hilft dabei, Ihre Wissenschaft transparenter und vertrauensw√ºrdiger zu machen\nEs sch√ºtzt vor P-Hacking und kognitiven Verzerrungen\n\nF√ºr weitere Informationen: https://help.osf.io/article/330-welcome-to-registrations\n\n\n\n\n\n\nHands-on: Preregistration selber machen\n\n\n\n\nGehen Sie auf https://aspredicted.org/\nKreuzen Sie Just trying it out an\nKlicken Sie auf Create a new pre-registration\nGeben Sie Ihre Unibe-Email ein und Continue\nWarten Sie, bis Sie einen Link bekommen und klicken Sie diesen Link\nKlicken Sie noch einmal auf I am just trying things out\nErstellen Sie eine Preregistrierung f√ºr Ihr Stroop oder Random-Dot Experiment.\n\n\n\n\nExtra Ressourcen:\n\nGood practices for scientific computing\nBuilding reproducible analytical pipelines with R",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Getting Started: Open Science and Good Practices</span>"
    ]
  },
  {
    "objectID": "goodpractices_data.html",
    "href": "goodpractices_data.html",
    "title": "17¬† Good Practices in der Datenverarbeitung",
    "section": "",
    "text": "17.1 Herausforderungen in der Arbeit mit neurowissenschaftlichen Daten\nIn der neurowissenschaftlichen Forschung werden zunehmend sehr grosse und komplexe Datens√§tze generiert. Daten aus unterschiedlichen Datenerhebungsverfahren sollen miteinander verkn√ºpft (aggregiert) werden, um neue Erkenntnisse zu gewinnen. Eine sehr h√§ufige Kombination sind beispielsweise Verhaltens- und Bildgebungsdaten, wie es in vielen fMRI-Studien der Fall ist. Das erfordert Kenntnisse der unterschiedlichen Formate und Eigenschaften dieser Daten sowie Programmierkenntnisse um diese Daten m√∂glichst automatisiert vorzuverarbeiten, zu verkn√ºpfen, visualisieren und analysieren.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Good Practices in der Datenverarbeitung</span>"
    ]
  },
  {
    "objectID": "goodpractices_data.html#herausforderungen-in-der-arbeit-mit-neurowissenschaftlichen-daten",
    "href": "goodpractices_data.html#herausforderungen-in-der-arbeit-mit-neurowissenschaftlichen-daten",
    "title": "17¬† Good Practices in der Datenverarbeitung",
    "section": "",
    "text": "Definition Datenmanagement\n\n\n\n\n\n\n\nHands-on: Herausforderungen von neurowissenschaftlichen Daten\n\n\n\nLesen Sie den untenstehenden Abschnitt aus Pierr√© et al. (2024). Besprechen Sie in Gruppen, welche spezifischen Herausforderungen Datenmanagement, -vorverarbeitung und -analyse in den Neurowissenschaften bestehen.\n\n\n\nIncreasing complexity of neuroscience data\nOver the past 20 years, neuroscience research has been radically changed by two major trends in data production and analysis.\nFirst, neuroscience research now routinely generates large datasets of high complexity. Examples include recordings of activity across large populations of neurons, often with high resolution behavioral tracking (Steinmetz et al., 2019; Stringer et al., 2019; Mathis et al., 2018; Siegle et al., 2021; Koch et al., 2022), analyses of neural connectivity at high spatial resolution and across large brain areas (Scheffer et al., 2020; Loomba et al., 2022), and detailed molecular profiling of neural cells (Yao et al., 2023; Langlieb et al., 2023; Braun et al., 2022; Callaway et al., 2021). Such large, multi-modal data sets are essential for solving major questions about brain function (Brose, 2016; Jorgenson et al., 2015; Koch and Jones, 2016).\nSecond, the collection and analysis of such datasets requires interdisciplinary teams, incorporating expertise in systems neuroscience, engineering, molecular biology, data science, and theory. These two trends are reflected in the increasing numbers of authors on scientific publications (Wareham, 2016), and the creation of mechanisms to support team science by the NIH and similar research funding bodies (Cooke and Hilton, 2015; Volkow, 2022; Brose, 2016).\nThere is also an increasing scope of research questions that can be addressed by aggregating ‚Äúopen data‚Äù from multiple studies across independent labs. Funding agencies and publishers have begun to aggressively promote data sharing and open data, with the goals of improving reproducibility and increasing data reuse (Dallmeier-Tiessen et al., 2014; Tenopir et al., 2015; Pasquetto et al., 2017). However, open data may be unusable if scattered in a wide variety of naming conventions and file formats lacking machine-readable metadata.\nBig data and team science necessitate new strategies for how to best organize data, with a key technical challenge being the development of standardized file formats for storing, sharing, and querying datasets. Prominent examples include the Brain Imaging Data Structure (BIDS) for neuroimaging, and Neurodata Without Borders (NWB) for neurophysiology data (Teeters et al., 2015; Gorgolewski et al., 2016; R√ºbel et al., 2022; Holdgraf et al., 2019). The Open Neurophysiology Environment (ONE), best known from adoption by The International Brain Laboratory (The International Brain Laboratory et al., 2020, 2023), has a similar application domain to NWB, but a highly different technical design. (‚Ä¶)\nThese initiatives provide technical tools for storing and accessing data in known formats, but more importantly provide conceptual frameworks with which to standardize data organization and description in an (ideally) universal, interoperable, and machine-readable way. Pierr√© et al. (2024) (Preprint)\n\n\n17.1.1 Datenquellen, Datenformate und Interdisziplinari√§t\nNeurowissenschaftliche Daten von Verhaltensdaten zu Bildgebungsdaten stammen aus unterschiedlichsten Quellen und haben alle spezifische Eigenschaften, die in der Datenverarbeitung ber√ºcksichtigt werden m√ºssen. Das bedeutet, dass sehr unterschiedliche Formate miteinander verkn√ºpft werden m√ºssen f√ºr die Analyse. Bei der Generierung von Daten sind oft auch Personen aus unterschiedlichen Fachrichtungen beteiligt, welche andere Hintergr√ºnde bez√ºglich Datenmanagement haben (z.B. bei fMRI Experimenten Fachpersonen aus den Bereichen Radiologie, Physik, Neurowissenschaften, Psychologie, Medizin, etc.). Auch bei der Analyse sind oft verschiedene Personen beteiligt, die alle darauf angewiesen sind, den Datensatz zu verstehen.\n\n\n17.1.2 Grosse und komplexe Datens√§tze\nNeurowissenschaftliche Datens√§tze sind oft sehr gross (pro Versuchsperson oft mehrere Gigabytes) und f√ºr die Speicherung und das Safety Back-up wird also viel Speicherplatz ben√∂tigt (mehrere Terrabytes). Komplexe Datens√§tze bedeutet, dass eine gute Dokumentation n√∂tig ist, welche Variable welche Bedeutung hat und wo gegebenenfalls √Ñnderungen gemacht wur#den.\n\n\n17.1.3 Umsetzung Open Science\nFalls dabei keine Pers√∂nlichkeitsrechte verletzt werden, sollten Daten m√∂glichst zug√§nglich gemacht werden, um einerseits transparente Resultate zu erm√∂glichen und andererseits kann so ein Datensatz auch von anderen Forschenden f√ºr weitere Fragestellung verwendet werden. Dies ist aber nur m√∂glich, wenn der Datensatz f√ºr Aussenstehende verst√§ndlich abgespeichert wurde.\n\n\n17.1.4 Zahlreiche Verarbeitungsschritte\nVon der Datenerhebung bis zur Datenanalyse werden die Daten oft ausf√ºhrlich vorverarbeitet. Dazu geh√∂ren u.a. folgende Schritte (wobei jeder eigene Fehlerquellen beinhalten kann):\n\nImportieren der Rohdaten\nVer√§ndern des Formats (z.B. .dcm -&gt; .nii in fMRI)\nIdentifikation von Missings\nAusschluss von ung√ºltigen Messungen\nAnonymisierung\nWeglassen nicht ben√∂tigter Datenpunkte\nFehlende Werte erg√§nzen\nDuplizierungen identifizieren und l√∂schen\nMetadaten hinzuf√ºgen\nDatens√§tze zusammenf√ºgen\nSpalten teilen\nVariablen umbenennen\nVariablen normalisieren/standardisieren\nVariablen ver√§ndern (z.B. ms zu sec)\nVariablentypen anpassen\nVariablen recodieren\nNeue Variablen erstellen\nNeuer Datensatz abspeichern\n\n\n\n\n\n\n\nTipp: Datencheck\n\n\n\nBevor mit einem Datensatz gearbeitet wird, empfiehlt es sich den Datensatz anzuschauen und folgendes zu identifizieren:\n\nIn welchem Dateiformat ist der Datensatz gespeichert? z.B. in .csv, .xlsx oder anderen?`\nIn welchem Datenformat ist der Datensatz geordnet? (long oder wide oder mixed?)\nGibt es ein data dictionary mit Erkl√§rungen zu den Variablen?\n\n\n\n\n\n17.1.5 Verschiedene Standards\nEs gibt zahlreiche Bem√ºhungen Datenmanagement in den Neurowissenschaften zu vereinheitlichen. Viele verf√ºgbare Standards und Tools machen die Datenverarbeitung aber nicht nur einfacher. Im n√§chsten Kapitel finden Sie deshalb eine √úbersicht von Ans√§tzen, die uns sinnvoll und allgemein anwendbar erscheinen und sich in unseren Labors bew√§hrt haben.\n xkcd Comic",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Good Practices in der Datenverarbeitung</span>"
    ]
  },
  {
    "objectID": "goodpractices_data.html#good-practices-in-der-datenverarbeitung",
    "href": "goodpractices_data.html#good-practices-in-der-datenverarbeitung",
    "title": "17¬† Good Practices in der Datenverarbeitung",
    "section": "17.2 Good Practices in der Datenverarbeitung",
    "text": "17.2 Good Practices in der Datenverarbeitung\nIm Folgenden wird auf einige wichtige Good Practices in der Datenverarbeitung eingegangen. Wichtig sind hier die Reproduzierbarkeit der Datenverarbeitungs- und Datenanalysepipelines sowie die Sicherstellung der Datenqualit√§t.\n\n17.2.1 Reproduzierbarkeit\nDie Replikationskrise hat in der Psychologie, aber auch in den kognitiven Neurowissenschaften ein Umdenken ausgel√∂st. Mit dem Ziel nachhaltigere Forschungsergebnisse zu erreichen sind verschiedene Begriffe wie Reproduzierbarkeit und Replizierbarkeit zu wichtigen Schlagworten geworden. Die Begrifflichkeiten werden verwirrenderweise aber oft unterschiedlich definiert und verwendet (Plesser (2018)).\n\n\n\n\n\n\n\n\n\n\nReplizierbarkeit (replicability) bedeutet, dass ein Experiment von einer anderen Forschungsgruppe mit einer neuen Stichprobe durchgef√ºhrt werden kann, und √§hnliche oder dieselben Resultate hervorbringt, wie die Originalstudie. Wird eine Studie mehrmals repliziert, steigt die Wahrscheinlichkeit, dass kein Zufallsbefund vorliegt.\n\nReplicability refers to the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected. Cacioppo et al. (2015)\n\nReproduzierbarkeit (reproducibility) h√§ngt eng mit der Replizierbarkeit zusammen. Der Begriff wird teilweise sehr allgemein verwendet, und bedeutet so dass Forschungsergebnisse wiederholt gefunden werden. Reproduzierbarkeit im engeren Sinn hingegen bezieht sich darauf, ob die durchgef√ºhrte Analyse wiederholt werden kann. Die Reproduzierbarkeit ist somit hoch, wenn Forschende die Daten und Datenanalyseskripts bereitstellen und andere Forschende damit dieselben Analysen durchf√ºhren k√∂nnen und zu gleichen Resultaten kommen.\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator. That is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results‚Ä¶. Reproducibility is a minimum necessary condition for a finding to be believable and informative. Cacioppo et al. (2015)\n\nUm die Begriffe zusammenzufassen schlugen Goodman, Fanelli, and Ionnidis (2016) vor von\n\nReproduzierbarkeit der Methoden (Daten und Prozesse k√∂nnen exakt wiederholt werden)\nReproduzierbarkeit der Resultate (andere Studien kommen auf dieselben Resultate) und\nReproduzierbarkeit der wissenschaftlichen Schlussfolgerung (bei Repetition der Analyse oder der Experimente werden dieselben Schl√ºsse gezogen)\n\nzu sprechen. Die Reproduzierbarkeit von Resultaten und Schlussfolgerungen ist hier nicht klar abgrenzbar vom Begriff der Replizierbarkeit. Grunds√§tzlich besteht das Ziel, dass in der Forschung m√∂glichst viel Evidenz f√ºr eine Schlussfolgerung gesammelt werden kann. Dies gelingt, wenn die Prozesse transparent, fehlerfrei und wiederholbar sind.\n\n\n17.2.2 Hindernisse bei der Reproduzierbarkeit\nIn diesem Kurs besch√§ftigen wir uns vor allem mit der Reproduzierbarkeit der Methoden als Grundlage f√ºr solide Erkenntnisgewinne. Reproduzierbarkeit kann laut Nosek et al. (2022) vor allem aus zwei Gr√ºnden nicht gegeben sein: Weil die Daten/Skripte nicht zur Verf√ºgung stehen, oder weil diese Fehler enthalten:\n\nIn principle, all reported evidence should be reproducible. If someone applies the same analysis to the same data, the same result should occur. Reproducibility tests can fail for two reasons. A process reproducibility failure occurs when the original analysis cannot be repeated because of the unavailability of data, code, information needed to recreate the code, or necessary software or tools. An outcome reproducibility failure occurs when the reanalysis obtains a different result than the one reported originally. This can occur because of an error in either the original or the reproduction study. Nosek et al. (2022)\n\nF√ºhrt die Reproduktion nicht zum selben Resultat, l√∂st das Zweifel am Forschungsergebnis aus. Wenn die Reproduzierbarkeit am Prozess scheitert, etwa weil die Daten nicht vorhanden sind, kann kein Schluss gezogen werden, ob die Resultate stimmen.\n\nAchieving reproducibility is a basic foundation of credibility, and yet many efforts to test reproducibility reveal success rates below 100%. ‚Ä¶ Whereas an outcome reproducibility failure suggests that the original result may be wrong, a process reproducibility failure merely indicates that the original result cannot be verified. Either reason challenges credibility and increases uncertainty about the value of investing additional resources to replicate or extend the findings (Nuijten et al.¬†2018). Sharing data and code reduces process reproducibility failures (Kidwell et al.¬†2016), which can reveal more outcome reproducibility failures (Hardwicke et al.¬†2018, 2021; Wicherts et al.¬†2011). Nosek et al. (2022)\n\nDas Teilen von Daten und Datenverarbeitungsskripten erh√∂ht demnach die Wahrscheinlichkeit, dass m√∂gliche Fehler im Prozess gefunden werden, da auch andere Forschende die Daten/Skripts verwenden k√∂nnen. Das ist vorerst unangenehm, geh√∂rt aber zum wissenschaftlichen Prozess dazu. Die Normalisierung einer Fehlerkultur in diesem Bereich w√ºrde indirekt auch die Replizierbarkeit von Ergebnissen erh√∂hen.\n\nNeuroimaging experiments result in complicated data that can be arranged in many different ways. So far there is no consensus how to organize and share data obtained in neuroimaging experiments. Even two researchers working in the same lab can opt to arrange their data in a different way. Lack of consensus (or a standard) leads to misunderstandings and time wasted on rearranging data or rewriting scripts expecting certain structure. BIDS Website (2024)\n\n\n\n17.2.3 Tools f√ºr Reproduzierbarkeit\nF√ºr reproduzierbare Forschung gibt es inzwischen viele gute Tools.\n\nOSF: Website der Open Science Foundation\nEine kostenfreie und unkomplizierte M√∂glichkeit Daten und Skripts zu teilen, und diese in Projekten abzulegen. Es l√§sst sich daf√ºr sogar ein doi erstellen. Auch Formulare f√ºr eine Pr√§registration sind hier zu finden.\n\n\nFAIR Guiding Principles\nBeim Ver√∂ffentlichen von wissenschaftlichen Artikeln ist es empfohlen, die Daten (falls Anonymisierung m√∂glich) sowie die Analyse-Skripte mitzuver√∂ffentlichen.\nF√ºr Datens√§tze gelten die FAIR Guiding Principles (Wilkinson et al. (2016)):\n\nF indability: Es ist klar unter welchen Umst√§nden und wie die Daten zug√§nglich sind\nA ccessibility: Daten sind zug√§nglich bzw. es ist klar wo sie zu finden w√§ren\nI nteroperability: Verwendbare Datenformate/strukturen\nR eusability: gute Beschreibung des Datensatzes/der enthaltenen Variablen\n\n\nHier finden Sie weitere Informationen zu FAIR.\n\n\n\nBIDS: Brain Imaging Data Structure\nF√ºr Neuroimaging-Daten gibt es beispielsweise vorgegebene Konventionen, wie ein Datensatz und die Verarbeitungsskripts abgespeichert werden. Ein Beispiel daf√ºr ist Brain Imaging Data Structure (BIDS). So k√∂nnen Datens√§tze mit einer f√ºr alle verst√§ndlichen Struktur ver√∂ffentlicht und geteilt werden. Gorgolewski et al. (2016)\n\nHier finden Sie weitere Informationen zu BIDS.\n\nHier sehen Sie ein Beispiel, wie ein fMRI Datensatz in BIDS Struktur umgewandelt wird:\n Gorgolewski et al. (2016)\n\n\n\n17.2.4 Coding: Best practices\nF√ºr das Ver√∂ffentlichen von Analyseskripts eignen sich Formate wie RMarkdown in R, oder LiveScripts in MATLAB aber auch .r-Skripte sehr gut. Beim Teilen von Code erh√∂ht sich die Reproduzierbarkeit, wenn dieser verst√§ndlich strukturiert und kommentiert ist.\nWichtig ist hier:\n\nDas Verwenden relativer Pfade (data/raw_data.csv statt C:/Users/IhrName/Desktop/Projekt/Versuch1/finaleDaten/raw_data.csv)\nKonsequentes L√∂schen ‚Äúalter‚Äù Variablen sowie Testen, ob der Code in sich l√§uft\nVersionskontrolle: Entweder konsistentes Umbenennen oder mittels Github/Gitlab o.√§., Erstellen von Changelogs\nVor dem Ver√∂ffentlichen, lohnt es sich jemanden den Code ausf√ºhren lassen. So zeigt sich wo noch unklare Stellen sind, die Kommentare ben√∂tigen.\n\nBeim Kommentieren von Code sollte folgendes beachtet werden:\n\nKommentare sollten geschrieben werden, wenn der Code erstellt wird und laufend √ºberarbeitet werden. Oft wird es sonst nicht nachgeholt.\nWenn man nicht genau kommentieren kann, was man im Code macht, dann ist evtl. der Code unklar, oder man versteht ihn noch nicht. Vielleicht kann man Variablennamen vereinfachen/pr√§zisieren und es braucht weniger Kommentare?\nWenn Code von anderen kopiert wird, sollte die Quelle angegeben werden.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Good Practices in der Datenverarbeitung</span>"
    ]
  },
  {
    "objectID": "goodpractices_data.html#datenmanagement",
    "href": "goodpractices_data.html#datenmanagement",
    "title": "17¬† Good Practices in der Datenverarbeitung",
    "section": "17.3 Datenmanagement",
    "text": "17.3 Datenmanagement\nIn diesem Kapitel wird auf die Sicherstellung der Datenqualit√§t, sowie die Wichtigkeit von Data collection plans und Data dictionaries eingegangen.\n\n17.3.1 Datenqualit√§t\nDie folgenden sieben Indikatoren f√ºr gute Datenqualit√§t wurden von C. Lewis (2024) zusammengefasst und sind hier zu finden.\n\n1. Analysierbarkeit\nDaten sollten in einem Format gespeichert werden in welchem sie analysiert werden sollen.\n\nDie Variablennamen stehen (nur!) in der ersten Zeile.\nDie restlichen Daten sind Werte in Zellen. Diese Werte sind analysierbar und Informationen sind explizit enthalten (keine leeren Felder, keine Farben als Information, nur 1 Information pro Variable).\n\n\n\n2. Interpretierbarkeit\n\nVariablennamen maschinenlesbar (kommen nur einmal vor, keine L√ºcken/spezielle Sonderzeichen/Farben, beginnen nicht mit einer Nummer, nicht zu lange)\nVariablennamen sind menschenlesbar (klare Bedeutung, konsistent formattiert, logisch geordnet)\nDatens√§tze sind in einem nicht-propriet√§ren Format abgespeichert (z.B. .csv nicht .xlsx oder .sav)\n\n\n\n3. Vollst√§ndigkeit\n\nKeine Missings, keine Duplikationen\nEnth√§lt alle erhobenen Variablen\nErkl√§rung f√ºr alle Variablen in zus√§tzlichem File (z.B. in einem data dictionary)\n\n\n\n4. Validit√§t\n\nVariablen entsprechen den geplanten Inhalten, d.h. Variablentypen und -werte stimmen mit Daten √ºberein (z.B. numerisch/kategorial, range: 1-5)\nMissings sind unverwechselbar angegeben (z.B. nicht -99, sondern NA)\n\n\n\n5. Genauigkeit\n\nDaten sollten in sich √ºbereinstimmen\nDaten sollten doppelt kontrolliert werden, wenn sie eingegeben werden\n\n\n\n6. Konsistenz\n\nVariablennamen sollten konsistent gew√§hlt werden\nInnerhalb wie auch zwischen den Variablen sollten Werte konsistent kodiert und formattiert sein\n\n\n\n7. Anonymisiert\n\nAlle Identifikationsmerkmale, sowohl direkte (Name, Adresse, E.Mail oder IP-Adresse, etc.) sowie indirekte (Alter, Geschlecht, Geburtsdatum, etc.) sollten so anonymisiert/kodiert sein, dass keine R√ºckschl√ºsse auf Personen m√∂glich sind\nBesondere Vorsicht bei: Offenen Fragen mit w√∂rtlichen Antworten, extremen Werten, kleinen Stichproben/kleinen Zellgr√∂ssen (&lt;3), Diagnosen, sensiblen Studienthemen\n\nEs empfiehlt sich vor der definitiven Abspeicherung oder gar Ver√∂ffentlichung des Datensatzes, diese Punkte durchzuarbeiten und zu kontrollieren.\n\n\n\n17.3.2 Data collection plan\nDie Datenqualit√§t kann erh√∂ht werden, indem die obenstehenden Punkte schon bei der Planung der Datenerhebung beachtet und einbezogen werden. Wenn die Daten schon so eingegeben werden, werden die darauffolgenden Data Cleaning Schritte verk√ºrzt und weniger Fehler passieren. Die Dateneingabe und -analyse sollte vor der Datenerhebung getestet und w√§hrenddessen immer wieder kontrolliert werden.\n\n\n17.3.3 Data dictionaries\nEin data dictionary ist eine Sammlung von Metadaten die beschreibt, welche Variablen ein Datensatz enth√§lt und wie die Werte dieser Variable formattiert sind.\nWichtige Inhalte f√ºr die Anwendung in den Neurowissenschaftlichen Forschung sind z.B. Name, Definition, Typ, Wertebereich (values), angewandte Transformationen, Geltungsbereiche (universe) und Format fehlender Angaben (skip logic).\nBeispiel Data Dictionary\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariable\nlabel\ntype\nvalues\nsource\ntransformations\nuniverse\nskip_logic\n\n\n\n\nparticipant identification\nid\ncharacter, factor\n‚Äúsub-001‚Äù - ‚Äúsub-100‚Äù\nraw files\nanonymized variable ‚Äúparticipant‚Äù\nall\nNA\n\n\nparticipant age\nage\ninteger\n18 - 55\nraw files\n\nall\nNA\n\n\nexperimental block\nblock\ninteger\n1, 2\nraw files\n\nall\nNA\n\n\n\n\n\n\n\n\n\nHands-on: Erstellen Data Dictionary\n\n\n\nErstellen Sie in kleinen Gruppen f√ºr eines unserer beiden Experimente ein Data Dictionary. Verwenden Sie hierf√ºr die in den oben abgebildeten Beispielstabelle vorhandenen Spalten.\nTipp: Sie k√∂nnen die Tabelle auch ganz simpel in RMarkdown erstellen in dem Sie die Tabelle als Text (nicht im Codechunk) erstellen. Wie das funktioniert k√∂nnen Sie hier nachlesen.\n\n\n\nAusf√ºhrlichere Informationen √ºber das Erstellen von data dictionaries finden Sie z.B. hier und hier.\n\nInformationen zu Datentypen finden Sie hier oder in der untenstehenden Tabelle\nDatentypen\n\n\n\n\n\n\n\n\nDatentyp\nBeschrieb\nBeispiel\n\n\n\n\ninteger\nGanzzahliger Wert\n1, 2, 3, 29\n\n\ndouble, float\nZahl mit Kommastellen\n1.234, 89.3, 1.0\n\n\ncharacter, factor\nText oder Kategorie (nicht numerisch interpretiert)\nspeed, 0\n\n\nstring\nText oder Kategorie in ‚Äú‚Äù oder ‚Äô‚Äô\n‚Äúsub-001‚Äù\n\n\ndatetime\nDatum, Zeitpunkt\n2024-04-13, 21.12.23, 00:45:45\n\n\nboolean\nEiner von 2 m√∂glichen Werten\nFALSE, 0\n\n\n\n\n\n\n\nCacioppo, J. T., R. M. Kaplan, J. A. Krosnick, J. L. Olds, and H. Dean. 2015. ‚ÄúSocial, Behavioral, and Economic Sciences Perspectives on Robust and Reliable Science.‚Äù Report of the Subcommittee on Replicability in Science Advisory Committee to the National Science Foundation Directorate for Social, Behavioral, and Economic Sciences.\n\n\nGoodman, Steven N., Daniele Fanelli, and John P. A. Ionnidis. 2016. ‚ÄúWhat Does Research Reproducibility Mean?‚Äù Science Translational Medicine 341. https://doi.org/10.1126/scitranslmed.aaf5027.\n\n\nGorgolewski, Krzysztof J., Tibor Auer, Vince D. Calhoun, R. Cameron Craddock, Samir Das, Eugene P. Duff, Guillaume Flandin, et al. 2016. ‚ÄúThe Brain Imaging Data Structure, a Format for Organizing and Describing Outputs of Neuroimaging Experiments.‚Äù Scientific Data 3 (1): 160044. https://doi.org/10.1038/sdata.2016.44.\n\n\nNosek, Brian A, Tom E Hardwicke, Hannah Moshontz, Aur√©lien Allard, Katherine S Corker, Anna Dreber, Fiona Fidler, et al. 2022. ‚ÄúReplicability, Robustness, and Reproducibility in Psychological Science.‚Äù Annual Review of Psychology 73: 719‚Äì48. https://doi.org/10.1146/annurev-psych-020821-114157.\n\n\nPierr√©, Andrea, Tuan Pham, Jonah Pearl, Sandeep Robert Datta, Jason T. Ritt, and Alexander Fleischmann. 2024. ‚ÄúA Perspective on Neuroscience Data Standardization with Neurodata Without Borders.‚Äù arXiv. http://arxiv.org/abs/2310.04317.\n\n\nPlesser, Hans E. 2018. ‚ÄúReproducibility Vs. Replicability: A Brief History of a Confused Terminology.‚Äù Frontiers in Neuroinformatics 11 (January): 76. https://doi.org/10.3389/fninf.2017.00076.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. ‚ÄúThe FAIR Guiding Principles for Scientific Data Management and Stewardship.‚Äù Scientific Data 3 (1): 160018. https://doi.org/10.1038/sdata.2016.18.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Good Practices in der Datenverarbeitung</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html",
    "href": "rmarkdown.html",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "",
    "text": "18.1 RStudio Projects\nRStudio Projekte erm√∂glichen vereinfachtes Arbeiten mit R, da alle Dateien, die in diesem Projektordner gespeichert sind, direkt verf√ºgbar sind. So kann die aktuelle R Session abgespeichert werden und beim n√§chsten √ñffnen kann dort weitergearbeitet werden wo man aufgeh√∂rt hat. Projekte erm√∂glichen somit ein stabiles working directory f√ºr ein Datenanalyse-Projekt.\nEs empfiehlt sich bei RProjekten eine Einstellungs√§nderung (Tools&gt; Project Options...) vorzunehmen, so dass die aktuell gespeicherten Variablen bei jedem Schliessen vom Projekt gel√∂scht werden. Dies verhindert, dass der aktuelle Code nur aufgrund fr√ºherer Speicherung l√§uft.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#rstudio-projects",
    "href": "rmarkdown.html#rstudio-projects",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "",
    "text": "Hands-on: Erstellen eines RStudio Projects\n\n\n\n\n√ñffnen Sie RStudio.\nErstellen Sie ein neues RStudio-Project\n\nKlicken Sie daf√ºr auf File &gt; New Project\nBenennen Sie das Project neurosci_complab_rmarkdown und speichern Sie es an einem sinnvollen Ort auf Ihrem Computer.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#r-markdown",
    "href": "rmarkdown.html#r-markdown",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.2 R Markdown",
    "text": "18.2 R Markdown\nR Markdown ist eine simple Markup-Sprache, die es erm√∂glicht reproduzierbare Data Reports zu erstellen. R Markdown ist praktisch, weil Text und Code gleichzeitig verwendet werden kann und der Output des Codes angezeigt wird. Text kann verwendet werden, ohne dass vor jeder Zeile ein # zum Auskommentieren gesetzt werden. Zudem kann Text formatiert werden, also z.B. dick oder kursiv dargestellt werden oder Auflistungen beinhalten.\nDas Skript der R Markdown Files wird geknittet und so - je nach Wahl - zu einem HTML, PDF oder Word-Dokument zusammengef√ºgt. R Markdown kann also beispielsweise eine Text-Beschreibung, Code zum Erstellen einer Grafik und auch die erstellte Grafik in einem Dokument kombinieren.\n\nMit R Markdown k√∂nnen auch Pr√§sentationen, Webseiten, B√ºcher, Lebensl√§ufe, Artikel oder Arbeiten erstellt werden. Hier finden Sie eine Galerie. Die Kurswebsite wurde ebenfalls in R erstellt.\n\nDas working memory innerhalb eines R Markdown Files ist der Speicherort des Files. Von dort aus k√∂nnen somit relative Pfade angegeben werden. Das hat den Vorteil, dass andere Benutzer denselben Projekt-Ordner auf Ihrem Computer mit unver√§nderten Pfaden verwenden k√∂nnen.\n\nWeitere Infos zu Pfaden in R Markdown.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#r-markdown-file-erstellen-und-ausf√ºhren",
    "href": "rmarkdown.html#r-markdown-file-erstellen-und-ausf√ºhren",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.3 R Markdown File erstellen und ausf√ºhren",
    "text": "18.3 R Markdown File erstellen und ausf√ºhren\n\n\n\n\n\n\nHands-on: R Markdown File in einem Projekt erstellen\n\n\n\n\nErstellen Sie ein neues .Rmd-File (File &gt; New File &gt; R Markdown).\nGeben Sie einen Titel und Ihren Namen ein und w√§hlen Sie HTML als Output-Format.\nSpeichern Sie dieses Dokument unter dem Namen rmarkdown_exampleab.\n\nWelches Format (Endung) hat das abgespeicherte R Markdown Skript nun in Ihrem Ordner?\n\n\n\nWeiterf√ºhrende Informationen:\nüëâ Einf√ºhrung in die Verwendung von R/RStudio/Notebooks im Rahmen des Psychologie Studiums von Andrew Ellis und Boris Mayer Einf√ºhrung in R\nüëâ Sehr kompakte, praxisnahe Einf√ºhrung in R Markdown von Danielle Navarro (Slidedeck in englisch) Einf√ºhrung in R Markdown",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#knitten",
    "href": "rmarkdown.html#knitten",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.4 Knitten",
    "text": "18.4 Knitten\nMit Knit wird das R Markdown Skript ausgef√ºhrt und eine zus√§tzliche Datei wird erstellt, z.B. ein html-File.\n\n\n\n\n\n\nHands-on: Knitten\n\n\n\n\n\nF√ºhren Sie das File mit Knit aus und vergleichen Sie das R Markdown Skript mit dem Output den Sie erhalten haben. Was f√§llt Ihnen auf?\n\nWas ist nicht mehr zu sehen?\nWas ist zus√§tzlich zu sehen?\nWas hat sich im Projekt-Ordner ver√§ndert?\n\n\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nIm geknitteten Dokument ist der YAML-header nicht mehr zu sehen. Ebenfalls sieht man die ‚ÄúUmrandungen‚Äù, also die r Einfassungen der Code-Snippets, die Markdown-Befehle zum Einf√ºgen von Grafiken, Mathematischen Formulierungen, etc. nicht mehr.\nNeu sieht man den Output des Codes. Je nach Einstellungen Code und Fehler-/Warnmeldungen und gerenderte Inhalte (Bilder, Mathematische Formeln, etc.).\nIm Projektordner wird ein .html-File erstellt.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#yaml-header",
    "href": "rmarkdown.html#yaml-header",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.5 YAML header",
    "text": "18.5 YAML header\nAm Anfang des R Markdown Skripts befindet sich der YAML header. Hier werden Informationen zu Titel, Autor:Innen, Datum, Outputformat, Literaturverzeichnis und Layout festgelegt.\n\nYAML: Yet Another Markdown Language\n\nDas Layout kann unter themege√§ndert werden. Das kann beispielsweise wie folgt aussehen:\noutput:\n  html_document:\n    theme: cosmo\nAchtung: Die Einr√ºckungen m√ºssen genau stimmen! Hier wurde das theme namens cosmo ausgew√§hlt. M√∂gliche andere themessind z.B. default, cerulean, journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, yeti.\n\n\n\n\n\n\nHands-on: Namen und Einstellungen anpassen\n\n\n\n\n\n\nGeben Sie dem Dokument einen neuen Titel z.B. R Markdown Einf√ºhrung\n√Ñndern Sie das Layout so, dass es Ihnen gef√§llt.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#text-erstellen-in-r-markdown",
    "href": "rmarkdown.html#text-erstellen-in-r-markdown",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.6 Text erstellen in R Markdown",
    "text": "18.6 Text erstellen in R Markdown\nText kann in R Markdown Files nicht nur geschrieben, sondern auch relativ simpel formatiert werden.\nüëâ Hier k√∂nnen Sie das Cheatsheet herunterladen. Auf der rechten Seite finden Sie die Informationen f√ºr die Textformatierung.\nEs empfiehlt sich das Skript anfangs h√§ufig zu knitten, so findet man den Fehler schneller, weil man noch weiss, was man als letztes ver√§ndert hat. Code kann aber auch einfach innerhalb der Code-Chunks √ºberpr√ºft werden.\n\n\n\n\n\n\nHands-on: Texte, Formeln und Bilder in R Markdown einf√ºgen\n\n\n\n\n\n\nL√∂schen Sie alles bis auf den YAML-Header\nSchreiben Sie im Textbereich eine √úberschrift f√ºr ein Kapitel, ein Unterkapitel und normalen Text.\nSchreiben Sie im Text etwas kursiv und etwas fett.\nErstellen Sie im Textbereich eine Liste mit 3 Punkten.\nSchreiben Sie alpha innerhalb von $, was passiert?\nF√ºgen Sie die untenstehende Formel in den Text ein. Verwenden Sie daf√ºr zwei Dollarzeichen am Anfang und am Ende. Was passiert?\n\n\\[\na^2 + b^2 = c^2\n\\]\n\nF√ºgen Sie einen Link ein, knitten Sie das File und schauen Sie ob der Link funktioniert. K√∂nnen Sie einen Link nur mit einem unterstrichenen Text anzeigen, so dass die Linkadresse nicht sichtbar ist?\nF√ºgen Sie ein Bild ein. Speichern Sie dieses Bild zuerst in einem Ordner namens img im Projektordner.\n\n\n\n\n\nHier finden Sie weiterf√ºhrende Hilfe zum Einf√ºgen von Mathnotationen.\n\nMathematics in RMarkdown\nRMarkdown: The definitive Guide",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "rmarkdown.html#code-erstellen-in-r-markdown",
    "href": "rmarkdown.html#code-erstellen-in-r-markdown",
    "title": "18¬† RStudio Projects und RMarkdown",
    "section": "18.7 Code erstellen in R Markdown",
    "text": "18.7 Code erstellen in R Markdown\nCode muss jeweils in einem Code-Chunk eingef√ºgt werden. Ein Code-Chunk kann unter Code &gt; Insert Chunk eingef√ºgt werden oder mit dem K√ºrzel Ctrl+Alt+ I.\nCode-Chunks werden mit ``` begonnen und beendet. In den geschweiften Klammern steht r, das bedeutet dass der Code in R geschrieben ist. In dieser Klammer kann dem Code-Chunk einen Namen gegeben und bestimmt werden, ob der Code ausgef√ºhrt und z.B. nur angezeigt werden soll, sowie ob der Output des Codes angezeigt werden soll.\nMit dem gr√ºnen Pfeil kann der Code-Chunk einzeln ausgef√ºhrt werden. Aber auch einzelne Zeilen k√∂nnen ausgef√ºhrt werden, genau so wie in einem .R- Skript.\n\n\n\n\n\n\nHands-on: Code in R Markdown einf√ºgen\n\n\n\n\n\n\nErstellen Sie einen Code-Chunk, der ausgef√ºhrt, aber nicht angezeigt wird. Erstellen Sie eine Variable mit dem Namen numbers, die 10 Zahlen enth√§lt.\nErstellen Sie ein Code-Chunk, der ausgef√ºhrt wird und dessen Output angezeigt wird. Berechnen Sie in diesem Chunk den Mittelwert und die Standardabweichung von numbers.\nErstellen Sie einen Plot mit plot(numbers).\nKnitten Sie das File, um zu √ºberpr√ºfen, ob alles funktioniert\n\nüëâ Schauen Sie f√ºr Hilfe nochmals im Cheatsheet nach oder dr√ºcken Sie auf das Zahnr√§dchen-Symbol beim Code-Chunk.\nF√ºr Fortgeschrittene:\n\nTesten Sie, ob Sie Ihr File auch zu einem PDF knitten k√∂nnen.\nErstellen Sie eine Tabelle\nErstellen Sie einen Glossar\nErstellen Sie ein Dokument mit Reitern oben (z.B. Data, Preprocessing, Analysis, Conclusions)\nF√ºgen Sie interaktive Elemente ein.",
    "crumbs": [
      "Open Science",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>RStudio Projects und RMarkdown</span>"
    ]
  },
  {
    "objectID": "intro_eeg.html",
    "href": "intro_eeg.html",
    "title": "19¬† Einf√ºhrung EEG",
    "section": "",
    "text": "19.1 Was ist EEG?\nElektroenzephalographie (EEG) ist eine nicht-invasive Methode zur Messung elektrischer Aktivit√§t im Gehirn. Dabei werden Elektroden auf der Kopfhaut angebracht, um Spannungs√§nderungen zu erfassen, die durch neuronale Aktivit√§t entstehen.",
    "crumbs": [
      "EEG",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Einf√ºhrung EEG</span>"
    ]
  },
  {
    "objectID": "intro_eeg.html#was-ist-eeg",
    "href": "intro_eeg.html#was-ist-eeg",
    "title": "19¬† Einf√ºhrung EEG",
    "section": "",
    "text": "19.1.1 Was misst EEG?\nEEG misst vor allem die summierten postsynaptischen Potentiale von gro√üen Gruppen von Nervenzellen, insbesondere den pyramidalen Neuronen im Kortex. Diese Neuronen liegen senkrecht zur Kopfhaut und erzeugen elektrische Felder, wenn sie aktiviert werden. Die gemessenen Signale stammen nicht von einzelnen Aktionspotentialen, sondern von der koordinierten Aktivit√§t vieler Neuronen.\n\n\n19.1.2 Wichtige Eigenschaften des EEG\n\nHohe zeitliche Aufl√∂sung im Millisekundenbereich\nNicht-invasiv und relativ kosteng√ºnstig\nMisst elektrische Aktivit√§t direkt\nSensibel f√ºr Prozesse im Kortex, aber weniger f√ºr tieferliegende Strukturen\nInverse Problem: die Schwierigkeit, aus den EEG-Signalen auf der Kopfhaut eindeutig auf die zugrunde liegenden Quellen im Gehirn zu schlie√üen.",
    "crumbs": [
      "EEG",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Einf√ºhrung EEG</span>"
    ]
  },
  {
    "objectID": "intro_eeg.html#grundlegende-schritte-der-eeg-analyse-bis-zu-erps",
    "href": "intro_eeg.html#grundlegende-schritte-der-eeg-analyse-bis-zu-erps",
    "title": "19¬† Einf√ºhrung EEG",
    "section": "19.2 Grundlegende Schritte der EEG-Analyse (bis zu ERPs)",
    "text": "19.2 Grundlegende Schritte der EEG-Analyse (bis zu ERPs)\n\n19.2.1 Was sind ERPs?\n\n\n\n\n\nsource: Beres, A.M. Time is of the Essence: A Review of Electroencephalography (EEG) and Event-Related Brain Potentials (ERPs) in Language Research. Appl Psychophysiol Biofeedback 42, 247‚Äì255 (2017). https://doi.org/10.1007/s10484-017-9371-3\nEvent-related potentials (ERPs) sind zeitlich mit einem bestimmten Event verkn√ºpfte Ver√§nderungen im EEG-Signal, die durch Mittelung √ºber viele √§hnliche Ereignisse gewonnen werden. Sie zeigen typische Wellenformen, die R√ºckschl√ºsse auf Wahrnehmung, Aufmerksamkeit oder Entscheidungsprozesse erlauben.\n\n\n19.2.2 ERP Analyse\nDie Analyse von EEG-Daten erfolgt in mehreren Schritten, um aus dem Rohsignal Event-Related Potentials (ERPs) zu extrahieren. Hier ein √úberblick √ºber die wichtigsten Analysephasen:\n\n1. Datenimport\n\nLaden der Rohdaten aus dem EEG-Aufzeichnungssystem\nEnth√§lt Informationen zu Kan√§len, Sampling-Rate und Markern (Events)\n\n\n\n2. Vorverarbeitung (Preprocessing)\n\nFilterung: Entfernen von Rauschen, z.‚ÄØB. tieffrequente Drift (High-Pass) oder Muskelartefakte (Low-Pass)\nRe-Referenzierung: Wahl einer gemeinsamen Referenz (z.‚ÄØB. Durchschnitt aller Elektroden)\nArtefaktentfernung: Ausschluss oder Korrektur von St√∂rungen wie Augenbewegungen oder Blinzeln (z.‚ÄØB. mithilfe von ICA)\n\n\n\n3. Event-Markierung\n\nIdentifikation relevanter Zeitpunkte im EEG (z.‚ÄØB. Reizbeginn, Tastendruck)\nDiese Marker definieren die Zeitfenster f√ºr weitere Analysen\n\n\n\n\n\n\nsource: Mart√≠nez Beltr√°n, E.T., Quiles P√©rez, M., L√≥pez Bernal, S. et al. Noise-based cyberattacks generating fake P300 waves in brain‚Äìcomputer interfaces. Cluster Comput 25, 33‚Äì48 (2022). https://doi.org/10.1007/s10586-021-03326-z\n\n\n4. Epochierung\n\nUnterteilung des kontinuierlichen EEG in kurze Zeitabschnitte (Epochen) rund um das Event (z.‚ÄØB. -200 bis +800‚ÄØms)\nJede Epoche repr√§sentiert die Reaktion auf ein einzelnes Event\n\n\n\n5. ERP-Berechnung\n\nMitteln der Epochen √ºber viele Trials pro Bedingung\nDas resultierende ERP zeigt zeitlich stabile, wiederholbare Hirnreaktionen auf spezifische Events\n\n\n\n6. Visualisierung und Interpretation\n\nDarstellung der ERPs als Wellenformen (z.‚ÄØB. √ºber die Zeit an bestimmten Elektroden)\nIdentifikation typischer Komponenten wie P1, N1, P300 usw.\nVergleich von Bedingungen oder Gruppen mit statistischen Tests",
    "crumbs": [
      "EEG",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Einf√ºhrung EEG</span>"
    ]
  },
  {
    "objectID": "modeling.html",
    "href": "modeling.html",
    "title": "20¬† Einf√ºhrung",
    "section": "",
    "text": "20.1 Warum braucht es Modelle?\nNeurowissenschaftliche Daten werden selten nur durch einen Faktor beeinflusst. Im Gegenteil: Meist sind sehr viele verschiedene Einflussfaktoren beteiligt, und sobald diese auch noch miteinander verkn√ºpft sind, kommen wir Menschen kognitiv sehr schnell an unsere Grenzen. Ab einer bestimmten Komplexit√§t2 k√∂nnen wir nicht mehr anhand simpler Deskriptivstatistik verstehen, welcher Prozess die Daten generiert hat.\nDeshalb macht es Sinn sich Gedanken √ºber den datengenerierenden Prozess zu machen und diesen zu modellieren. Ein Modell ist eine auf das wesentliche reduzierte Erkl√§rung f√ºr einen Prozess. Ein passendes Modell erm√∂glicht es uns Daten zusammenzufassen, Abl√§ufe zu verstehen, zuk√ºnftige Daten vorherzusagen und idealerweise sogar die Erkl√§rung eines Prozesses. Wenn Sie den darunterliegenden datengenerierenden Prozess jedoch kennen, k√∂nnen Sie Daten erkl√§ren und auch zuk√ºnftige Zust√§nde vorhersagen.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "modeling.html#warum-braucht-es-modelle",
    "href": "modeling.html#warum-braucht-es-modelle",
    "title": "20¬† Einf√ºhrung",
    "section": "",
    "text": "20.1.1 Game of Life\nEin gutes Beispiel daf√ºr ist das Game of Life. Das Game of Life ist ein von Mathematiker John Horton Conway 1970 entworfenes Spiel bzw. Vorgehen. Hierbei besteht ein Raster mit inaktiven (weissen) sowie aktiven (schwarzen) Zellen. Die Zellinhalte entwickeln sich nach festgelegten, einfachen Regeln.\n\nEin anderes Beispiel daf√ºr, dass wir intuitiv schnell falsch liegen, ist der Collider Bias3\n\n\nhttps://playgameoflife.com/\n\n\n\n\n\n\nHands-on: Whats going on in the game of life?\n\n\n\nSchauen Sie sich die Entwicklung der Punkte an. Ihre Aufgabe ist es den Prozess, der den Daten zugrundeliegt, zu beschreiben und erkl√§ren:\n\nWie gehen Sie vor um den zugrundeliegenden Prozess zu untersuchen?\nWie k√∂nnen Sie Deskriptivstatistik und Inferenzstatistik anwenden, die Sie im Studium bisher gelernt haben?\nEntdecken Sie wiederkehrende Muster?\nWelche Regeln k√∂nnen Sie erkennen?\nK√∂nnen Sie, wenn Sie den Prozess anhalten, den n√§chsten Zustand vorhersagen?\n\n\n\nWir k√∂nnten also versuchen oben genannte Vorgehensweisen anzuwenden, um den Prozess ‚Äúhinter‚Äù dem Game of Life zu verstehen:\nZuerst beobachten wir inaktive und aktive Zellen (Beobachtungsstudien) und in einem zweiten Schritt untersuchen wir die Zellen, indem wir systematisch in das Geschehen eingreifen (Experiment) in dem wir zum Start gewisse Zellen aktivieren oder deaktivieren.\nWir k√∂nnen versuchen aus den Daten Erkenntnisse zu gewinnen, in dem wir beispielsweise:\n\nDaten deskriptiv beschreiben: Schwarze Felder haben einen Anteil von 20%, weisse Felder einen Anteil von 80%.\nVergleichen verschiedener Gruppen/Bedingungen: Es gibt signifikant mehr weisse als schwarze Felder.\nZusammenh√§nge von Variablen berechnen: Je weiter unten ein Feld liegt, desto eher ist es schwarz.‚Äù\n\nWeiter f√§llt uns vielleicht auf, dass wir h√§ufig folgende Konstellationen beobachten k√∂nnen:\n\n\n\nhttps://de.wikipedia.org/wiki/Conways_Spiel_des_Lebens\n\n\nDaher k√∂nnten wir die wiederkehrenden Muster z√§hlen und beispielsweise √ºber die Zeit hinweg vergleichen:\n\nWie oft taucht ein bestimmtes Muster im Verlauf auf?\nFolgen dieselben Muster immer aufeinander?\nK√∂nnen wir in verschiedenen Bedingungen diese verschiedenen Muster h√§ufiger auftauchen lassen?\n\nWenn Sie all dies getan haben:\n\nWie gut k√∂nnen Sie den n√§chsten Zustand des Systems vorhersagen, wenn Sie einen bestehenden Zustand kennen?\nVerstehen Sie den Prozess?\nK√∂nnen Sie ihn erkl√§ren?\n\n\n\n\n\n\n\n\nRegeln des Game of Life\n\n\n\n\n\nDie Regeln des Game of Life lauten:\n\nEine aktive Zelle bleibt auch in der Folgegeneration aktiv (lebt weiter), wenn sie entweder zwei oder drei aktive Nachbarn hat.\nEine inaktive Zelle wird aktiv (‚Äûwird geboren‚Äú/lebt in der Folgegeneration), wenn sie genau drei aktive Nachbarn hat.\n\nDaraus folgt:\n\nEine aktive Zelle mit keiner, einer oder mehr als drei aktiven Zellen um sich her wird inaktiv (‚Äústirbt‚Äù).\nEine inaktive Zelle bleibt inaktiv, solange sie keine, eine, zwei oder mehr als drei aktive Zellen um sich her hat.\n\nH√§tten Sie aus diesen Regeln das Muster vorhersagen k√∂nnen ohne Zellen zu z√§hlen und es aufzuzeichnen?",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "modeling.html#wie-wird-ein-prozess-modelliert",
    "href": "modeling.html#wie-wird-ein-prozess-modelliert",
    "title": "20¬† Einf√ºhrung",
    "section": "20.2 Wie wird ein Prozess modelliert?",
    "text": "20.2 Wie wird ein Prozess modelliert?\n\nThere is little doubt that even before you started reading this book, you had already fit many models to data. No one who has completed an introductory statistics course can escape learning about linear regression. It turns out that every time you computed a regression line, you were actually fitting a model‚Äînamely, the regression line with its two parameters, slope and intercept‚Äîto the data. Lewandowsky & Farrell (2010, S. 71)\n\n\n20.2.1 Planetare Bewegung\nEin Beispiel daf√ºr, wie ein datengenerierender Prozess √ºber Jahrhunderte hinweg modelliert wurde, ist die planetare Bewegung: Menschen haben √ºber sehr lange Zeit hinweg durch das Beobachten der Objekte im Himmel versucht zu verstehen, wie diese Bewegungen zustande kommen. Das folgende Beispiel basiert auf dem Buch von Lewandowsky & Farrell (2011).\nDie Daten die beobachtet wurden, waren die beobachtbaren Objekte im Himmel √ºber die Zeit. Dies f√ºhrte zu zwei Erkenntnissen:\n\neinige Planeten √§ndern pl√∂tzlich ihre Richtung\nnach einiger Zeit nehmen sie ihren urspr√ºnglichen Weg wieder auf\n\n\n\n\n\n\n\n\n\n\n\nGeozentrisches Modell\n\n\n\n\n\n\n\nHeliozentrisches Modell\n\n\n\n\n\nWir sehen daran:\n\nDie Daten lassen sich nur mit einem Modell des zugrunde liegenden Prozesses erkl√§ren.\nModelle an sich k√∂nnen nicht beobachtet werden.\nEs gibt fast immer mehrere Modelle, welche die Daten erkl√§ren k√∂nnen\n\n\n\n\n\n\n\nHands-on: Modelle und Realit√§t\n\n\n\nWas haben untenstehende Zitate und die Abbildung gemeinsam?\n\nAll models are wrong, some are useful. George Box (1976)\n\n\nThe map is not the territory. Gregory Bateson (1988)",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "modeling.html#summary",
    "href": "modeling.html#summary",
    "title": "20¬† Einf√ºhrung",
    "section": "20.3 Summary",
    "text": "20.3 Summary\n\n‚ÄúWe suggest that purely verbal theorizing in cognition is increasingly inadequate in light of the growing richness of our data: whereas several decades ago decision-making tasks might have yielded only simple accuracy measures, we now have access not only to accuracy but also to the latencies of all response classes and their distributions. This richness defies verbal analysis but presents an ideal landscape for computational modeling. Indeed, we suggest that models also help avoid replication failures because the likelihood that an experiment will yield a quantitatively predicted intricate pattern of results involving multiple dependent variables by chance alone is surely lower than that a study might, by randomness alone, yield simple pairwise differences between conditions that happen to mesh with a verbally specified theoretical notion. Second, we consider the increasingly tight connection between modeling and the cognitive neurosciences to be a particularly promising arena. Measurement models, explanatory models, and cognitive architectures are now either directly neurally inspired, or they provide a conceptual bridge between behavioral data and their neural underpinnings. There is little doubt that this trend will continue in the future.‚Äù Lewandowsky & Oberauer (2018)",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "modeling.html#weiterf√ºhrende-literatur",
    "href": "modeling.html#weiterf√ºhrende-literatur",
    "title": "20¬† Einf√ºhrung",
    "section": "20.4 Weiterf√ºhrende Literatur",
    "text": "20.4 Weiterf√ºhrende Literatur\n\nForstmann, B. U., & Wagenmakers, E. J. (2015). Model-based cognitive neuroscience: A conceptual introduction. In An introduction to model-based cognitive neuroscience (pp.¬†139-156). New York, NY: Springer New York.\nLewandowsky, S., & Farrell, S. (2010). Computational modeling in cognition: Principles and practice. Sage.\nLewandowsky, S., & Oberauer, K. (2018). Computational modeling in cognition and cognitive neuroscience. Stevens‚Äô handbook of experimental psychology and cognitive neuroscience, 5, 1-35.\nLekt√ºre f√ºr die Semesterferien: ‚ÄúModels of the Mind: How Physics, Engineering, and Mathematics Have Shaped Our Understanding of the Brain‚Äù von Grace Lindsay (2021)",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "modeling.html#footnotes",
    "href": "modeling.html#footnotes",
    "title": "20¬† Einf√ºhrung",
    "section": "",
    "text": "https://andysbrainbook.readthedocs.io/en/stable/fMRI_Short_Course/fMRI_05_1stLevelAnalysis.html‚Ü©Ô∏é\nund diese ist extrem fr√ºh erreicht, wie das Beispiel Game of life mit nur wenigen Regeln zeigt‚Ü©Ô∏é\nhttps://www.the100.ci/2017/03/14/that-one-weird-third-variable-problem-nobody-ever-mentions-conditioning-on-a-collider/‚Ü©Ô∏é",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Einf√ºhrung</span>"
    ]
  },
  {
    "objectID": "sdt.html",
    "href": "sdt.html",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "",
    "text": "21.1 %-Correct\nWeshalb ist die SDT n√ºtzlich? Dies kann am Beispiel des Masses %-Correct aufgezeigt werden. Das Berechnen von %-Correct, also dem Anteil richtiger Antworten innerhalb eines Experiments / einer Person / einer Bedingung, ist ein h√§ufig genutztes Vorgehen, um zu quantifizieren, wie gut Personen eine Aufgabe l√∂sen kann. Sie eignet sich jedoch nur als Mass f√ºr Sensitivit√§t, wenn nicht zwischen der Sensitivit√§t und der Antworttendenz unterschieden werden soll.\nF√ºr unseren Random Dot-Datensatz k√∂nnen wir den Anteil richtiger Antworten jeder Versuchsperson aufgrund der gegebenen Antworten (resp) bzw. der Variable corr berechnen. Diese entspricht bei richtiger Antwort 1 und bei falscher Antwort 0. Wenn wir den Durchschnitt (mean()) der Variable corr berechnen, erhalten wir den Anteil korrekter Antworten. Wenn wir diese Zahl \\(\\cdot 100\\) rechnen, erhalten wir %-Correct.\nIm Experiment wurde die Instruktion (speed und accuracy) innerhalb der Versuchspersonen manipuliert. Es macht daher Sinn, f√ºr diese beiden Bedingungen je einen Wert pro Person zu berechnen.\nWir nehmen nicht an, dass sich im Experiment die ‚ÄúSensitivit√§t‚Äù ver√§ndert hat, also wie gut eine Person eine Aufgabe l√∂sen kann, sondern viel mehr, dass sich ihr Entscheidungskriterium ver√§ndert hat durch die unterschiedliche Instruktion. Tats√§chlich finden wir unseren Daten keinen Unterschied. Es k√∂nnte aber sein, dass eine Instruktion dazu f√ºhrt, dass eine Antworttendenz st√§rker auf die Daten Einfluss nimmt, als in einer anderen. In diesem Fall w√ºrde vielleicht eine Antworttendenz von Personen eher rechts als links zu dr√ºcken eher Einfluss nehmen, wenn man wenig Zeit hat die Aufgabe zu l√∂sen.\nWenn wir wissen m√∂chten, ob die Aufgabe mit Speed-Instruktion gleich gut l√∂sbar war wie die mit der Accuracy-Instruktion und gleichzeitig wissen m√∂chten, ob die Personen eine Tendenz haben ‚Äúrechts‚Äù oder ‚Äúlinks‚Äù zu antworten, k√∂nnen wir die SDT anwenden.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#correct",
    "href": "sdt.html#correct",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "",
    "text": "Hands-on: %-Correct berechnen\n\n\n\n\nErstellen Sie ein neues R-Projekt namens complab_models. Erstellen Sie im Projektordner einen Ordner data.\nLaden Sie Daten des Random Dot Experiments hier herunter und speichern Sie diese im erstellten Projekt im Ordner data.\n√ñffnen Sie ein neues R-Skript/RNotebook/RMarkdown signaldetection und lesen Sie die heruntergeladenen Daten ein.\nBerechnen Sie die Sensitivit√§t f√ºr jede Versuchsperson individuell getrennt f√ºr die beiden Bedingungen speed und accuracy (vgl. Output unten).\n\n\nd_sens = |&gt;\n    ...\n    ...\n    ...\n\n\n\n# A tibble: 6 √ó 3\n# Groups:   id [3]\n  id      condition  sens\n  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 sub-007 accuracy   68.3\n2 sub-007 speed      66.7\n3 sub-010 accuracy  100  \n4 sub-010 speed     100  \n5 sub-011 accuracy   91.7\n6 sub-011 speed      90  \n\n\n\nDer resultierende Datensatz der berechneten Sensitivit√§ten ist im Long-Format. √úberf√ºhren Sie den Datensatz in das Wide-Format, um die Daten einfacher verst√§ndlich zu machen (vgl. Output unten).",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#vorgehen-in-der-sdt",
    "href": "sdt.html#vorgehen-in-der-sdt",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.2 Vorgehen in der SDT",
    "text": "21.2 Vorgehen in der SDT\nDie SDT ist eine statistische Entscheidungstheorie, deren zentrale Fragestellung lautet: Was ist der (unbekannte) Zustand der Welt, angesichts der verrauschten Daten?\nIn einem Modell macht es Sinn, sicherzustellen, dass das Problem einfach ist ‚Äì wir beschr√§nken die Welt auf zwei m√∂gliche Zust√§nde. Dies k√∂nnen beispielsweise sein:\n\npr√§sent ‚Äì abwesend\nrechts ‚Äì links\nneu/unbekannt ‚Äì alt/bekannt (in einem Ged√§chtnisparadigma)\n\nWir werden das Vorgehen in der SDT anhand unserer eigenen Random Dot Experiment Daten nachvollziehen. Hierf√ºr werden wir das Experiment aus zwei Perspektiven betrachten:\n\naus der Perspektive einer Person, welche die Aufgabe hat, Stimuli in zwei Klassen zu klassifizieren und\naus der Perspektive eines Modells, das die Leistung der Person in der Aufgabe vorhersagt.\n\n\n21.2.1 Die Perspektive der Versuchsperson\nWir betrachten ein Experiment, bei dem eine Person einen Stimulus in eine von zwei m√∂glichen Kategorien einordnen muss. Das Random Dot Experiment beinhaltete die Stimuluskategorien Bewegung nach rechts und Bewegung nach links. Die Aufgabe der Person war es, eine bin√§re Klassifikation mit den Antwortoptionen rechts und links durchzuf√ºhren. Die Antwortoptionen entsprechen den beiden m√∂glichen Zust√§nden der ‚ÄúWelt‚Äù, oder genauer gesagt, Hypothesen der Person √ºber die m√∂glichen Zust√§nde der Welt.\n\nAnnahmen\n\nDie Person verarbeitet den Stimulus und gelangt zu einer internen Repr√§sentation des Stimulus. Diese interne Repr√§sentation ist nicht deterministisch, sondern variiert zuf√§llig und ist demzufolge eine Zufallsvariable \\(X\\). Wir nehmen an, dass die interne Repr√§sentation normalverteilt ist.\nDie Zufallsvariable \\(X\\) repr√§sentiert die Information, die die Person √ºber den Stimulus hat, also die Evidenz.\nDie Person weiss, dass \\(X\\) aus einer von zwei Verteilungen gezogen wurde, die sich nur in ihrer Lage (in ihrem Mittelwert) unterscheiden. Welche Verteilung es war, weiss die Person jedoch nicht ‚Äì dies muss sie anhand eines Kriteriums entscheiden.\nDie Person hat ein Kriterium \\(k\\), das sie verwendet, um zu entscheiden, ob sich der Stimulus nach rechts oder links bewegt. Eine einfache Entscheidungsregel lautet: Wenn \\(X &gt; k\\), dann bewegen sich die Punkte nach rechts, andernfalls nach links.\n\n\n\n\nPlot adapted and modified from Vuorre (2017)2\n\n\n\n\n\n21.2.2 Die Perspektive des/der externen Beobachter*in\nDie Leistung der Versuchsperson kann durch die Wahrscheinlichkeit beschrieben werden, dass sie einen Treffer (Hit) oder einen False Alarm produziert. Diese Wahrscheinlichkeiten werden als Hit Rate und False Alarm Rate bezeichnet. Die Hit Rate ist die Wahrscheinlichkeit, dass die Person einen richtig liegt, wenn der Stimulus rechts ist. Die False Alarm Rate ist die Wahrscheinlichkeit, dass die Person einen Fehler macht, wenn der Stimulus links ist.\nDie Antworten der Versuchspersonen k√∂nnen in einer Tabelle zusammengefasst werden, mit vier m√∂glichen Ergebnissen.3\n\n\n\n\nStimulus\n\n\n\n\n\nAntwort\nRechts\nLinks\n\n\nRechts\nHit\nFalse alarm (FA)\n\n\nLinks\nMiss\nCorrect rejection (CR)\n\n\n\n\nHit: Stimulus ist rechts, Antwort ist rechts\nMiss: Stimulus ist rechts, Antwort ist links\nFalse alarm: Stimulus ist links, Antwort ist rechts\nCorrect rejection: Stimulus is links, Antwort ist links\n\n\n\n\n\n\n\nHands-on: Hit, False Alarm, Miss und Correct Rejection labeln\n\n\n\nSetzen Sie diese verbale Beschreibung in R-Code um.\n\nErstellen Sie dazu im Random Dot Datensatz mit der Funktion mutate() eine Variable type. In dieser Variable soll f√ºr jeden Trial stehen, ob es sich um einen Hit, einen Miss, einen FA oder eine CR handelt (vgl. Daten unten).\n\n\nsdt &lt;- d |&gt;\n    select(id, stimulus = direction, resp) |&gt;\n    mutate(type = case_when(\n        direction == ... & resp == ... ~ ...,\n        ...\n        ...\n        ...))\n\n\n\n       id trial direction condition corrAns  resp corr        rt type\n1 sub-007     1     right     speed   right right    1 0.6537022  Hit\n2 sub-007     2      left     speed    left right    0 0.5821858   FA\n3 sub-007     3      left     speed    left  left    1 1.3868371   CR\n4 sub-007     4     right     speed   right right    1 0.9550371  Hit\n5 sub-007     5      left     speed    left right    0 0.4990127   FA\n6 sub-007     6     right     speed   right  left    0 0.6926959 Miss",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#sdt-parameter-berechnen",
    "href": "sdt.html#sdt-parameter-berechnen",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.3 SDT Parameter berechnen",
    "text": "21.3 SDT Parameter berechnen\nDie beiden wichtigsten Parameter der Signal-Detektionstheorie sind \\(d'\\) und \\(c\\).\n\n\\(d'\\) (d-prime) ist ein Mass f√ºr die Sensitivit√§t eines Beobachters bei der Unterscheidung zwischen zwei Stimulusklassen. Ein gr√∂√üerer \\(d'\\)-Wert zeigt eine gr√∂ssere Sensitivit√§t an. Dies bedeutet, dass die Verteilungen der beiden Stimulusklassen st√§rker voneinander getrennt sind und somit leichter unterscheidbar sind.\n\\(c\\) (criterion) ist ein Mass daf√ºr, ob eine Voreingenommenheit (bias) f√ºr eine der beiden Antwortoptionen besteht. Genauer gesagt ist \\(c\\) der Abstand vom tats√§chlichen Kriterium zum Punkt welcher genau zwischen den Verteilungen liegt.\n\n\n\n\n\n\n\nHands-on: Fragestellung\n\n\n\nWas bedeuten \\(d'\\) und \\(c\\) in unserem Beispiel? Welche Fragestellung(en) k√∂nnen wir untersuchen?\n\n\nUm \\(d'\\) und \\(c\\) zu erhalten, berechnen wir zuerst die Hit Rate und die False Alarm Rate, \\(z\\)-transformieren diese und nehmen dann die Differenz.\n\\[d' = z(Hit~Rate) - z(FA~Rate)\\]\n\n\\[c = -0.5 * (z(Hit~Rate) + z(FA~Rate))\\]\n\nRelative H√§ufigkeiten von Hits und False Alarms berechnen\nUm \\(d'\\) und \\(c\\) aus den beobachteten Antworth√§ufigkeiten zu berechnen, m√ºssen wir zuerst die relativen H√§ufigkeiten der Hits (Hit Rate) und der False Alarms (FA Rate) berechnen.\nDie Hits sind die rechts-Antworten auf rechts-Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem rechts Stimulus die Antwort rechts war. Die False Alarms sind die rechts-Antworten auf links-Stimuli. Dies bedeutet, dass wir z√§hlen, wie oft bei einem links Stimulus die Antwort rechts war.\nUm \\(d'\\) und \\(c\\) f√ºr jede Vpn in beiden Instruktions Bedingungen zu berechnen, z√§hlen wir die verschiedenen Antworttypen (vgl. Daten unten) pro Person und Bedingung.\n\n\n\n\n\n\nRelative H√§ufigkeiten von Hits und False Alarms berechnen\n\n\n\n\nsdt_summary &lt;- sdt |&gt;\n    group_by(..., ...) |&gt;\n    count(...)\n\nsdt_summary\n\n\n\n# A tibble: 539 √ó 4\n# Groups:   id, condition [140]\n   id      condition type      n\n   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;int&gt;\n 1 sub-007 accuracy  CR       21\n 2 sub-007 accuracy  FA        9\n 3 sub-007 accuracy  Hit      20\n 4 sub-007 accuracy  Miss     10\n 5 sub-007 speed     CR       20\n 6 sub-007 speed     FA       10\n 7 sub-007 speed     Hit      20\n 8 sub-007 speed     Miss     10\n 9 sub-010 accuracy  CR       30\n10 sub-010 accuracy  Hit      30\n# ‚Ñπ 529 more rows\n\n\n\n\nVor dem Berechnen von \\(d'\\) und \\(c\\) m√ºssen wir den Datensatz noch formatieren: Hierzu konvertieren wir den Datensatz von long zu wide, um alle vier Antworttypen in jeweils eigenen Variablen zu speichern.\n\nsdt_summary &lt;- sdt_summary |&gt;\n    pivot_wider(names_from = type, \n                values_from = n)\nsdt_summary\n\n# A tibble: 140 √ó 6\n# Groups:   id, condition [140]\n   id      condition    CR    FA   Hit  Miss\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 sub-007 accuracy     21     9    20    10\n 2 sub-007 speed        20    10    20    10\n 3 sub-010 accuracy     30    NA    30    NA\n 4 sub-010 speed        30    NA    30    NA\n 5 sub-011 accuracy     26     4    29     1\n 6 sub-011 speed        26     4    28     2\n 7 sub-012 accuracy     29     1    29     1\n 8 sub-012 speed        30    NA    29     1\n 9 sub-015 accuracy     25     5    24     6\n10 sub-015 speed        22     8    25     5\n# ‚Ñπ 130 more rows\n\n\n\n\nNAs ersetzen\nWir erstellen eine Hilfsfunktion replace_NA() um alle fehlenden Werte (NA) durch 0 zu ersetzen.\n\nreplace_NA &lt;- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\n\nsdt_summary &lt;- sdt_summary |&gt;\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))\nsdt_summary\n\n# A tibble: 140 √ó 6\n# Groups:   id, condition [140]\n   id      condition    CR    FA   Hit  Miss\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n 1 sub-007 accuracy     21     9    20    10\n 2 sub-007 speed        20    10    20    10\n 3 sub-010 accuracy     30     0    30     0\n 4 sub-010 speed        30     0    30     0\n 5 sub-011 accuracy     26     4    29     1\n 6 sub-011 speed        26     4    28     2\n 7 sub-012 accuracy     29     1    29     1\n 8 sub-012 speed        30     0    29     1\n 9 sub-015 accuracy     25     5    24     6\n10 sub-015 speed        22     8    25     5\n# ‚Ñπ 130 more rows\n\n\n\n\nHit Rate und False Alarm Rate berechnen\nDie Hit Rate und die False Alarm Rate kann anhand der folgenden Formeln berechnet werden:\n\n\\[ Hit~Rate = \\frac{Hits}{Hits + Misses} \\]\n\n\\[ FA~Rate = \\frac{False Alarms}{False Alarms + Correct Rejections} \\] \n\n\n\n\n\n\nHands-on: Hit Rate und False Alarm Rate berechnen\n\n\n\n\nsdt_summary &lt;- sdt_summary |&gt;\n    mutate(hit_rate = ...,\n           fa_rate = ...)\nsdt_summary\n\n\n\n# A tibble: 140 √ó 8\n# Groups:   id, condition [140]\n   id      condition    CR    FA   Hit  Miss hit_rate fa_rate\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 sub-007 accuracy     21     9    20    10    0.667  0.3   \n 2 sub-007 speed        20    10    20    10    0.667  0.333 \n 3 sub-010 accuracy     30     0    30     0    1      0     \n 4 sub-010 speed        30     0    30     0    1      0     \n 5 sub-011 accuracy     26     4    29     1    0.967  0.133 \n 6 sub-011 speed        26     4    28     2    0.933  0.133 \n 7 sub-012 accuracy     29     1    29     1    0.967  0.0333\n 8 sub-012 speed        30     0    29     1    0.967  0     \n 9 sub-015 accuracy     25     5    24     6    0.8    0.167 \n10 sub-015 speed        22     8    25     5    0.833  0.267 \n# ‚Ñπ 130 more rows\n\n\n\n\n\n\n0 und 1 ersetzen\nWir erstellen eine Hilfsfunktion correct_zero_one() mit der wir bei den Hit und False Alarm Rates alle 0 und 1 Werte durch 0.001 oder 0.999 ersetzen. Dies machen wir, damit wir bei der Berechnung der z-Werte nicht \\(\\pm \\infty\\) erhalten.\n\ncorrect_zero_one &lt;- function(x) {\n    if (identical(x, 0)) {\n        x = x + 0.001\n    } else if (identical(x, 1)) {\n        x = x - 0.001\n    }\n    x\n}\n\nF√ºr den n√§chsen Schritt nutzen wir die Funktion correct_zero_one().\n\nsdt_summary &lt;- sdt_summary |&gt;\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))\nsdt_summary\n\n# A tibble: 140 √ó 8\n# Groups:   id, condition [140]\n   id      condition    CR    FA   Hit  Miss hit_rate fa_rate\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 sub-007 accuracy     21     9    20    10    0.667  0.3   \n 2 sub-007 speed        20    10    20    10    0.667  0.333 \n 3 sub-010 accuracy     30     0    30     0    0.999  0.001 \n 4 sub-010 speed        30     0    30     0    0.999  0.001 \n 5 sub-011 accuracy     26     4    29     1    0.967  0.133 \n 6 sub-011 speed        26     4    28     2    0.933  0.133 \n 7 sub-012 accuracy     29     1    29     1    0.967  0.0333\n 8 sub-012 speed        30     0    29     1    0.967  0.001 \n 9 sub-015 accuracy     25     5    24     6    0.8    0.167 \n10 sub-015 speed        22     8    25     5    0.833  0.267 \n# ‚Ñπ 130 more rows\n\n\n\n\n\\(z\\)-Transformation\nAls n√§chstes m√ºssen die \\(z\\)-Werte der Hit Rate und der False Alarm Rate berechnet werden. Dazu kann die Funktion qnorm()verwendet werden.\n\n\n\n\n\n\nHands-on: \\(z\\)-Transformation\n\n\n\n\nsdt_summary &lt;- sdt_summary |&gt;\n    mutate(zhr = ...,\n           zfa = ...)\nsdt_summary\n\n\n\n# A tibble: 140 √ó 10\n# Groups:   id, condition [140]\n   id      condition    CR    FA   Hit  Miss hit_rate fa_rate   zhr    zfa\n   &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 sub-007 accuracy     21     9    20    10    0.667  0.3    0.431 -0.524\n 2 sub-007 speed        20    10    20    10    0.667  0.333  0.431 -0.431\n 3 sub-010 accuracy     30     0    30     0    0.999  0.001  3.09  -3.09 \n 4 sub-010 speed        30     0    30     0    0.999  0.001  3.09  -3.09 \n 5 sub-011 accuracy     26     4    29     1    0.967  0.133  1.83  -1.11 \n 6 sub-011 speed        26     4    28     2    0.933  0.133  1.50  -1.11 \n 7 sub-012 accuracy     29     1    29     1    0.967  0.0333 1.83  -1.83 \n 8 sub-012 speed        30     0    29     1    0.967  0.001  1.83  -3.09 \n 9 sub-015 accuracy     25     5    24     6    0.8    0.167  0.842 -0.967\n10 sub-015 speed        22     8    25     5    0.833  0.267  0.967 -0.623\n# ‚Ñπ 130 more rows\n\n\n\n\n\n\n\\(d'\\) und \\(c\\) berechnen\nNun k√∂nnen die SDT Parameter anhand der folgenden Formeln berechnet werden:\n\n\\[d' = z(Hit~Rate) - z(FA~Rate)\\]\n\n\\[c = -0.5 * (z(Hit~Rate) + z(FA~Rate))\\] \n\n\n\n\n\n\nHands-on: \\(d'\\) und \\(c\\) berechnen\n\n\n\n\nsdt_summary &lt;- sdt_summary |&gt;\n    mutate(dprime = ...,\n           c = ...) |&gt;\n    mutate(across(c(dprime, c), round, 2))\n\n\n\n# A tibble: 140 √ó 13\n# Groups:   id, condition [140]\n   id     condition    CR    FA   Hit  Miss hit_rate fa_rate   zhr    zfa dprime\n   &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 sub-0‚Ä¶ accuracy     21     9    20    10    0.667  0.3    0.431 -0.524   0.96\n 2 sub-0‚Ä¶ speed        20    10    20    10    0.667  0.333  0.431 -0.431   0.86\n 3 sub-0‚Ä¶ accuracy     30     0    30     0    0.999  0.001  3.09  -3.09    6.18\n 4 sub-0‚Ä¶ speed        30     0    30     0    0.999  0.001  3.09  -3.09    6.18\n 5 sub-0‚Ä¶ accuracy     26     4    29     1    0.967  0.133  1.83  -1.11    2.94\n 6 sub-0‚Ä¶ speed        26     4    28     2    0.933  0.133  1.50  -1.11    2.61\n 7 sub-0‚Ä¶ accuracy     29     1    29     1    0.967  0.0333 1.83  -1.83    3.67\n 8 sub-0‚Ä¶ speed        30     0    29     1    0.967  0.001  1.83  -3.09    4.92\n 9 sub-0‚Ä¶ accuracy     25     5    24     6    0.8    0.167  0.842 -0.967   1.81\n10 sub-0‚Ä¶ speed        22     8    25     5    0.833  0.267  0.967 -0.623   1.59\n# ‚Ñπ 130 more rows\n# ‚Ñπ 2 more variables: k &lt;dbl&gt;, c &lt;dbl&gt;\n\n\n\n\n\n\nNeuer Datensatz erstellen\nF√ºr den finalen Datensatz w√§hlen wir d' und c f√ºr jede Person in jeder Bedingung.\n\n\n\n\n\n\nHands-on: Datensatz erstellen\n\n\n\n\nsdt_final &lt;- sdt_summary |&gt;\n    select(...)\nsdt_final\n\n\n\n# A tibble: 140 √ó 4\n# Groups:   id, condition [140]\n   id      condition dprime     c\n   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n 1 sub-007 accuracy    0.96  0.05\n 2 sub-007 speed       0.86  0   \n 3 sub-010 accuracy    6.18  0   \n 4 sub-010 speed       6.18  0   \n 5 sub-011 accuracy    2.94 -0.36\n 6 sub-011 speed       2.61 -0.2 \n 7 sub-012 accuracy    3.67  0   \n 8 sub-012 speed       4.92  0.63\n 9 sub-015 accuracy    1.81  0.06\n10 sub-015 speed       1.59 -0.17\n# ‚Ñπ 130 more rows",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#sdt-parameter-vergleichen",
    "href": "sdt.html#sdt-parameter-vergleichen",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.4 SDT Parameter vergleichen",
    "text": "21.4 SDT Parameter vergleichen\nIn einem weiteren Schritt k√∂nnen die berechneten Parameter verglichen werden. So kann unterschieden werden, worauf sich die Instruktion ausgewirkt hat: Auf die Antworttendenz oder auf die Sensitivit√§t?\nUm die SDT Parameter zwischen den Bedingungen zu vergleichen berechnen wir f√ºr \\(d'\\) und \\(c\\) den Mittelwert (mean()) und die Standardabweichung (sd()) in beiden Bedingungen (speed und accuracy).\n\n\n\n\n\n\nHands-on: Mittelwerte und SD berechnen, um Bedingungen zu vergleichen\n\n\n\n\ncs &lt;- sdt_final |&gt;\n    select(id, condition, c) |&gt;\n    Rmisc::summarySEwithin(measurevar = \"...\",\n                           withinvars = \"...\",\n                           idvar = \"...\",\n                           na.rm = FALSE,\n                           conf.interval = 0.95)\n\ndprimes &lt;- sdt_final |&gt;\n    select(id, condition, dprime) |&gt;\n    Rmisc::summarySEwithin(measurevar = \"...\",\n                           withinvars = \"...\",\n                           idvar = \"...\",\n                           na.rm = FALSE,\n                           conf.interval = 0.95)\n\n\n\nWenn alle Schritte ausgef√ºhrt wird, kann mit folgendem Code ein Plot erstellt werden:\n\nlibrary(patchwork)\n    \np_dprime &lt;- dprimes |&gt;\n    ggplot(aes(x = condition, y = dprime, group = 1)) +\n    geom_jitter(aes(condition, dprime), alpha = 0.1, data = sdt_final, width = 0.05) +\n    geom_line() +\n    geom_line(aes(condition, dprime, group = id), alpha = 0.05, data = sdt_final, width = 0.05) +\n    geom_errorbar(width = 0.1, aes(ymin = dprime - ci,\n                                   ymax = dprime + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"Sensitivity\") + theme_minimal()\n\np_bias &lt;- cs |&gt;\n    ggplot(aes(x = condition, y = c, group = 1)) + \n    geom_jitter(aes(condition, c), alpha = 0.1, data = sdt_final, width = 0.05) +\n    geom_hline(yintercept = 0, \n               linetype = \"dashed\",\n               color = \"grey60\") +\n    geom_line() +\n    geom_line(aes(condition, c, group = id), alpha = 0.05, data = sdt_final, width = 0.05) +\n    geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                   ymax = c + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"Bias\") + theme_minimal()\n\np_dprime + p_bias \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on: Was wissen wir nun?\n\n\n\nDiskutieren Sie zusammen die beiden Plots: Was k√∂nnen wir daran sehen?\nOb Unterschiede einer statistischen Untersuchung standhalten k√∂nnten wir z.B. mit einer ‚Äòrepeated-measures‚Äô ANOVA untersuchen.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#anwendungsbeispiele",
    "href": "sdt.html#anwendungsbeispiele",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.5 Anwendungsbeispiele",
    "text": "21.5 Anwendungsbeispiele\nDie SDT wird in einem breiten Spektrum von Fragestellungen verwendet. Hier einige Beispiele:\n\nEntdecken von Fake-News: Batailler, C., Brannon, S. M., Teas, P. E., & Gawronski, B. (2021). A Signal Detection Approach to Understanding the Identification of Fake News. Perspectives on Psychological Science, 17(1), 78-98. https://doi.org/10.1177/1745691620986135\nGo/No-Go-Task und Alkohol: Ames, S. L., Wong, S. W., Bechara, A., Cappelli, C., Dust, M., Grenard, J. L., & Stacy, A. W. (2014). Neural correlates of a Go/NoGo task with alcohol stimuli in light and heavy young drinkers. Behavioural brain research, 274, 382-389. https://doi.org/10.1016/j.bbr.2014.08.039\nSomatic Signal Detection Task: Mirams, L., Poliakoff, E., Brown, R.J. et al.¬†Vision of the body increases interference on the somatic signal detection task. Exp Brain Res 202, 787‚Äì794 (2010). https://doi.org/10.1007/s00221-010-2185-7\n\n\n\n\n\n\n\nHands-on: Anwendung der SDT\n\n\n\nSuchen Sie sich ein Paper mit einer SDT-Analyse oder w√§hlen Sie eine der oben angegebenen Paper:\nLesen Sie den Abstract durch (und falls notwendig Teile des Papers):\n\nWas war das Signal? Was der Noise?\nWas entspricht \\(d'\\) und was \\(c\\)?\nWas waren die Findings?",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#weiterf√ºhrende-informationen",
    "href": "sdt.html#weiterf√ºhrende-informationen",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.6 Weiterf√ºhrende Informationen",
    "text": "21.6 Weiterf√ºhrende Informationen\n\n\n\n\n\n\nWeitere Anwendungsbeispiele\n\n\n\nDas laufende Kursexperiment kann zwar mit SDT analysiert werden, es gibt jedoch weitaus spannendere Datens√§tze als den unseres Paradigmas:\n\nHier ein Beispiel eines Random Dot Experiments, bei dem den Personen vor den Dots Hinweisreize gezeigt wurde, in welche Richtung sich die Punktewolke am wahrscheinlichsten bewegen wird\nHier ein Beispiel der Analyse eines Datensatzes von einem Ged√§chtnisexperiment (Signal: schon gesehenes Gesicht, Rauschen: neues Gesicht)\n\n\n\n\nInteraktives Tutorial zu SDT: https://wise.cgu.edu/wise-tutorials/tutorial-signal-detection-theory/\nAusf√ºhrlichere Einf√ºhrung in die SDT: Stanislaw and Todorov (1999) und Macmillan and Creelman (2004)\nEinf√ºhrung in die Verwendung von R zur Durchf√ºhrung von SDT-Analysen: Knoblauch and Maloney (2012)",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#referenzen",
    "href": "sdt.html#referenzen",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "21.7 Referenzen",
    "text": "21.7 Referenzen\n\nVuorre, Matti. 2017. ‚ÄúEstimating Signal Detection Models with Regression Using the Brms R Package.‚Äù PsyArXiv. https://doi.org/10.31234/osf.io/vtfc3_v1.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "sdt.html#footnotes",
    "href": "sdt.html#footnotes",
    "title": "21¬† Signalentdeckungstheorie",
    "section": "",
    "text": "\\(z\\)-transformierte relative H√§ufigkeit der Treffer minus \\(z\\)-transformierte relative H√§ufigkeit der falschen Alarme‚Ü©Ô∏é\nhttps://vuorre.com/posts/sdt-regression/index.html#fig-sdt-example‚Ü©Ô∏é\nMeistens wird Signaldetektion im Rahmen von Signal vs.¬†Rauschen verwendet, die beiden Verteilungen k√∂nnen aber wie hier auch ‚ÄúBewegung nach Rechts‚Äù und ‚ÄúBewegung nach links‚Äù unmfassen.‚Ü©Ô∏é",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Signalentdeckungstheorie</span>"
    ]
  },
  {
    "objectID": "ddm.html",
    "href": "ddm.html",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "22.1 DDM: Modell eines Entscheidungsprozesses\nIn unserem Random dot Experiment wurde neben der Antwort der Versuchspersonen (links, rechts) auch die Zeit (rt) gemessen, welche ben√∂tigt wurde um diese Antworten zu geben. Diese Information wurde in den vorherigen Modellen nicht gleichzeitig mit der Antwortgenauigkeit ber√ºcksichtigt.\nEin Modell mit dem solche Entscheidungsprozesse modelliert werden sind Drift-Diffusion-Modelle. Es geht davon aus, dass bin√§re Entscheidungen auf der Anh√§ufung von verrauschten Beweisen basieren, beginnend am Ausgangspunkt und endend an einer Entscheidungsschwelle, die mit einer bestimmten Entscheidung verbunden ist.\nDas Modell hat mindestens vier Parameter:\nDie Gesamtzeit f√ºr eine Reaktion ist die Zeit f√ºr die Ausbreitung vom Startpunkt bis zur Grenze plus die Non-decision time.\nIm Modell wird die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt (diskrete Zeitschritte). Diese Evidenz wird in einer Entscheidungsvariable (decision variable: dv) gesammelt.\nUm nachzuvollziehen, wie sich eine Entscheidung (in unserem Beispiel: rechts und links) innerhalb eines Trials entwickelt, kann dieser Prozess in R simuliert werden.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "href": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "Das Modell wurde von Roger Ratcliff entwickelt. Es hat seinen Ursprung in Modellen zu den Bewegungen von Partikeln in einer Fl√ºssigkeit, und geht auf Arbeiten von Albert Einstein und Norbert Wiener zur√ºck.\n\n\n\nDrift rate steht f√ºr die durchschnittliche Anzahl von Beweisen pro Zeiteinheit und ist ein Index f√ºr die Schwierigkeit der Aufgabe oder die F√§higkeit des Subjekts.\nBoundary separation stellt die Vorsicht dar; eine gr√∂√üere Trennung der Grenzen f√ºhrt zu weniger Fehlern (wegen geringerer Auswirkung des Diffusionsrauschens innerhalb des Trials), jedoch um den Preis einer langsameren Reaktion (speed-accuracy tradeoff).\nStarting point repr√§sentiert die a-priori Pr√§ferenz f√ºr eine der Wahlalternativen.\nNon-decision time ist ein Verz√∂gerungsparameter, der die Zeit f√ºr periphere Prozesse (Kodierung eines Reizes, Umwandlung der Repr√§sentation des Reizes in eine entscheidungsbezogene Repr√§sentation) und Ausf√ºhrung einer Reaktion misst.\n\n\n\n\n\n\n\n\nAnnahmen des DDM\n\n\n\n\n\nDas DDM geht von folgenden Annahmen aus:\n\nBinary decision making: DDM ist ein Model f√ºr bin√§re Entscheidungen. Es gibt also 2 M√∂glichkeiten zwischen denen entschieden werden muss (in unserem Beispiel: rechts und links).\nContinuous sampling: Es wird davon ausgegangen, dass die Person den Stimulus verarbeitet und √ºber die Zeit Evidenz akkumuliert (sequential sampling). Entscheidungen beruhen demnach auf einem kontinuierlichen Verarbeitung von Daten.\nSingle-stage processing: Entscheidungen basieren auf einer einstufigen Verarbeitung.\nParameter sind konstant. Das heisst z.B. die drift rate kann sich nicht √ºber Zeit ver√§ndern.\n\n\n\n\n\n\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('left', '0', 'right')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#random-walk",
    "href": "ddm.html#random-walk",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.2 Random walk",
    "text": "22.2 Random walk\nEin Random walk ist das Resultat der Aufsummierung von Zufallszahlen. Dies kann in R selbst nachvollzogen werden:\nDazu wird ein Random walk mit 100 Zeitschritten simuliert (mit rnorm()). Es wird mit \\(0\\) begonnen und dann werden 99 normalverteilte Zufallszahlen dazuaddiert, also die kumulierte Summe berechnet (hierf√ºr eignet sich die Funktion cumsum()).\n\nRandom walkCode\n\n\n\n\n\n\nlibrary(gganimate) # library for animation\nset.seed(546)\n\n# 0 + 100 standardnormalverteilte Zufallszahlen\nzufallszahlen_1 = c(0, rnorm(99, 0, 1))\nrandom_walk_1 = cumsum(zufallszahlen_1)\n\nd1 = tibble(t = 1:100,\n            rand_walk = random_walk_1)\n\nd1 |&gt;\n    ggplot(aes(x = t, y = rand_walk)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Random walk') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    theme_classic() +\n    transition_reveal(nb) # animate\n\n\n\n\nDie aktuelle decision variable zu Zeitpunkt \\(t\\) als wird hier als normalverteilte Zufallszahl modelliert. Dieser Random walk hat keinen Trend, weil jeder Wert aus einer Normalverteilung mit Mittelwert \\(\\mu=0\\) gezogen wird.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#drift-rate-evidenzakkumulierung-√ºber-die-zeit",
    "href": "ddm.html#drift-rate-evidenzakkumulierung-√ºber-die-zeit",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.3 Drift rate: Evidenzakkumulierung √ºber die Zeit",
    "text": "22.3 Drift rate: Evidenzakkumulierung √ºber die Zeit\nWenn stattdessen aus einer Verteilung mit \\(\\mu=0.1\\) gezogen werden w√ºrde, erg√§be dies einen positiven Trend √ºber die Zeit hinweg und es w√ºrde sich Evidenz f√ºr eine Entscheidungsrichtung ansammeln.\nDie driftrate entspricht also dem Mittelwert der Evidenz und sd deren Standardabweichung.\n\n\n\n\n\n\nHands-on: Drift rate\n\n\n\nModellieren Sie die aktuelle decision variable zu Zeitpunkt \\(t\\) als normalverteilte Zufallszahl, bei der die driftrate nicht 0 entspricht.\nVer√§ndern Sie daf√ºr die Werte der Variablen mean_driftrate (positive und negative Werte) und sd_driftrate im Code.\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nIst der Mittelwert f√ºr die decision variable positiv wird zunehmend Evidenz f√ºr die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin ‚ÄúSt√ºck‚Äù Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4442915\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.7051354\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungef√§hr 0.71 betr√§gt. Da die Evidenz die durchschnittliche Steigung repr√§sentiert, wird Evidenz \\(&gt;0\\) dazu f√ºhren, dass ein Schritt in Richtung der oberen Grenze gemacht wird. W√§re die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also m√∂glich, dass die Evidenz zuf√§llig negativ wird, obwohl die drift rate, d.h. die Repr√§sentation der Stimulusst√§rke, positiv ist.\nWenn dieser Prozess nun √ºber mehrere Zeitschritte hinweg wiederholt wird und die evidence Werte aufsummiert werden, ergibt sich die decision variable. Diese gleicht einem Random walk, hat aber einen Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk mit und ohne DriftCode\n\n\n\n\n\n\nset.seed(546)\n\nt = 100\n\nd3 &lt;- tibble(\n    nb = 1:t,\n    random_walk_neg = cumsum(c(0, rnorm(t-1, -0.3, 1))),\n    random_walk_neutral = random_walk_1,\n    random_walk_pos = cumsum(c(0, rnorm(t-1, 0.3, 1)))\n    ) |&gt;\n    pivot_longer(cols = c(random_walk_neg, random_walk_neutral, random_walk_pos),\n                 names_to = \"name\",\n                 values_to = \"value\")\n\n# aggregate dataset and plot\nd3 |&gt;\n    ggplot(aes(x = nb, y = value, color = name)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    lims(y = c(-30, 30)) +\n    labs(x = 'Time', y = 'Random walk', color = '') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    scale_color_manual(labels = c('negative drift', 'no drift', 'positive drift'), values = c(\"tomato4\", \"black\", \"skyblue\")) +\n    theme_classic()\n\n\n\n\n\n22.3.1 Evidenzakkumulierung in R modellieren\nDie Evidenzakkumulierung kann als Iterationen √ºber einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# F√ºr jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on f√ºr Interessierte: Funktion erstellen\n\n\n\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # F√ºr jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time-bias-und-boundaries",
    "href": "ddm.html#non-decision-time-bias-und-boundaries",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.4 Non-decision time, bias und boundaries",
    "text": "22.4 Non-decision time, bias und boundaries\nDie Decision Variable dv repr√§sentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable gr√∂sser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.\nWir k√∂nnen nun noch die non-decision time und den Anfangspunkt (bias) der Evidenzakkumulierung hinzuf√ºgen.\nDie non-decision time beschreibt die Zeit, welche nicht der Evidenzakkumulierung dient. Vor dem Entscheidungsprozess ist das z.B. das Ausrichten des Blicks auf die Aufgabe, nach dem Entscheidungsprozes ist dies z.B. die Ausf√ºhrung des Tastendrucks.\nDer bias, also der Anfangspunkt ist ein sehr wichtiger Parameter der beeinflusst, ob schon vor dem Entscheidungsprozess zu einer gewissen Antwort tendiert wird (Antworttendenz). Wenn beispielsweise der Anfangspunkt unterhalb der Mitte liegt, braucht es weniger Evidenz um die untere Grenze zu √ºberschreiten und mehr Evidenz f√ºr die obere Grenze zu √ºberschreiten.\nDie boundaries beeinflussen, wie viel Evidenz ausreicht, um eine Entscheidung zu treffen. Will man sich ganz sicher sein, sind die boundaries weiter auseinander.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualit√§t der Evidenz pro Zeiteinheit\nTask Schwierigkeit, F√§higkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Pr√§ferenz f√ºr eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerz√∂gerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5, # z\n                           driftrate = 0.8, # v\n                           decision_boundary = 2, # a\n                           ndt = 0.5, # t0\n                           diffvar = 0.1, \n                           dt = 0.001, # t step duration\n                           max_time = 6) {\n    \n    assertthat::assert_that(diffvar &gt; 0)\n    \n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n    \n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n    \n    # start accumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n    \n    for (j in 2:time_steps) {\n        \n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                       min(dv[j], decision_boundary),\n                                       max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                      dv = dv,\n                      steps = seq_along(dv),\n                      driftrate = driftrate,\n                      decision_boundary = decision_boundary,\n                      bias = bias,\n                      ndt = ndt)\n    return(d)\n}\n\n\n\n\n\n\n\n\n\n\nHands-on: DDM Parameter\n\n\n\nVer√§ndern Sie im Code die Werte der Variablen\n\nmean_driftrate (positive und negative Werte)\nsd_driftrate\nbias\nboundary\ntimesteps.\n\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#auswirkungen-der-parameter",
    "href": "ddm.html#auswirkungen-der-parameter",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.5 Auswirkungen der Parameter",
    "text": "22.5 Auswirkungen der Parameter\nUm den Effekt dieser Parameter zu visualisieren, k√∂nnen Trials mit unterschiedlichen Parameterwerten geplottet werden.\n\n22.5.1 Drift rate\nWenn die drift rate viel gr√∂sser als \\(0\\) ist, also \\(&gt;&gt; 0\\), wird die obere Entscheidungsgrenze (decision boundary) schnell erreicht. Zudem wird es nur wenige Fehler geben. Ist die drift rate kleiner, aber immer noch \\(&gt; 0\\), wird die durschnittliche Zeit l√§nger, um eine korrekte Antwort zu geben.\n\nHohe vs.¬†tiefe drift rateCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(829)\n\nslow = drift_diffusion(driftrate = 0.8) |&gt; mutate(type = \"slow\")\nfast = drift_diffusion(driftrate = 1.2) |&gt; mutate(type = \"fast\")\n\nfastslow = bind_rows(fast, slow) \n\nfastslow |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue3\", \"skyblue\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.2 Bias\nWenn der bias \\(&gt;0.5\\) ist, wird die obere Entscheidungsgrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate‚Äîist diese klein, und der bias \\(&lt;0.5\\), ist die Chance, schnelle Fehler zu machen erh√∂ht.\n\nStarting point (bias)Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(29)\n\nunbiased = drift_diffusion(bias = 0.5) |&gt; mutate(type = \"unbiased\")\nupbiased = drift_diffusion(bias = 0.7) |&gt; mutate(type = \"upbiased\")\ndownbiased = drift_diffusion(bias = 0.3) |&gt; mutate(type = \"downbiased\")\n\nbias = bind_rows(unbiased, upbiased, downbiased) \n\nbias |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\",\"skyblue3\", \"skyblue4\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.3 Boundary separation\nLiegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies f√ºhrt dazu, dass weniger Fehler gemacht werden, da die zuf√§llige Fluktuation √ºber l√§ngere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erkl√§ren.\n\nDecision boundariesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(90)\n\ncarefree = drift_diffusion(decision_boundary = 1.6) |&gt; mutate(type = \"carefree\")\ncautious = drift_diffusion(decision_boundary = 2.1) |&gt; mutate(type = \"cautious\")\n\ncautiouscareless = bind_rows(carefree, cautious) \n\ndecision_boundaries = tribble(~type, ~decision_boundary,\n                               \"carefree\", 1.6,\n                               \"cautious\", 2.1)\ncautiouscareless |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +\n    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +\n    theme_classic()\n\n\n\n\n\n\n22.5.4 Non-decision time\nEine Ver√§nderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.\n\nNon-decision timeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4534)\n\nlongndt = drift_diffusion(ndt = 0.7) |&gt; mutate(type = \"longndt\")\nshortndt = drift_diffusion(ndt = 0.2) |&gt; mutate(type = \"shortndt\")\n\nndt = bind_rows(longndt, shortndt) \n\nndts = tribble(~type, ~ndt,\n                \"longndt\", 0.7,\n                \"shortndt\", 0.2)\n\nndt |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\n\nHands-on: Interpretation der Random Dot DDM Parameter\n\n\n\n\nDDM Random Dot ExperimentCodeDaten\n\n\nWie k√∂nnen die DDM Parameter interpretiert werden?\nBeachten Sie hierzu auch die 95% credible intervals.\n\n\n\n\n\nparameter\nestimate\n95%CrI (lower)\n95%CrI (upper)\n\n\n\n\ndrift rate accuracy\n0.02\n-0.01\n0.05\n\n\ndrift rate speed\n0.03\n0.00\n0.06\n\n\nboundary accuracy\n2.85\n2.81\n2.88\n\n\nboundary speed\n2.46\n2.43\n2.49\n\n\nbias accuracy\n0.50\n0.49\n0.51\n\n\nbias speed\n0.49\n0.48\n0.50\n\n\nndt\n0.04\n0.03\n0.04\n\n\n\n\n\n\n\n\nlibrary(brms)\nlibrary(cmdstanr)\n\nd = read_csv('data/sdt_random_dot_clean.csv') |&gt;\n    mutate(resp = case_match(resp,\n                             'right' ~ 'upper',\n                             'left' ~ 'lower'))\n\n# Vereinfachte Sch√§tzung der DDM Parameter (ohne Einbezug der Messwiederholung!)\nfit = brm(bf(rt | dec(resp) ~ 0 + condition,\n             bias ~ 0 + condition,\n             bs ~ 0 + condition\n           #ndt ~ 0 + condition\n),\n         # inits = 0.1,\n          data = d,\n          family = wiener(link_bs = \"identity\",\n                          link_ndt = \"identity\",\n                          link_bias = \"identity\"),\n          cores = parallel::detectCores(),\n          chains = 4,\n          backend = \"cmdstanr\")\n\n\n\nDie Daten stammen aus dem Random Dot Experiment FS25.\nDatensatz",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#diffusions-modell-in-der-forschung",
    "href": "ddm.html#diffusions-modell-in-der-forschung",
    "title": "22¬† Drift Diffusion Modell",
    "section": "22.6 Diffusions Modell in der Forschung",
    "text": "22.6 Diffusions Modell in der Forschung\nWeil mit dem Diffusionsmodell verschiedene Aspekte des Entscheidungsprozesses spezifisch modelliert und unterschieden werden k√∂nnen, wird dieses Modell h√§ufig in der Forschung verwendet. So k√∂nnen detaillierte Einsichten in den Entscheidungsprozess gewonnen werden. Hier ein paar Beispiele:\n\nUntersuchung der kognitiven Eigenschaften bei ADHS Review\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Abh√§ngigkeit (Tabak, Alkohol und Gl√ºcksspiel)\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Depression, und Angst.\nUntersuchung von ver√§ndertem Entscheidungsverhalten aufgrund von strukturellen oder funktionalen Ver√§nderungen des Gehirns z.B. bei Parkinson.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#footnotes",
    "href": "ddm.html#footnotes",
    "title": "22¬† Drift Diffusion Modell",
    "section": "",
    "text": "Bogacz, Rafal; Eric Brown, Jeff Moehlis, Philip Holmes, Jonathan D. Cohen (2006). ‚ÄúThe Physics of Optimal Decision Making: A Formal Analysis of Models of Performance in Two-Alternative Forced-Choice Tasks‚Äù. Psychological Review. 113 (4): 700‚Äì765. https://doi.org/10.1037/0033-295X.113.4.700‚Ü©Ô∏é",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "webrconsole.html",
    "href": "webrconsole.html",
    "title": "WebR Konsole",
    "section": "",
    "text": "In der WebR-Konsole k√∂nnen Sie R-Code ausf√ºhren. Erstellte Variablen werden gespeichert, so lange das Browserfenster nicht geschlossen wird.\n\n‚ÄÉKonsole‚ÄÉTipp‚ÄÉL√∂sung\n\n\nGeben Sie hier Code ein.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPackages\nLaden Sie zuerst das {tidyverse} mit library(tidyverse).\nDatens√§tze\nEs stehen Ihnen folgende Datens√§tze zur Verf√ºgung:\n\ncars\niris\n\nEs k√∂nnen weitere Datens√§tze durch das Laden von Packages genutzt werden:\n\npenguins aus {palmerpenguins}\n\n\n# Laden vom penguins-Datensatz aus dem {palmerpenguins} Package\nlibrary(palmerpenguins)\nd &lt;- penguins\n\n\n\n\nlibrary(tidyverse)\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13‚Ä¶\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34‚Ä¶\n\nplot(cars)",
    "crumbs": [
      "Anhang",
      "WebR Konsole"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License and Authorship",
    "section": "",
    "text": "The complab course was initially conceptualized and written by Andrew Ellis (2021-2023), extended by Gerda Wyssen (2021-2025), Daniel Fitze (2024), and Enea Weber (2025). The course experiments (Complab 2024-2025) and their descriptions were created by Rebekka Borer.\nPrevious course material:\n\nComplab 2021\n\nComplab 2022\nComplab 2023\nComplab 2024\n\nWe thank all current and previous students who gave valuable feedback on the course and material!\nCite as: Wyssen, G., Ellis, A., Weber, E., Fitze, D. (2025). Neurowissenschaft im Computerlab. Skript FS 2025. https://kogpsy.github.io/neuroscicomplabFS25.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Anhang",
      "License and Authorship"
    ]
  }
]