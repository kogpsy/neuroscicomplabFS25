[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "Herzlich Willkommen\nHier finden Sie das Wichtigste zum Kurs FS2025.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#ilias",
    "href": "index.html#ilias",
    "title": "Neurowissenschaft Computerlab",
    "section": "Ilias",
    "text": "Ilias\nUnter diesen Links finden Sie die Iliasgruppen:\nILIAS-Gruppe Freitag 08.15-10.00 👉 468703-FS2025-0\nILIAS-Gruppe Freitag 10.15-12.00 👉 468703-FS2025-1",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#kursvoraussetzungen",
    "href": "index.html#kursvoraussetzungen",
    "title": "Neurowissenschaft Computerlab",
    "section": "Kursvoraussetzungen",
    "text": "Kursvoraussetzungen\nWir werden mit der Programmiersprache R und zu einem kleinen Teil mit Python arbeiten. Sie benötigen in der Veranstaltung deshalb einen eigenen Laptop (Tablets sind nicht geeignet!) mit ca. 20 GB freiem Speicherplatz und mit einer installierten (aktuellen) Version von R und RStudio (Link zum Download von R und RStudio).\nR Kenntnisse (gemäss Statistik I-IV in Psychologie) werden vorausgesetzt. Zur Auffrischung dient folgender Link (https://methodenlehre.github.io/einfuehrung-in-R/) oder für Fortgeschrittene die Bücher „Advanced R” und „R for Data Scientists” von Hadley Wickham.\nZusätzlich dient Übung 2 zur Auffrischung der Vorkenntnisse auf die im späteren Verlauf des Kurses aufgebaut wird.\nBitte installieren Sie bis zum 2. Kurstermine folgende Software:\n\nNeue Versionen von R und RStudio\nPsychoPy\nJASP",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#leistungsnachweise",
    "href": "index.html#leistungsnachweise",
    "title": "Neurowissenschaft Computerlab",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nDer Kurs entspricht 5 ETCS. Dafür müssen 3 Bereiche erfüllt werden:\n\nAnwesenheit im Kurs\nbestandene Übungen\nbestandenes Abschlussquiz\n\nAlle Leistungsnachweise werden in den Veranstaltungen angekündigt. Die Termine für die Leistungsnachweise finden Sie unter Termine der Leistungsnachweise.\n\nAnwesenheit\nDie Anwesenheit im Kurs wird vorausgesetzt, an 2 Terminen darf gefehlt werden.\nDas Online-Skript erlaubt das Nacharbeiten des wichtigsten Stoffes im Eigenstudium, wir können jedoch nicht für die Vollständigkeit garantieren. Hilfestellung beim Programmieren und Verstehen der Inhalte erhalten Sie während der Kurszeiten. Aus zeitlichen Gründen können wir keine ausführliche Beantwortung von Fragen zum Kursinhalt per E-Mail anbieten. Bitte stellen Sie Ihre Fragen in der Veranstaltung - auch Ihre Mitstudierenden werden davon profitieren, oft haben mehrere Personen dieselbe Frage.\n\n\nÜbungen\nEs gibt fünf Übungen.\n\nDie Übungen werden auf der Website aufgeschaltet und in der Veranstaltung erklärt.\nDie Ergebnisse der Übungen müssen in den entsprechenden Ordner auf ILIAS hochgeladen werden. Je nach Umfang der Übung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens zwei Wochen betragen.\nAusser Übung 2 müssen alle Übungen abgegeben und als bestanden bewertet werden. Wird eine ungenügende Übungen abgegeben erhalten Sie eine zweite Frist für die Abgabe oder einen Zusatzauftrag.\nÜbungen dürfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen müssen die Übung abgeben. Damit wir sehen, welche Übungsabgaben zusammengehören: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_3_GW_EW.R\nAlle Übungen müssen bestanden werden. Ob die Übung bestanden wurde, sehen Sie auf Ilias. Bei Nicht-Bestehen muss die Übung nochmals abgeben werden oder eine Zusatzaufgabe erledigt werden.\n\nVerwenden von LLMs für Übungen: Sie dürfen LLMs gerne als Tool nutzen, um die Übung zu bearbeiten. Es liegt in Ihrer Verantwortung, den Output von LLMs vor der Abgabe gründlich zu prüfen. Halten Sie sich an Folgendes:\n\nLLMs geben Code aus. Aber sogar wenn dieser problemlos ausgeführt werden kann, muss genau überprüft werden, ob der Code das Richtige tut. Dieses Überprüfen kann unter Umständen genau so lange dauern, wie das Lesen und Verstehen der Dokumentation.\nDas Überprüfen von Code erfordert gewisse Grundkenntnisse. Das Verwenden von LLMs ersetzt kein Lernaufwand.1\nDas direkte Verwenden von Code ohne kompetente Prüfung ist in der Forschung unethisch!\nEs dürfen keine sensiblen Daten eingegeben werden bzw. auch keine Datensätze die nicht öffentlich sind.\n\n\n\nAbschlussquiz\nDas Abschlussquiz wird gegen Ende des Semesters auf Ilias freigeschaltet und dient dazu das Gelernte zu prüfen und so Feedback zu geben, wie gut man die Lerninhalte erinnert. Sie haben die Möglichkeit das Quiz mehrmals zu wiederholen.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#datacamp",
    "href": "index.html#datacamp",
    "title": "Neurowissenschaft Computerlab",
    "section": "DataCamp",
    "text": "DataCamp\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL auf unterschiedlichen Niveaus an; sowohl für Anfänger als auch für Fortgeschrittene gibt es ein breites Angebot.\nIm Rahmen dieser Lehrveranstaltung können alle Teilnehmenden sich unter folgendem Link mit ihrer Uni Bern E-Mail Adresse (*students.unibe.ch) registrieren und die Kurse kostenlos nutzen:\n👉🏼 Einladungslink DataCamp Registration (zuerst muss ein DataCamp Zugang erstellt werden.)\nWir werden jeweils die empfohlenen Datacamp Kurse verlinken. Sie haben mit dem Link Zugriff auf alle Datacamp-Kurse bis Ende FS25.\n👉🏼 Zur Auffrischung von R-Kenntnissen eignet sich dieser Kurs: Introduction to R\n👉🏼 Als Einführung in Python eignet sich folgender Kurs: Introduction to Python",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "↩︎",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "forschungsprozess.html",
    "href": "forschungsprozess.html",
    "title": "1  Complab im Forschungsprozess",
    "section": "",
    "text": "Der Begriff Computerlab wird für unsere Veranstaltung genutzt, um sich auf die vielfältige Arbeit, die Neurowissenschaftler:innen an Computern oder anderen elektronischen Geräten durchführen, um neurowissenschaftliche Forschungsfragen zu beantworten. Jede Forschungsarbeit hat mehrere Phasen, welche ganz unterschiedliche Anforderungen stellen und eigenen Skills benötigen.\nIn jeder Phase des Forschungsprozesses werden verschiedenste\n\nelektronische Geräte (Computer, Eyetracker, EEG-Geräte, MRTs, etc.)\nProgramme (PsychoPy, E-Prime, etc.)\nProgrammiersprachen (R, MATLAB, Python, Java, C++, Ruby, Julia, etc.)\nspeicherbare Ergebnisse: Skripte, Datensätze, Stimuli, Grafiken…\netc.\n\nverwendet.\n\n\n\nPhasen des Forschungsprozesses\n\n\nIn diesem Kurs werden wir einige Stationen dieses Forschungsprozesses gemeinsam bearbeiten, um Einblick in das neurowissenschaftliche Arbeiten zu erhalten.\n\n\n\n\n\n\nHands-on: Complab im Forschungsprozess\n\n\n\n\nWählen Sie in 2-4er Gruppen eines der untenstehenden Paper (Open Access) aus:\n\n\nQuon et al. (2021): Quon et al. (2021): Musical components important for the Mozart K448 effect in epilepsy\nRichter et al. (2021): Richter et al. (2021): Listening to speech with a guinea pig-to-human brain-to-brain interface\nZhang et al. (2021): Zhang et al. (2021): Longitudinal effects of meditation on brain resting-state functional connectivity\n\n\nSchreiben Sie zuerst in einem Satz oben auf Ihr Blatt auf, was die Fragestellung des Papers ist.\nGehen Sie das Paper durch und schreiben Sie heraus, wo überall im “Computerlab” gearbeitet wurde, bei dieser Forschungsarbeit. (Sie können auch Vermutungen anstellen.)\n\nz.B. Datenanalyse -&gt; R/RStudio\n[15 Minuten]\n\n\n\n\n\n\nQuon, Robert J., Michael A. Casey, Edward J. Camp, Stephen Meisenhelter, Sarah A. Steimel, Yinchen Song, Markus E. Testorf, et al. 2021. “Musical Components Important for the Mozart K448 Effect in Epilepsy.” Scientific Reports 11 (1): 16490. https://doi.org/10.1038/s41598-021-95922-7.\n\n\nRichter, Claus-Peter, Petrina La Faire, Xiaodong Tan, Pamela Fiebig, David M. Landsberger, and Alan G. Micco. 2021. “Listening to Speech with a Guinea Pig-to-Human Brain-to-Brain Interface.” Scientific Reports 11 (1): 12231. https://doi.org/10.1038/s41598-021-90823-1.\n\n\nZhang, Zongpai, Wen-Ming Luh, Wenna Duan, Grace D. Zhou, George Weinschenk, Adam K. Anderson, and Weiying Dai. 2021. “Longitudinal Effects of Meditation on Brain Resting-State Functional Connectivity.” Scientific Reports 11 (1): 11361. https://doi.org/10.1038/s41598-021-90729-y.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Complab im Forschungsprozess</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html",
    "href": "voraussetzungen.html",
    "title": "2  Voraussetzungen der Forschung",
    "section": "",
    "text": "3 Marr’s levels of explanation\nDavid Marr hat drei Ebenen vorgeschlagen, um zu klären, wie komplexe Systeme, insbesondere kognitive Systeme wie das Gehirn, Informationen verarbeiten. Die Idee ist, dass jedes informationsverarbeitende System (biologisch oder künstlich) auf diesen drei verschiedenen Ebenen analysiert werden kann. Zusammen zeigen sie, was das System tut, wie es das tut und wie es physikalisch realisiert ist.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html#levels-of-analyses",
    "href": "voraussetzungen.html#levels-of-analyses",
    "title": "2  Voraussetzungen der Forschung",
    "section": "3.1 3 Levels of analyses",
    "text": "3.1 3 Levels of analyses\n\n3.1.1 Computational level (what and why)\n\nWas macht das System?\nEs definiert das Ziel oder den Zweck des Prozesses. Diese Ebene erklärt, welches Problem das System löst und warum es wichtig ist.\nBeispiel aus dem Sehen: Das System muss die 3D-Welt aus dem 2D-Input der Retina rekonstruieren. Warum? Weil das Verständnis der räumlichen Umgebung für das Überleben wichtig ist.\nWas es zeigt: Das „große Ganze“ - die Funktion, die das System erfüllt.\n\n\n\n3.1.2 Algorithmic level (how)\n\nWie erreicht das System das Ziel?\nEs geht um die spezifischen Darstellungen und Verfahren, die zur Erreichung des Ziels eingesetzt werden. Betrachten Sie dies als die „Anweisungen“ oder „Software“ des Systems.\nBeispiel aus dem Sehen: Das Gehirn erkennt Kanten, kombiniert Merkmale und identifiziert Objekte mithilfe von Algorithmen wie Merkmalsextraktion und Mustervergleich.\nWas es zeigt: Den Prozess - die schrittweise Umwandlung vom Input zum Output.\n\n\n\n3.1.3 Implementational level\n\nWie wird der Prozess physisch umgesetzt?\nDiese Ebene beschreibt die Hardware oder biologischen Strukturen, die die Berechnungen ausführen. Beim Menschen sind dies Neuronen, Gehirnbereiche und neuronale Schaltkreise.\nBeispiel aus dem Sehen: Die Randerkennung erfolgt in der Retina und in frühen visuellen Bereichen wie dem primären visuellen Kortex (V1). Bestimmte Neuronen feuern bei bestimmten Ausrichtungen des Lichts.\nWas es zeigt: Die materielle Basis - die Mechanismen, die es möglich machen.\n\nKognitive Neurowissenschaft kann auf allen drei Ebenen tätig sein. Beispiel aus der Gesichtserkennung:\n\nDas Gehirn muss Gesichter schnell und genau erkennen, weil dies für die soziale Interaktion evolutionär wichtig ist.\nDie Gesichtserkennung kann die Extraktion von Merkmalen (Augen, Nase, Mund) und eine ganzheitliche Verarbeitung umfassen.\nDas fusiforme Gesichtsareal (FFA) spielt eine Schlüsselrolle bei der Wahrnehmung von Gesichtern.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "voraussetzungen.html#grundlegendes-postulat",
    "href": "voraussetzungen.html#grundlegendes-postulat",
    "title": "2  Voraussetzungen der Forschung",
    "section": "3.2 Grundlegendes Postulat:",
    "text": "3.2 Grundlegendes Postulat:\nMentale Prozesse ergeben sich aus der Gehirnaktivität.\nGanz wichtig ist: Korrelation ≠ Kausalität. Neuroimaging-Methoden zeigen nur Korrelationen und keine Kausalität.",
    "crumbs": [
      "Neurowissenschaftliches Forschen",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Voraussetzungen der Forschung</span>"
    ]
  },
  {
    "objectID": "experiments.html",
    "href": "experiments.html",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "",
    "text": "3.1 Forschungsbereiche der Neurowissenschaften\nIn der Neurowissenschaft wird mit naturwissenschaftlichem Schwerpunkt der Aufbau und die Funktionen des Nervensystems untersucht. Neurowissenschaften sind ein sehr weites Forschungsbereich in dem unterschiedlichste und zahlreiche Themen bearbeitet werden. Die Forschungsbereiche reichen von Affektiven Neurowissenschaften, die den Zusammenhang von Gehirn und Emotionen untersuchen, über Neurochemistry, die sich u.a. mit Neurotransmittern und psychopharmakologischen Themen befasst, bis hin zu Neuroengineering, welches neuronale Systeme zu verstehen, ersetzen, reparieren oder verbessern versucht.1\nSo vielfältig, wie die Forschungsbereiche sind auch die experimentellen Ansätze und Methoden. Neurowissenschaftliche Forschung wird oft an Organismen und Tieren durchgeführt (z.B. Einzelzellableitungen in Affen). In diesem Kurs fokussieren wir uns auf neurowissenschaftliche Forschung am Menschen im Bereich der kognitiven Neurowissenschaft und Neuropsychologie. Das bedeutet, wir besprechen die Datenerhebung und -verarbeitung in verhaltenswissenschaftlichen Experimenten (teilweise auch im Zusammenhang mit bildgebenden Verfahren), welche Gehirnprozesse von Menschen untersuchen.\nKognitive Neurowissenschaften sind eng verknüpft mit Forschungsbereichen, wie beispielsweise der Psychologie, der Linguistik, künstlicher Intelligenz, Philosophie und Anthropologie:",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#forschungsbereiche-der-neurowissenschaften",
    "href": "experiments.html#forschungsbereiche-der-neurowissenschaften",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "",
    "text": "Das Nebenfach Neurowissenschaften an der Universität Bern fokussiert auf Aspekte der Neurowissenschaft, die für das Gebiet der Psychologie relevant sind, wie z. B. die neuronalen Grundlagen von Kognition, Emotion oder Sozialverhalten.\n\n\n\n\n\nGrafik von O. Guest (2024) modifiziert nach dem Paper von Van Rooij et al. (2023)\n\n\n\nWer sich für die Bedeutung von AI im Zusammenhang mit den Neurowissenschaften interessiert findet im Paper von Van Rooij et al. (2023) eine kritische Auseinandersetzung mit Chancen und Herausforderungen dieser Verknüpfung.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#besondere-herausforderungen-von-experimenten-in-den-verhaltenswissenschaften-kognitiven-neurowissenschaften",
    "href": "experiments.html#besondere-herausforderungen-von-experimenten-in-den-verhaltenswissenschaften-kognitiven-neurowissenschaften",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "3.2 Besondere Herausforderungen von Experimenten in den Verhaltenswissenschaften / kognitiven Neurowissenschaften",
    "text": "3.2 Besondere Herausforderungen von Experimenten in den Verhaltenswissenschaften / kognitiven Neurowissenschaften\nDas Erstellen und Durchführen neurowissenschaftlicher Experimente bringt viele Herausforderungen mit sich.\n\n3.2.1 Passung: Experimentalparadigmen passend zur Fragestellung\nNeurowissenschaftliche Experimente müssen exakt auf die Fragestellung zugeschnitten werden um aussagekräftige Daten zu liefern. Oft muss ein neues Paradigma erstellt werden, d.h. Forschende können kein schon bestehendes Experiment nutzen, sondern untersuchen einen Aspekt eines neuronalen Prozesses mit einer neuen Methode, einer neuen Fragestellung oder einem neuen Ansatz. Deshalb programmieren die meisten Forschenden ihre Experimentalparadigmen selbst. So können beispielsweise Instruktionen oder verwendete Stimuli, deren Grösse und Anzeigedauer präzise definiert werden. Dies erfordert breite Kenntnisse im Programmieren, der zu verwendenden Technik, wie auch der Gehirnprozesse.\n\n\n3.2.2 Präzision: Hohe räumliche und zeitliche Auflösung\nEine grosse Schwierigkeit neurowissenschaftlicher Experimente ist oft, dass eine präzise Kontrolle von räumlichen und zeitliche Eigenschaften der Experimente nötig ist um sinnvolle Daten zu erhalten. Visuelle Stimuli müssen z.B. sehr genau und immer gleich präsentiert werden können. Die zeitliche Auflösung ist gerade bei EEG Experimenten von enormer Bedeutung, da EEG eine sehr hohe zeitliche Auflösung hat. Räumliche Auflösung kann bedeuten, dass sehr präzise visuelle Darbietung möglich sein muss, sowie dass die Versuchsperson sich im Setup nicht bewegen darf, weil dies die Distanzen verschiebt (z.B. im MRT, oder der Abstand zum Bildschirm beim Eyetracking).\n\n\n3.2.3 Synchronisation: Mehrere Datenspuren\nNeurowissenschaftliche Experimente beinhalten oft die Datenerhebung auf mehreren Ebenen, z.B. wird gleichzeitig Hirnaktivität und das Drücken von Antwortbuttons aufgenommen. Das bedeutet, dass Bildschirm, MRT/EEG/Eyetracking/etc., sowie die Antwort zeitlich koregistriert/synchronisiert werden müssen, um die Daten im Nachhinein auswerten zu können. Technisch ist das oft mit grossem Aufwand verbunden und benötigt einiges an Pilotierung.\n\n\n3.2.4 Komplexität: Zu untersuchender Prozess und Störprozesse\nOft soll ein ganz spezifischer Prozess untersucht werden, aber das ist eine sehr komplexe Aufgabe, weil im menschlichen Gehirn gleichzeitig sehr viele verschiedene Prozesse ablaufen, kein Hirnareal hat nur eine einzige Aufgabe und aus ethischen Gründen ist das “Ausschalten” von Störfaktoren nicht immer möglich. Was kann man tun?\nEin Weg den Prozess sichtbar zu machen ist es zum Beispiel einen Kontrast zu rechnen, dies wird beispielsweise bei EEG und fMRI Experimenten, aber auch bei Reaktionszeitexperimenten sehr oft gemacht. Hierfür erhebt man Daten in einer Test-Bedingung in der der Prozess abgerufen wird und eine Kontroll-Bedingung, welche als “Baseline” dient. Die Baseline enthält alle “nicht interessierenden” Prozesse, die in der Test-Bedingung vorhanden sind. Durch das Vergleichen der Test- und Kontrollbedingung erhält man einen Kontrast: Also das was den interessierenden Prozess ausmacht!\nSie müssen sich beim Erstellen eines Experiments also nicht nur Gedanken dazu machen, was Sie interessiert - sondern genau so auch darüber was Sie nicht interessiert. In der Theorie tönt das einfach, in der Praxis ist das oft recht kniffelig.\n\n\n3.2.5 Ressourcenintensive Datenerhebung: Teuer und anspruchsvoll\nBildgebende Verfahren, benötigen zum Teil extrem teure Geräte, wie z.B. fMRI, und bedeuten oft hohen Aufwand, z.B. das Kleben der Elektroden beim EEG. Bei der Untersuchung von ganz bestimmten Patientengruppen hat man zudem oft nicht sehr viele Personen zur Verfügung die den Einschlusskriterien entsprechen. Oft müssen Personen auch aus dem Experiment ausgeschlossen werden, weil sie z.B. Auffälligkeiten im MRI zeigen, die nichts mit dem zu untersuchenden Prozess zu tun hat oder sie brechen während der Untersuchung ab. Gerade bei der Untersuchung klinischer Aspekte stellen sich oft Schwierigkeiten, wie beispielsweise fehlende Motivation oder Compliance von Patient:innen. Daher können oft keine sehr grossen Stichproben erhoben werden, was im Gegenzug besonders präzise Experimente erfordert.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#wichtige-elemente-von-experimenten",
    "href": "experiments.html#wichtige-elemente-von-experimenten",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "3.3 Wichtige Elemente von Experimenten",
    "text": "3.3 Wichtige Elemente von Experimenten\nBeim Programmieren von Experimenten lohnt es sich, sich zuerst darüber im klaren zu sein, welche Bausteine das geplante Experiment hat. Im Folgenden werden einige typische Elemente eines Verhaltensexperiments beschrieben. Oft kommen hier natürlich noch Stimulations- oder Aufnahmemethoden hinzu.\n\n3.3.1 Begrüssung und Einverständniserklärung\nHier wird die Versuchsperson begrüsst, wird über das Experiment aufgeklärt und gibt (wenn nicht vorher auf Papier schon geschehen) ihre Einverständnis zur Teilnahme am Experiment. Dies wird je nach Ethikkommission und Ethikantrag unterschiedlich gehandhabt. Wichtige Informationen sind hierbei, dass die Versuchsperson weiss worauf sie sich einlässt (Ist zum Beispiel Hirnstimulation/fMRI/etc. geplant? Wie lange dauert das Experiment ungefähr? Was soll sie tun, wenn sie abbrechen möchte?). Die Schwierigkeit ist oft, genügend Information zu geben aber die Hypothese nicht zu verraten.\n\n\n3.3.2 Instruktion\nDie Instruktion wird oft schriftlich gegeben, um diese zwischen den Versuchspersonen konstant zu halten. Es ist teilweise herausfordernd, einen Task so genau zu erklären, dass er verständlich ist, aber die Erklärung auch kurz genug zu halten, dass die Instruktion auch gelesen wird. Oft werden Übungstrials verwendet um die Instruktion zu verdeutlichen.\n\n\n3.3.3 Stimuli\nUnter Stimuli werden die gezeigten Elemente verstanden, die den Task ausmachen. Es können Töne, Bilder, Wörter, etc. als Stimuli verwendet werden.\n\n\n\n\n\n\nHands-on: Stimuli\n\n\n\nWelche Stimuli aus neurowissenschaftlichen Experimenten kennen Sie?\nTauschen Sie sich mit Ihren Mitstudierenden aus und schreiben/zeichnen Sie ein paar Beispiele vorne an die Tafel.\n[~5 Minuten]\n\n\n\n\n3.3.4 Trial\nEin Trial beschreibt ein sich wiederholender Vorgang in dem der Stimulus gezeigt wird und z.B. von der Versuchsperson eine Antwort erwartet wird. Ein Trial wird oft sehr viele Male wiederholt. Die Stimuli können zwischen den Trials variieren oder gleich bleiben. Das Timing der Trials kann konstant sein (ein Stimulus wird bspw. immer gleich lang gezeigt) oder variiert werden (unterschiedliche Anzeigedauer).\nZwischen den Trials wird ein Inter-Trial-Interval (ITI) festgelegt. Dies wird z.B. bei fMRI Experimenten dann variiert, damit (je nach Repetition Time/TR) nicht immer in derselben Schicht aufgenommen wird bei Stimuluspräsentation.\nWährend einem Trial wird die Antwort / Response der Versuchsperson aufgenommen. Bei der Aufnahme von Reaktiosnzeiten muss festgelegt werden, wann der Trial oder die Stimuluspräsentation beginnt und mit welcher Handlung sie endet. Es kann bestimmt werden, welche Antworten zulässig sind (bspw. nur bestimmte Tasten) und was passiert wenn eine richtige oder falsche Antwort gegeben wird: Gibt es z.B. ein Feedback bei falschen Antworten?\n\n\n3.3.5 Run / Block\nEin Run/ein Block bezeichnet eine Einheit mit mehreren Trials. Oft werden Bedingungen z.B. zwischen den Runs randomisiert. Zwischen den Runs sind Pausen möglich, damit sich die Versuchsperson erholen kann. Oft wird vor dem Experimentstart ein “Übungsblock” durchgeführt, um sich sicher zu sein, dass die Versuchspersonen die Aufgabe und Instruktion verstanden haben.\n\n\n3.3.6 Debriefing und Verabschiedung\nIm Debriefing wird der Versuchsperson erklärt, um was es im Experiment gegangen ist, welche Hypothesen untersucht wurden und eine eventuelle Coverstory aufgedeckt. Oft werden Personen vor dem Debriefing nach der getesteten Hypothese gefragt, um zu schauen, ob sie diese erraten hatten. Das gibt Aufschluss darüber wie sehr das Experiment dadurch verzerrt sein könnte, dass die Versuchspersonen Bescheid wissen. Wichtig ist es auch den Versuchspersonen zum Schluss zu danken.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#vorgehen-experiment-programmieren",
    "href": "experiments.html#vorgehen-experiment-programmieren",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "3.4 Vorgehen Experiment programmieren",
    "text": "3.4 Vorgehen Experiment programmieren\nWichtige Schritte beim Programmieren von Experimenten sind folgende (nicht unbedingt in dieser Reihenfolge, das kommt auf das Experiment an):\n\nTask auswählen\nStimuli auswählen und generieren\nTrial erstellen (Fixationskreuz? Stimulus? Antwortmöglichkeiten? Feedback? Masking?)\nTiming festlegen: Dauer Stimuluspräsentation? ITIs (Inter-Trial-Intervals)? Antwortfenster?\nDesign: Anzahl Bedingungen und Trials bestimmen (Power bedenken), within oder between Design?\nAblauf des Experiments festlegen: Gesamtdauer? Pausen nötig?\nInstruktion: klare Anweisungen, Coverstory\nEinbindung von allen technischen Geräten (z.B. EEG Recorder, MRT, Brainstimulation-Devices, Eyetracking) und Synchronisation\n\n\n3.4.1 Flowcharts\nFlowcharts, auf Deutsch Flussdiagramme, eignen sich um Prozesse zu beschreiben. Beim Programmieren kann man damit gut darstellen, was ein Programm machen soll.\n\nBei der Planung und dem Erstellen eines Experiments ist es ebenfalls hilfreich eine Flowchart zu erstellen. In einer Experiment-Flowchart sind die Elemente eines Experimentes in Boxen eingezeichnet und mit Pfeilen verbunden um sie zeitlich einzuordnen. Timing-Informationen können unter oder neben den Boxen festgehalten werden. Die Anzahl Repetitionen wird oft neben den Pfeilen eingefügt. Hilfreich ist auch zu kennzeichnen, wo welche Daten erhoben werden (button presses, EEG, etc.).\n\nWir werden in diesem Kurs immer wieder darauf eingehen, wie man ein Experiment möglichst gut planen kann um aussagekräftige Daten zu erhalten. Hier gibt es viele Möglichkeiten wie Pilotierung, Datensimulation und die adäquate Wahl der statistischen Verfahren in Bezug auf die Fragestellung.\n\nEine Flowchart eignet sich ebenfalls sehr gut, um in einem Paper/einer Arbeit darzustellen, wie der Ablauf des Experiments war.\n\n\n\n\n\n\nHands-on: Flowcharts\n\n\n\nSuchen Sie zusammen zu einem Thema Ihrer Wahl eine Flowchart.\n\nIdentifizieren Sie alle Elemente des Experiments, die Sie finden.\nGibt es Informationen zu den Stimuli?\nGibt es Informationen zum Timing?\nGibt es Informationen zur Datenerhebung?\nFehlt etwas? Wie würden Sie dies ergänzen?\n\n[~10 Minuten]\n\n\n\n\n\n\nShepherd, Gordon M. 1988. Neurobiology, 2nd Ed. Neurobiology, 2nd Ed. New York, NY, US: Oxford University Press.\n\n\nVan Rooij, Iris, Olivia Guest, Federico G Adolfi, Ronald De Haan, Antonina Kolokolova, and Patricia Rich. 2023. “Reclaiming AI as a Theoretical Tool for Cognitive Science.” Preprint. PsyArXiv. https://doi.org/10.31234/osf.io/4cbuv.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "experiments.html#footnotes",
    "href": "experiments.html#footnotes",
    "title": "3  Neurowissenschaftliche Experimente",
    "section": "",
    "text": "Forschungsbereiche der Neurowissenschaften: ↩︎",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Neurowissenschaftliche Experimente</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html",
    "href": "psychopy_experiments.html",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "",
    "text": "4.1 Umgebung",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#umgebung",
    "href": "psychopy_experiments.html#umgebung",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "",
    "text": "4.1.1 Experiment-File erstellen und abspeichern\n\nÖffnen Sie PsychoPy und speichern Sie in einem dafür erstellten Ordner (z.B. psychopy_experiment) das Experiment-File ab (z.B. unter experiment_stroop-task).\n\n\n\n4.1.2 Builder (GUI) und Coder?\nExperimente können in PsychoPy mit dem Builder (in einem GUI) erstellt werden, der Python Code wird so automatisch für Sie generiert. Sie können sich diesen Code auch anschauen und verändern. Leider können Sie sobald Sie den Code verändert haben, diese Änderungen nicht zurück in den Builder übertragen. Im Builder-Modus können Sie aber Codestücke einfügen um einzelne Teile des Experiments in Python (oder anderen Programmiersprachen) zu programmieren und dennoch im Builder weiterarbeiten zu können.\n\nFalls Sie planen ein Online-Experiment durchzuführen, eignet sich der Builder besonders, da die Experimente direkt online durchgeführt werden können.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#experiment-erstellen",
    "href": "psychopy_experiments.html#experiment-erstellen",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "4.2 Experiment erstellen",
    "text": "4.2 Experiment erstellen\n\n4.2.1 Stimuli\nIn PsychoPy finden Sie schon vorprogrammierte Stimulus Elemente, wie Gratings oder Rating Scales und können Texte, geometrische Figuren, Bilder und Filme einfügen. Auch komplexere Stimuluselemente wie Random Dots können sehr einfach konfiguriert werden ohne dass sie von Grund auf neu programmiert werden müssen.\n\nErstellen Sie einen Stimulus. Beachten Sie folgende Aspekte:\n\nFarbe\nGrösse\nweitere Eigenschaften, wie Bedingung/Kongruenz?\nTiming (Stimulusdauer, Stimulusende)\n\nNotieren Sie, welche Eigenschaften des Stimulus sich über die Trials hinweg verändern sollte. Dies können auch mehrere Eigenschaften sein. Diese Liste benötigen Sie später.\n\n\n\n4.2.2 Trial\n\nErgänzen Sie alle Elemente, die für einen vollständigen Trial notwendig sind:\n\nAntwort der Versuchsperson / Response (siehe auch 4.2.4)\nInter-Trial-Intervall (ITI): kann vor oder nach dem Stimulus eingefügt werden. (Die Zeit des ITI wird oft variiert. Dies müsste also auch auf die Liste oben)\nFixationskreuz?\nMask?\nFeedback?\n\n\n\n\n4.2.3 Trialschleife\nSie müssen nicht alle Trials (oder in PsychoPy: Routines) des Experiments einzeln programmieren, sondern können diese wiederholen, in dem Sie eine Trial-Schleife (loop) um den Trial herum erstellen.\n\nErstellen Sie einen loopindem Sie im Feld Flow auf Insert loop klicken.\n\nMit loopType können Sie steuern, die Bedingungen randomisiert/gemischt oder sequentiell/der Reihe nach angezeigt werden sollen.\nMit nReps können Sie angeben, wie oft jeder Stimulus wiederholt werden soll. Haben Sie also einen Stimulus mit zwei zu varierenden Eigenschaften , welche je 3 Stufen haben (also 9 Zeilen im conditions-File und nReps= 2), ergibt das 18 Trials.\n\n\nMittels diesen Schleifen können die Bedingungen implementiert werden z.B. dass sich der Stimulus bei jedem Trial verändert. Dies kann mit einer conditions-Datei spezifiziert werden, idealerweise im .csv oder .xlsx-Format.\n\nDie Endung .csv bedeutet, dass die Daten als comma separated values abgespeichert werden, also durch ein Komma getrennt. Dieses Dateiformat eignet sich besser als .xlsx, weil es mit vielen Programmen kompatibel und gut einlesbar ist.\n\nBeispielsweise wollen wir drei verschiedene Worte anzeigen (dog, cat und rabbit) und dieses Wort unterschiedlich lange anzeigen (Dauer: 1, 10 und 100 Frames). Die Versuchspersonen sollen dann den Anfangsbuchstaben des Wortes drücken, also d für dog, c für cat und r für rabbit.\n\nUm die Bedingungen (in unserem Fall: die sich verändernden Stimuluseigenschaften) zu definieren, erstellen wir eine .csvoder .xlsx-Datei (z.B. in Excel/Notepad/etc.) mit dem Namen conditions und speichern dieses im selben Ordner wie das Experiment.\n\nFügen Sie für jedes sich verändernde Element einen Variablennamen und die entsprechenden Werte ein (dies sind die Eigenschaften, die Sie sich bei Punkt 4.2.1 notiert haben). Die Variablennamen schreiben wir immer in die oberste Zeile der Datei.\nWenn wir z.B. einen Text anzeigen möchten, schreiben wir in die erste Zeile word und duration.\nIn die Spalte unter die Variablennamen schreiben wir die Werte.\nAls Beispiel könnten die Worte die wir anzeigen lassen wollen cat, dog und rabbit lauten. Dann stehen in der Spalte word, diese 3 Wörter unter dem Variablennamen. Unter dem Variablennamen duration geben wir die Anzahl Frames ein, also 1, 10 und 100. Wir wollen jedes Wort mit jeder Dauer kombinieren. Das ergibt 9 Zeilen.\nFügen Sie in jeder Zeile unter dem Variablennamen corrAns die jeweils korrekte Antwort ein.\nFügen Sie, falls vorhanden, in jeder Zeile weitere wichtige Information zum Stimulus ein.\nIm Beispiel möchten Sie z.B. später fleischfressende mit pflanzenfressenden Tieren vergleichen, deshalb eine Spalte meat. Dies verändert im Experiment nichts, dient aber am Schluss zur Auswertung, weil diese Variable auch immer in den Datensatz geschrieben wird.\n\n\nFügen Sie nun im Loop-Fenster die conditions-Datei ein.\n\n\n\n\n\n\n\n\nTipp\n\n\n\nJede Zeile in der conditions-Datei unterhalb des Variablennamens entspricht einer Bedingung (condition).\nSetzen Sie nReps auf 1 während Sie das Experiment erstellen, so sparen Sie Zeit.\n\n\nIm PsychoPy können Sie Variablen mit einem vorangestellten $einfügen.\n\nÖffnen Sie nun wieder das Stimulusfenster und passen Sie dort die Stimuluseigenschaften an. Anstatt von hard-coded values (also einmalig, fix festgelegten Werten) geben wir nun einen Variablennamen ein. Der Stimulus darf nicht auf constant gesetzt sein, sonst kann er sich nicht Trial für Trial verändern, setzen Sie ihn deshalb unbedingt auf set every repeat.\nIn unserem Beispiel fügen wir bei text die Laufvariable (verändernde Eigenschaft) ein: $word. Die Anzeigedauer des Textes soll $duration in Frames sein.\n\n\n\nLassen Sie das Experiment laufen und kontrollieren Sie, ob alles funktioniert hat.\n\n\n\n\n\n\n\nTipp\n\n\n\nMit dieser Methode können Sie auch Instruktionen, ITIs, etc. variieren lassen.\n\n\n\n\n4.2.4 Antworten aufnehmen\nIn PsychoPy muss definiert werden, wie die Antwort der Versuchsperson aufgenommen wird. Dies kann mit der Maus, der Tastatur oder anderen Devices umgesetzt werden. Die Möglichkeiten sehen Sie unter Responses.\n\nFügen Sie eine Antwortkomponente hinzu und benennen Sie diese sinnvoll.\nIn unserem Beispiel möchten wir, dass die Versuchsperson mittels Keyboard antwortet.\n\nMit Force end of Routine können Sie einstellen, ob eine Antwort den Trial beendet und mit dem nächsten fortfährt.\nDer Namen der Antwortkomponente wird später im Datensatz als Variable zu finden sein.\nWerden in einer Antwortkomponente namens key_resp mittels Tastendruck Antwort und Response Time aufgenommen, heissen die Variablen dann key_resp.keys(gedrückte Taste) und key_resp.rt (Antwortdauer).\nEntscheiden Sie, ob PsychoPy überprüfen soll, ob die richtige Antwort gegeben wurde.\nWenn Sie dies möchten, gleicht PsychoPy in unserem Beispiel die gegebene Antwort (key_resp.keys) mit der dafür eingegebenen Variable (hier corrAns) ab. Stimmen diese überein, fügt es in die Variable key_resp.corr 1 ein, wenn nicht 0).\nMit first key definieren Sie, dass der erste Tastendruck zählt.\n\n\n\n\n\n\n4.2.5 Weitere Elemente\nIn PsychoPy GUI wird Ihnen im Fenster Floweine Art Flowchart angezeigt. Hier sehen Sie, welche Elemente Ihr aktuelles Experiment enthält.\n\nFügen Sie nun alle weiteren Elemente, die Sie zu Beginn auf Ihrer Flowchart eingezeichnet hatten, z.B.\n\nBegrüssung\nEinverständnis\nInstruktion\nDebriefing, Verabschiedung\n\nLassen Sie das Experiment laufen und kontrollieren Sie, ob alles funktioniert hat.\n\n\n\n\n\n\n\nTipp\n\n\n\nBeim Programmieren lohnt es sich oft, die kleinen Schritte zwischenzutesten, weil es dann einfacher ist herauszufinden, wo genau der Fehler passiert ist.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#datenspeicherung",
    "href": "psychopy_experiments.html#datenspeicherung",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "4.3 Datenspeicherung",
    "text": "4.3 Datenspeicherung\nWenn man die default-Einstellungen nicht ändert, speichert PsychoPy die Daten automatisch in einer trial-by-trial .csv-Datei. Das bedeutet, dass jeder Trial 1 Zeile generiert. Die .csv-Datei erhält einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es möglich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die .csv-Dateien werden in einem Ordner mit dem Name data abgelegt.\nIn den Fenstern der Elemente kann jeweils angegeben werden, was alles gespeichert werden soll.\n\n\n\n\n\n\nTipp\n\n\n\nBei der Wahl vom Datenfile-Namen empfiehlt es sich immer Datum und Uhrzeit anzuhängen. Dies verhindert, dass Daten überschrieben werden, wenn z.B. eine Versuchspersonen-ID falsch eingetippt oder doppelt vergeben wird.\n\n\nDas oben verwendete Beispielsexperiment ergibt folgenden Datensatz:\n\nSie sehen die Infos aus der conditions-Datei (gelb), die Zählerinformationen der Loops (hellgrau), die Timinginformationen (dunkelgrau), die Antwortinformationen (blau) und die Experimentinformationen (grün).",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#test-pilotierung",
    "href": "psychopy_experiments.html#test-pilotierung",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "4.4 Test / Pilotierung",
    "text": "4.4 Test / Pilotierung\n\nFühren Sie das Experiment aus und schauen Sie sich den Datensatz an: Sind alle wichtigen Informationen auf jeder Zeile vorhanden?\n\nVersuchspersonen-ID\nBedingung\nStimuluseigenschaften (z.B. word)\nAntwort der Versuchsperson\nAntwortdauer der Versuchsperson\nAntwort korrekt?\n\nKönnen die Daten überschrieben werden?\nLassen Sie jemanden anderes Ihr Experiment durchführen, und geben Sie einander Feedback.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#verwenden-von-codekomponenten-im-builder",
    "href": "psychopy_experiments.html#verwenden-von-codekomponenten-im-builder",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "4.5 Verwenden von Codekomponenten im Builder",
    "text": "4.5 Verwenden von Codekomponenten im Builder\nAuch wenn man das Experiment im Builder erstellt erfordern einige Experimentelemente das Verwenden von Codekomponenten. In diesem Abschnitt werden zwei häufige Anwendungsbeispiele besprochen: Die variable Blockdauer (z.B. für Fixationskreuze oder ITIs) und das Geben von Feedback (z.B. in einem Übungsdurchgang).\n\n\n\n\n\n\nIf-else Statements in Python\n\n\n\nIn Python können Sie für verschiedene Fälle (cases) andere Aktionen ausfüllen, indem Sie If-else Statements nutzen.\nEin If-else Statement enthält ein if (wenn), einer condition (das zutrifft), einem body (dann mach das).\nErgänzt kann dies werden mit ifelse (oder wenn)+ condition (das zutrifft) + body (dann mach das) und einem else (wenn nichts davon zutrifft) + body (dann mach das).\nWichtig: - Python ist indentation-sensibel, das bedeutet: Die Einrückung (1 Tab) muss stimmen, sonst funktioniert der Code nicht. Auch der Doppelpunkt : ist wichtig und muss an der richtigen Stelle stehen. Wenn Sie mehrere conditions verwenden möchten, müssen Sie diese in Klammern () setzen. Hier sehen Sie die Syntax eines If-else Statements:\nif (condition):\n    body\n    \nelif (condition):\n    body\n    \nelse:\n    body\n\n\n\nEinführung in Python auf Datacamp: 👉🏼 Introduction to Python\n\n\n4.5.1 Variable Dauer von Elementen\n\nFixationskreuz und ITI mit randomisierter Dauer\nUm das Experiment für die Versuchsperson unvorhersehbarer zu machen, implementieren wir vor dem eigentlichen Stimulus ein Fixationskreuz mit variabler Länge. Diese Länge soll 0.2, 0.4, 0.6, oder 0.8 Sekunden betragen.\n\nFügen Sie einen Codeblock code_fixationcross ein und definieren Sie unter Begin Routine die Variable fixationcross_duration.\n\nFügen Sie einen Textblock fixationcross ein mit dem Text + und Schriftgrösse 10. Geben Sie unter duration Ihre vorher definierte Variable ein (vergessen Sie dabei das $ nicht): $fixationcross_duration.\n\n\n\n\n\n\n\n\nHands-on: Variable ITI einbauen\n\n\n\nFügen Sie nach dem Stimulus eine ITI mit variabler Dauer hinzu.\nEinfachere Variante: Die ITI soll 10, 20, 30, 40 oder 50 Frames betragen.\nSchwierigere Variante: Die ITI soll eine Zufallszahl zwischen 0.2 und 0.8 Sekunden betragen.\n\n\n\n\n\n4.5.2 Feedback\nEs gibt Experimente, welche Feedback erfordern. Oft wird vor der Datenerhebung ein Übungsblock eingebaut, welcher Feedback enthält, so dass die Versuchspersonen wissen, ob sie den Task richtig verstanden haben.\n\nErstellen Sie zuerst eine Trialschleife mit einem Stimulus und einer Response.\nFügen Sie nach dem Stimulus und der Antwort (aber innerhalb der Trialschleife!) eine Routine feedback ein.\nFügen Sie innerhalb der Routine feedback eine Codekomponente hinzu. In dieser Komponente können Sie nun\n\nFügen Sie nun eine Textkomponente hinzu und fügen Sie beim Textfeld die Variable $response_msg ein, damit die Versuchsperson abhängig von ihrer Antwort das entsprechende Feedback erhält, welches zuvor in der Codekomponente definiert wurde.\n\n\n\n\n\n\n\n\nHands-on: Feedback geben\n\n\n\nSie können mittels einer Codekomponente auch reagieren, wenn die Versuchsperson zu schnell, zu langsam oder gar nicht antwortet.\n\nErstellen Sie einen Übungsdurchgang. Fügen Sie eine Code-Komponente hinzu und legen Sie fest, welches Feedback die Versuchsperson erhalten soll.\n\nEinfache Variante: Geben Sie der Person Feedback, ob ihre Antwort richtig oder falsch war.\nMittelschwere Variante: Geben Sie der Person Feedback, wenn Sie zu schnell oder zu langsam antwortet.\nSchwere Variante: Erstellen Sie einen Counter, welcher der Versuchsperson anzeigt, wie gut sie ist, indem für jede richtige Antwort 5 Punkte erhält, für jede falsche Antwort 5 Punkte abgezogen werden.\nFalls Sie zur Geschwindigkeit Rückmeldung geben wollen oder einen Counter bauen, können Sie etwas in dieser Art machen.\nif dots_keyboard_response.keys is None:\n    response_text = \"miss\"\n\nelif dots_keyboard_response.rt &lt;= 0.1:\n    response_text = \"too fast\"\n\nelse:\n    if (direction == \"left\" and dots_keyboard_response.keys == \"f\" or \n        direction == \"right\" and dots_keyboard_response.keys == \"j\"):\n        response_text = \"+5 points\"\n    else:\n        response_text = \"+0 points\"",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "psychopy_experiments.html#weitere-wichtige-punkte",
    "href": "psychopy_experiments.html#weitere-wichtige-punkte",
    "title": "4  Verhaltensexperimente mit PsychoPy",
    "section": "4.6 Weitere wichtige Punkte",
    "text": "4.6 Weitere wichtige Punkte\n\n4.6.1 Degrees of Visual Angle\nOftmals werden Grössenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abhängig sind. Degrees of visual angle gibt die wahrgenommene Grösse des Stimulus an, und berücksichtigt die Grösse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von OpenSesame. Üblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm für die Erstellung behavioraler Experimente.\n\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem Link mehr Information.\n\n\n4.6.2 Timing\nFrames vs. time (sec or ms): Die präziseste Art zur Steuerung des Timings von Stimuli besteht darin, sie für eine festgelegte Anzahl von Frames zu präsentieren. Bei einer Framerate von 60 Hz können Sie Ihren Stimulus nicht z. B. 120 ms lange präsentieren; die Bildperiode würde Sie auf einen Zeitraum von 116,7 ms (7 Bilder) oder 133,3 ms (8 Bilder) beschränken. Dies ist besonders wichtig für Reaktionszeit-Aufgaben und EEG-Studien, wo ein präzises Millisekunden-Timing erforderlich ist. Hier finden Sie weitere Informationen zu diesem Thema: Presening Stimuli - Psychopy.\n\nHertz ist eine Einheit die angibt, wie häufig etwas pro Sekunde passiert. Hertz kann wie Mal pro Sekunde ausgesprochen werden. 60 Hertz bedeutet also, 60 Mal pro Sekunde.\n\n\n\n4.6.3 Individualisierte Aufgabenschwierigkeit / Schwellenmessung\nIm Random Dot Experiment macht es z.B. für gewisse Fragestellungen Sinn die Aufgabenschwierigkeit für jede Person anzupassen, da sonst ceiling/floor-Effekte auftreten können.\nIn PsychoPy kann ein Staircase in einem Loop verwendet werden, um die Schwierigkeit einer Aufgabe basierend auf der Leistung der Teilnehmer dynamisch anzupassen. Sie ist besonders häufig in Experimenten zur Schwellenmessung, bei denen das Ziel darin besteht, die kleinste wahrnehmbare Reizintensität zu bestimmen. Hier finden Sie weitere Informationen zu diesem Thema: Using a Staircase - PsychoPy.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Verhaltensexperimente mit PsychoPy</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html",
    "href": "stroop_experiment.html",
    "title": "5  Stroop Paradigma",
    "section": "",
    "text": "6 Stroop Task\nDer Stroop Task wurde 1935 zum ersten Mal beschrieben (Stroop, 1935) und ist einer der meist zitierten und verwendeten neuropsychologischen Aufgaben (MacLeod, 1991). In der Neuropsychologie wird der Stroop Color and Word Test (SCWT) verwendet, um die Fähigkeit zur Inhibition kognitiver Interferenz zu messen, welche entsteht wenn zwei Stimuluseigenschaften gleichzeitig verarbeitet werden sich aber widersprechen (Scarpina & Tagini, 2017). Teilweise misst der Task auch andere kognitive Funktionen, wie visuelle Suche oder Arbeitsgedächtnis, weshalb der Vergleich von Bedingungen relevant ist (Periáñez et al., 2021).\nWährend dem Stroop Task wird ein Text mit Farbwörtern präsentiert. Im kongruenten Durchgang entsprechen die Farben des Textes dem Farbwort (das Wort “rot” wird in rot präsentiert), im inkongruenten Durchgang unterscheiden sich die Farben des Textes vom Farbwort (das Wort “rot” wird in gelber Farbe präsentiert). Die Person muss angeben in welcher Farbe das Wort abgedruckt ist. In der kongruenten Bedingung fällt dies leichter, weil das gelesene Wort auch der Farbe entspricht. In der inkongruenten Bedingung verlangsamt sich die Geschwindigkeit durch die entstehende Interferenz von Wort und Farbe, da das Wort automatisch gelesen wird. Oft wird auch noch eine neutrale Bedingung verwendet, wo nur die Farbe oder das Wort präsentiert werden.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#kurzbeschrieb-kursexperiment",
    "href": "stroop_experiment.html#kurzbeschrieb-kursexperiment",
    "title": "5  Stroop Paradigma",
    "section": "6.1 Kurzbeschrieb Kursexperiment",
    "text": "6.1 Kurzbeschrieb Kursexperiment\nIn diesem Experiment lösen die Personen zwei Bedingungen des Stroop Task, einmal geben sie die Farben der Wörter an in einer kongruenten Bedingung (Wortinhalt und Wortfarbe) stimmen überein. Einmal lösen sie die Aufgabe in einer inkongruenten Bedingung (Wortinhalt und Wortfarbe stimmen nicht überein).\nDie kongruente und inkongruente Bedingung kommen im selben Block vor. Die Instruktion lautet für beide Bedingungen gleich, da immer die Wortfarbe angegeben werden muss. Drei Farben werden verwendet: rot, blau und gelb.\nDas Stroop Kursexperiment ist folgendermassen aufgebaut:\n\n\n\n\n\n\n\nHands-on: Stroop Kursexperiment\n\n\n\nLaden Sie das Experiment herunter und testen Sie, ob es auf Ihrem Laptop läuft. Hier finden Sie die Anweisungen dazu.\n\nTesten Sie, ob das Experiment startet und ob die Übungstrials funktionieren. Kontrollieren Sie, ob es ein Datenfile abgespeichert hat und schauen Sie, ob dieses Datenfile alles Relevante enthält. Wenn alles ok ist, ist das Experiment bereit für Übung 1. Führen Sie die Testungen ausserhalb des Computerlabs durch.\nBeantworten Sie folgende Fragen zum Experiment:\n\n\nWas wurde im Experiment variiert? Wie viele unterschiedliche Trials gibt es?\nWelche Bedingungen gibt es?\nWieviele Trials werden pro Bedingung durchgeführt?\nWie lange wird der Wort-Stimulus angezeigt? Wann ist er fertig (zeit oder tasten-definiert?)?\nWie denken Sie, wird sich das Verhalten (Reaktionszeit, Richtigkeit) zwischen den Bedingungen unterscheiden?",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#credits",
    "href": "stroop_experiment.html#credits",
    "title": "5  Stroop Paradigma",
    "section": "6.2 Credits",
    "text": "6.2 Credits\nDieses Experiment wurde von Rebekka Borer programmiert.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "stroop_experiment.html#referenzen",
    "href": "stroop_experiment.html#referenzen",
    "title": "5  Stroop Paradigma",
    "section": "6.3 Referenzen",
    "text": "6.3 Referenzen\nMacLeod C. M. (1991). Half a century of research on the Stroop effect: an integrative review. Psychological Bulletin. 109(2), 163–203. https://doi.org/10.1037/0033-2909.109.2.163\nPeriáñez, J. A., Lubrini, G., García-Gutiérrez, A., & Ríos-Lago, M. (2021). Construct validity of the stroop color-word test: influence of speed of visual search, verbal fluency, working memory, cognitive flexibility, and conflict monitoring. Archives of Clinical Neuropsychology, 36(1), 99-111. https://doi.org/10.1093/arclin/acaa034\nScarpina, F., & Tagini, S. (2017). The stroop color and word test. Frontiers in psychology, 8, 557. https://doi.org/10.3389/fpsyg.2017.00557\nStroop, J. R. (1935). Studies of interference in serial verbal reactions. Journal of Experimental Psychology, 18(6), 643–662. https://doi.org/10.1037/",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Stroop Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html",
    "href": "random_dot_experiment.html",
    "title": "6  Random Dot Paradigma",
    "section": "",
    "text": "7 Random Dot Experiment\nJeden Tag treffen wir Tausende von kleinen Entscheidungen, meistens unter gewissem Zeitdruck. Viele davon sind trivial (z. B. welches Paar Socken man anzieht) und automatisch (z. B. ob man die Espresso- oder Lungo-Taste auf der Kaffeemaschine drückt). Die meisten Entscheidungen im wirklichen Leben setzen sich eigentlich aus zwei Entscheidungen zusammen: Einerseits der Entscheidung, mit dem Abwägen aufzuhören und aufgrund des aktuellen Wissenstandes zu handeln. Andererseits die Wahl oder Entscheidungshandlung selbst. Dieser sequentielle Charakter der Entscheidungsfindung ist eine grundlegende Eigenschaft des menschlichen Nervensystems und spiegelt seine Unfähigkeit wieder, Informationen sofort zu verarbeiten.\nPerzeptuelle Entscheidungen sind Entscheidungen, welche auf der Wahrnehmung, Einordnung und Integration von Sinnesreizen beruhen. Um beispielsweise eine Strasse sicher überqueren zu können, müssen wir mittels den Sinnesinformationen der Augen und Ohren sowie der Verarbeitung dieser Reize einschätzen mit welcher Geschwindigkeit ein herannahendes Auto unterwegs ist und ob wir lieber abwarten bis es vorbeigefahren ist. Innerhalb der Neurowissenschaften wird perceptual decision making untersucht, um die neuronalen Schaltkreise welche Wahrnehmungssignale kodieren, speichern und analysieren zu verstehen und mit beobachtbarem Verhalten in Verbindung zu bringen. Von Interesse ist zum Beispiel wie die Entscheidung ausfällt, wenn die sensorischen Daten undeutlich oder sogar widersprüchlich sind. Besonders spannend ist auch wie Vorwissen (prior knowledge) auf das Entscheidungsverhalten einwirkt.\nObwohl das Treffen von Entscheidungen für uns etwas sehr Vertrautes ist, ist das Wissen darum, wie das Gehirn diese Entscheidungsaufgaben löst noch sehr begrenzt. Eine einzelne Entscheidung kann schon sehr komplex sein. Um die Dynamik der Entscheidungsfindung zu verstehen, konzentrieren sich die meisten Studien deshalb auf einfache, wiederholbare Wahlprobleme mit nur zwei (binären) Antwortmöglichkeiten. Ein typisches Paradigma in neurowissenschaftlichen Studien ist das random-dot motion paradigm. Hierbei muss eine Person entscheiden in welche Richtung sich eine Punktewolke bewegt.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html#kurzbeschrieb-kursexperiment",
    "href": "random_dot_experiment.html#kurzbeschrieb-kursexperiment",
    "title": "6  Random Dot Paradigma",
    "section": "7.1 Kurzbeschrieb Kursexperiment",
    "text": "7.1 Kurzbeschrieb Kursexperiment\nIn unserem Experiment lösen die Versuchspersonen einen Random Dot Task zweimal (in zwei Blöcken). In jedem Block erhalten sie eine andere Instruktion, die Aufgabe bleibt jedoch dieselbe: Sie müssen herausfinden in welche Richtung sich die Punktewolke bewegt. In einem Block werden sie instruiert die Aufgabe möglichst schnell zu lösen. Im anderen Block werden sie instruiert die Aufgabe möglichst richtig zu lösen. Wir werden dann analysieren, wie sich das Entscheidungsverhalten von Menschen verändert, je nachdem wie sie instruiert wurden.\nDas Random Dot Kursexperiment ist folgendermassen aufgebaut:\n\n\n\n\n\n\n\nHands-on: Random Dot Kursexperiment\n\n\n\nLaden Sie das Experiment herunter und testen Sie, ob es auf Ihrem Laptop läuft. Hier finden Sie die Anweisungen dazu.\n\nTesten Sie, ob das Experiment startet und ob die Übungstrials funktionieren. Kontrollieren Sie, ob es ein Datenfile abgespeichert hat und schauen Sie, ob dieses Datenfile alles Relevante enthält. Wenn alles ok ist, ist das Experiment bereit für Übung 1. Führen Sie die Testungen ausserhalb des Computerlabs durch.\nBeantworten Sie folgende Fragen zum Experiment:\n\n\nWas wurde im Experiment variiert? Wie viele unterschiedliche Trials gibt es?\nWelche Bedingungen gibt es?\nWieviele Trials werden pro Bedingung durchgeführt?\nWie lange wird der Dot-Stimulus angezeigt? Wann ist er fertig (zeit oder tasten-definiert?)?\nWie denken Sie, wird sich das Verhalten (Reaktionszeit, Richtigkeit) zwischen den Bedingungen unterscheiden?",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "random_dot_experiment.html#credits",
    "href": "random_dot_experiment.html#credits",
    "title": "6  Random Dot Paradigma",
    "section": "7.2 Credits",
    "text": "7.2 Credits\nDieses Experiment wurde von Rebekka Borer programmiert.\n\n\n\n\nHauser, Christopher K., and Emilio Salinas. 2014. “Perceptual Decision Making.” In Encyclopedia of Computational Neuroscience, edited by Dieter Jaeger and Ranu Jung, 1–21. New York, NY: Springer New York. https://doi.org/10.1007/978-1-4614-7320-6_317-1.\n\n\nMulder, M. J., E.-J. Wagenmakers, R. Ratcliff, W. Boekel, and B. U. Forstmann. 2012. “Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff.” Journal of Neuroscience 32 (7): 2335–43. https://doi.org/10.1523/JNEUROSCI.4156-11.2012.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Dot Paradigma</span>"
    ]
  },
  {
    "objectID": "loops.html",
    "href": "loops.html",
    "title": "7  Schleifen programmieren mit Python",
    "section": "",
    "text": "7.1 for-Schleifen\nDie for-Schleife wird oft genutzt, um über eine Liste oder eine andere Sequenz zu iterieren.\nIn dieser Konsole können Sie Python-Code schreiben, verändern und ausführen:\nMan kann eine for-Schleife auch mit range() verwenden:",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#for-schleifen",
    "href": "loops.html#for-schleifen",
    "title": "7  Schleifen programmieren mit Python",
    "section": "",
    "text": "hirnregionen = [\"Frontallappen\", \"Okzipitallappen\", \"Temporallappen\"] \nfor hirnregion in hirnregionen: \n    print(\"Ich mag den\", hirnregion, \"!\")\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nfor i in range(5):  # Iteriert von 0 bis 4\n    print(\"Iteration Nummer:\", i)\n    \n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#while-schleifen",
    "href": "loops.html#while-schleifen",
    "title": "7  Schleifen programmieren mit Python",
    "section": "7.2 while-Schleifen",
    "text": "7.2 while-Schleifen\nEine while-Schleife wird benutzt, wenn die Anzahl der Iterationen nicht im Voraus bekannt ist, sondern von einer Bedingung abhängt.\nzaehler = 0\nwhile zaehler &lt; 3:\n    print(\"Dies ist Schleifeniteration:\", zaehler)\n    zaehler = zaehler + 1  # Erhöht den Zähler, um eine Endlosschleife zu vermeiden\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nHands-on 1-3: for und while-Schleifen erstellen\n\n\n\n\nGeben Sie die Zahlen von 1 bis 10 mit einer for-Schleife aus.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nGeben Sie “Python macht Spaß!” fünfmal mit einer while-Schleife aus.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nErstellen Sie eine Schleife, die nur gerade Zahlen von 1 bis 20 ausgibt.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#flowcharts",
    "href": "loops.html#flowcharts",
    "title": "7  Schleifen programmieren mit Python",
    "section": "7.3 Flowcharts",
    "text": "7.3 Flowcharts\nBeispiel Flowchart:\ni = 1\nwhile i &lt;= 100:\n    print(i)\n    if i == 39:\n        i = 61\n    else:\n        i = i + 1\n\n\n\nhttps://de.wikipedia.org/wiki/Programmablaufplan#/media/Datei:Flowchart_de.svg\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\n\nHands-on 4: Flowchart erstellen\n\n\n\nErstellen Sie eine Flowchart für die for-Schleife in Aufgabe 3.\nSie können diese auf https://app.diagrams.net/ erstellen.\n\n\n\n\n\n\n\n\nHands-on 5: Fortgeschrittene Übung: Donuts-Essen\n\n\n\nErstellen Sie eine Flowchart für den folgenden Code:\ndonuts = 5\nwhile donuts &gt; 0:\n    print(\"Ich esse einen Donut. Lecker!\")\n    donuts = donuts - 1\n    if donuts == 1:\n        print(\"Oh nein! Nur noch ein Donut übrig!\")\n    elif donuts == 0:\n        print(\"Keine Donuts mehr... Zeit, neue zu kaufen!\")\nHier können Sie ausprobieren, was der Code macht. Passt das zu Ihrer Flowchart?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#wichtig-endlosschleifen-vermeiden",
    "href": "loops.html#wichtig-endlosschleifen-vermeiden",
    "title": "7  Schleifen programmieren mit Python",
    "section": "7.4 Wichtig: Endlosschleifen vermeiden",
    "text": "7.4 Wichtig: Endlosschleifen vermeiden\nSchleifen müssen immer eine Bedingung haben, die sie beendet. Sonst könnte folgendes passieren:\ni = 0\nwhile i &lt; 1:\n    i = i - 1\n    print(i)  # Diese Schleife läuft endlos!\nHier fehlt eine Bedingung, die i wieder größer macht, sodass die Schleife stoppt.\nProbieren Sie es aus (wenn Sie einen Crash Ihres Browsertabs nicht scheuen…?).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "loops.html#fazit",
    "href": "loops.html#fazit",
    "title": "7  Schleifen programmieren mit Python",
    "section": "7.5 Fazit",
    "text": "7.5 Fazit\nSchleifen sind ein mächtiges Werkzeug um wiederkehrende Aufgaben effizient zu lösen. Schleifen werden fast überall benutzt: Experimente programmieren, Daten einlesen, Daten bearbeiten, Grafiken erstellen, usw.\n\n\n\n\n\n\n\nHands-on Lösungen\n\n\n\n\n\n\n7.5.1 Hands-on 1\nfor i in range(10):\n    print(i + 1)\nAlternativ:\nzahlen = [1,2,3,4,5,6,7,8,9,10]\nfor z in zahlen:\n    print(z)\nOder:\nzahlen = 1\nwhile zahlen &lt;= 10:\n    print(zahlen)\n    zahlen = zahlen + 1\n\n\n7.5.2 Hands-on 2\ni = 0\nwhile i &lt; 5:\n    print(\"Python macht Spaß!\")\n    i = i + 1\n\n\n7.5.3 Hands-on 3\nn = 2\nwhile n &lt;= 20:\n    print(n)\n    n = n + 2\n\n\n7.5.4 Hands-on 4\n\n\n\n\n\n\n\n7.5.5 Hands-on 5",
    "crumbs": [
      "Experimentieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Schleifen programmieren mit Python</span>"
    ]
  },
  {
    "objectID": "uebung_1.html",
    "href": "uebung_1.html",
    "title": "Übung 1",
    "section": "",
    "text": "Auftrag\nFühren Sie selbst und mit 2 weiteren Personen das Stroop und das Random Dot Experiment durch. Laden Sie anschliessend die 6 Datensätze auf Ilias hoch. Die beiden Experimente dauern zusammen ca. 30 Minuten ( abhängig von den Versuchspersonen).\nFühren Sie das Experiment mit der Einstellung Run durch und nicht im Pilot-Mode!\nWichtig:\nDie erhobenen Daten werden wir dann in den kommenden Sitzungen verwenden, achten Sie also auf gute Datenqualität.",
    "crumbs": [
      "Experimentieren",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#vorgehen",
    "href": "uebung_1.html#vorgehen",
    "title": "Übung 1",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nLaden Sie die 2 Experimente herunter und testen Sie, ob Sie einwandfrei laufen. Die Experimente befinden sich auf Github. Sie können sie unter den untenstehenden Links downloaden. Klicken Sie dafür auf den ZIP-Ordner, und dann auf View Raw oder auf das Icon mit ... und dort auf Download. Sie müssen das File dann evtl. entzippen, bevor Sie das Experiment starten können. Bei Problemen finden Sie unten einen Abschnitt Troubleshooting. Wenn das nichts hilft, können Sie sich bei der nächsten Veranstaltung an uns wenden.\n\nStroop Experiment\nRandom Dot Experiment\n\nFühren Sie selber die beiden Experimente durch.\n\nStellen Sie sicher, dass hier ein vollständiger Datensatz abgespeichert wird. Testen Sie erst dann zusätzliche Personen.\n\nLassen Sie 2 weitere Personen die beiden Experimente ausführen (jede Person soll beide Experimente ausführen).\n\nDie Personen müssen zwischen 18 und 60 Jahren alt sein.\nDie Personen sollten eine normale oder korrigiert-zu-normale (Brille/Kontaktlinsen) Sehstärke haben.\nKeine Mitstudierenden aus dem Computerlab testen.\nAchten Sie darauf, dass die Personen die Aufgaben konzentriert und ohne Ablenkung lösen können.\n\nLaden Sie die 6 Datensätze auf ILIAS hoch.\n\nLaden Sie die 6 .csv/.xlsx-Files mit den erhobenen Datensätzen auf Ilias unter Übung 1 hoch.\n\n\nDie Datensätze finden Sie im Experimentordner (dort wo das .psyexp-File des Experiments gespeichert ist) einen Ordner data. In diesem Ordner sind mehrere Dateien vorhanden. Sie müssen nur die .csv/.xlsx-Files pro Person hochladen, die anderen Files werden nicht benötigt. Die Datei muss einige KB gross sein, sonst hat etwas nicht geklappt (z.B. wenn die Datei nur 2 KB gross ist).",
    "crumbs": [
      "Experimentieren",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#abgabetermin",
    "href": "uebung_1.html#abgabetermin",
    "title": "Übung 1",
    "section": "Abgabetermin",
    "text": "Abgabetermin\n14. März 2024 23:55",
    "crumbs": [
      "Experimentieren",
      "Übung 1"
    ]
  },
  {
    "objectID": "uebung_1.html#trouble-shooting",
    "href": "uebung_1.html#trouble-shooting",
    "title": "Übung 1",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nBitte die Fehlermeldung im Fenster genau durchlesen. Dort finden Sie Hinweise darauf, was schief gelaufen ist.\nDas Experiment startet nicht.\n\nUnter Einstellungen (Radsymbol) den Reiter Basic auswählen. Bei Use PsychoPy version die neuste PsychoPy Version 2024.2.4 auswählen.\nUnter Einstellungen (Radsymbol) den Reiter Input auswählen. Bei Keyboard backend (statt ioHub) PsychToolbox auswählen.\n\nDas Experiment startet zwar, der Bildschirm ist aber dann einfach für eine kurze Zeit grau und das Fenster schliesst sich wieder.\n\nZugriffsrechte gegeben? (Bei Windows: Als Administrator starten, bei MacOS: Zugriffsrechte erteilen)\nUnter Einstellungen (Radsymbol) den Reiter Input auswählen. Keyboard Backend auf PsychToolbox statt ioHub setzen.",
    "crumbs": [
      "Experimentieren",
      "Übung 1"
    ]
  },
  {
    "objectID": "datawrangling.html",
    "href": "datawrangling.html",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "",
    "text": "8.1 Datenformate\nBevor mit einem Datensatz gearbeitet wird, empfiehlt es sich den Datensatz anzuschauen und Folgendes zu identifizieren:",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#datenformate",
    "href": "datawrangling.html#datenformate",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "",
    "text": "In welchem Dateiformat ist der Datensatz gespeichert? (z.B. in .csv, .xlsx oder anderen?)\nIn welchem Datenformat ist der Datensatz geordnet? (long oder wide oder mixed?)\nGibt es ein data dictionary mit Erklärungen zu den Variablen?",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#set-up",
    "href": "datawrangling.html#set-up",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.2 Set up",
    "text": "8.2 Set up\n\n\n\n\n\n\nHands-on: Vorbereitung\n\n\n\n\nÖffnen Sie RStudio.\nErstellen Sie ein neues RStudio-Project.\n\nKlicken Sie dafür auf File &gt; New Project\nBenennen Sie das Project complab_fs25 und speichern Sie es an einem sinnvollen Ort auf Ihrem Computer. Wählen Sie, dass dafür ein neuer Ordner erstellt werden soll.\n\nErstellen Sie in diesem Projekt-Ordner einen Ordner namens data.\nKopieren Sie in den data-Ordner Ihre erhobenen Daten des Stroop Experiments. Falls Sie noch keine Daten erhoben haben, dann laden Sie hier einen Beispiels-Datensatz herunter und speichern Sie ihn im data-Ordner.\nErstellen Sie ein neues RScript oder ein RNotebook (.Rmd-File: File &gt; New File &gt; RNotebook) und speichern Sie dieses unter intro_datawrangling im Projekt-Ordner.\n\n\n\n\n\n\n\n\n\nTipp: Namensgebung für Files und Variablen\n\n\n\nWenn Sie Filenamen auswählen, achten Sie darauf dass diese machine-readable sind:\n\nkeine Lücken (verwenden Sie stattdessen den camelCase, den snake_case oder -)\nkeine ä, ö, ü oder andere Sonderzeichen verwenden",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#packages-installieren-und-laden",
    "href": "datawrangling.html#packages-installieren-und-laden",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.3 Packages installieren und laden",
    "text": "8.3 Packages installieren und laden\nFür das Bearbeiten der Daten verwenden eignen sich Funktionen aus dem Package {tidyverse}, eine Sammlung von verschiedenen, für data science sehr geeigneten R Packages. Funktionen aus dem {tidyverse} ermöglichen und vereinfachen viele Schritte der Datenverarbeitung. Im Folgenden werden die wichtigsten und häufigst verwendeten Funktionen beschrieben. Das {tidyverse} können Sie direkt in R herunterladen:\n\nMehr Informationen zum {tidyverse} finden Sie hier.\n\n\n# Download und Installieren des Packages (nur einmal ausführen)\ninstall.packages(\"tidyverse\")\n\nEin Package muss nur einmal heruntergeladen und installiert werden, danach ist es lokal auf dem Computer gespeichert. Aber: Jedes Mal wenn R geöffnet wird, müssen Packages wieder neu geladen werden.\n\n# Package laden (bei jedem Öffnen von R zu Beginn des Skripts ausführen)\nlibrary(\"tidyverse\") \n\nSobald ein Package installiert ist, können die Funktionen auch verwendet werden ohne, dass das ganze Package mit library() geladen wird, indem die Funktion mit dem Package-Namen zusammen aufgerufen wird: packagename::packagefunction(). Dies macht Sinn, wenn verschiedene Packages dieselben Namen für verschiedene Funktionen nutzen und es so zu Konflikten kommt oder wenn nur eine Funktion aus einem Package verwendet werden soll und alle anderen sowieso nicht gebraucht werden.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-importieren-in-r-read.csv",
    "href": "datawrangling.html#daten-importieren-in-r-read.csv",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.4 Daten importieren in R: read.csv()",
    "text": "8.4 Daten importieren in R: read.csv()\nEinen Datensatz in .csv-Format kann mit der Funktion read.csv() importiert werden. Teilweise muss innerhalb der Klammer zusätzlich der Separator mit sep = \",\" angegeben werden, also mit welchem Zeichen die Spalten getrennt sind. Normalerweise ist dies , in .csv (comma separated values), es kann aber auch ;, . oder eine Lücke  sein.\n\n# Daten laden und anschauen\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\")\nglimpse(d_stroop)\n\n\n\n\n\n\n\nHands-on: Daten einlesen\n\n\n\nLesen Sie den Stroop Datensatz in Ihrem data-Ordner ein und schauen Sie ihn dann mit den Funktionen glimpse() und head() an.\n\nWelche Variablen sind wichtig für die weitere Auswertung?\nWelche braucht es wahrscheinlich nicht mehr?\nFinden Sie Versuchspersonenidentifikation? / Reaktionszeit? / Antwort der Versuchsperson?\n\n\n\n\n\n\n\n\n\nTipp: Daten anderer Formate einlesen\n\n\n\nFalls Sie eine Excel-Datei einlesen möchten, können Sie dies mit der read_excel()-Funktion aus dem Package readxl() tun: readxl::read_excel().\nFalls Sie nicht wissen, mit welcher Funktion Sie Ihre Daten einlesen können, können Sie dies in RStudio ausprobieren indem Sie beim Reiter Environment auf Import Dataset klicken und dort Ihren Datensatz auswählen oder über File &gt; Import Dataset. Sie können dort diverse Einstellungen tätigen. In der R Console können Sie dann den Code sehen, der zum Einlesen verwendet wurde und die dortige Funktion in Ihren Code kopieren.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#verwenden-der-pipe-oder",
    "href": "datawrangling.html#verwenden-der-pipe-oder",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.5 Verwenden der Pipe: |> oder %>%",
    "text": "8.5 Verwenden der Pipe: |&gt; oder %&gt;%\nIn R können Sie die Pipe verwenden um mehrere Datenverarbeitungsschritte aneinander zu hängen. Damit sparen Sie sich aufwändige Zwischenschritte und vermeiden das Erstellen von immer neuen Datensätzen. Statt zwei einzelne Datenverarbeitungsschritte zu machen wie oben, können mehrere Schritte (hier Daten einlesen und anzeigen) zusammengefasst werden, in dem nach Zeilenende eine Pipe eingefügt wird:\n\nWann Pipes ungeeignet sind wird hier beschrieben.\n\n\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\") |&gt;\n    glimpse()\n\nDie Base R Pipe |&gt; und die magritter Pipe %&gt;%_ unterscheiden sich in Details, in diesem Kapitel spielt es jedoch keine Rolle, welche Pipe Sie verwenden.\n\n\n\n\n\n\nTipp\n\n\n\nAchtung: Wenn wir zu Beginn ein &lt;- oder = verwenden, wird alles was nach der Pipe kommt wird ebenfalls im Datensatz verändert. Wird z.B. der Code …\n\nd_stroop &lt;- read.csv(\"data/stroop_example.csv\", sep = \",\") |&gt;\n    head()\n\n…eingegeben, besteht der Datensatz d_stroop dann nur noch aus 6 Zeilen, weil die Funktion head() den Datensatz auf die ersten 6 Zeilen kürzt.\nWird die Pipe ohne &lt;- oder = verwendet, bleibt der Datensatz unverändert:\n\nd_stroop |&gt;\n    head()",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-filtern-filter",
    "href": "datawrangling.html#daten-filtern-filter",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.6 Daten filtern: filter()",
    "text": "8.6 Daten filtern: filter()\nMit filter() können bestimmte Beobachtungen oder Untergruppen ausgewählt werden. Hierfür muss in der Funktion filter(.data, filter, ...) der Datensatz, die betreffende Variable, sowie eine Bedingung eingegeben werden. Es wird die ganze Zeile im Datensatz behalten in der die Variable der Bedingung entspricht.\nBeispiele:\n\n# nur die Trials mit den rot angezeigten Wörtern behalten\nd_stroop_filtered &lt;- filter(d_stroop, color == \"red\")\n\n# dasselbe mit der Pipe\nd_filtered &lt;- d_stroop |&gt; filter(color == \"red\")\n\n# nur Trials die ohne blau angezeigten Wörter behalten\nd_filtered &lt;- d_stroop |&gt; filter(color != \"blue\")\n\n# nur Übungstrials mit einer Antwortszeit unter oder gleich gross wie 1 Sekunde behalten\nd_filtered &lt;- d_stroop |&gt; filter(respPractice.rt &lt;= 1)\n\n# nur Übungstrials mit Antwortzeiten zwischen 1 und 2 Sekunden behalten\nd_filtered &lt;- d_stroop |&gt; filter(respPractice.rt &gt; 1 & respPractice.rt &lt; 2)\n\n# mehrere Filter verwenden\nd_filtered &lt;- d_stroop |&gt; \n    filter(color == \"red\") |&gt;\n    filter(respPractice.rt &lt;= 1)\n\nIn unserem Datensatz möchten wir nur die gültigen Experimentdaten behalten, die Color-To-Key (ctk) Bedingung sowie die Practice Trials möchten wir ausschliessen.\nDie Variable trials_test.thisN enthält die Trialnummer, sie enthält nur Einträge, während der gültigen Trials. Wir können dies nutzen und alle Zeilen behalten in welchen die Zelle der Variable trials_test.thisN nicht leer ist:\n\nd_stroop &lt;- d_stroop |&gt; \n    filter(!is.na(trials_test.thisN)) \n\n\n\n\n\n\n\nHands-on: Daten filtern\n\n\n\nErstellen Sie einen neuen Datensatz namens d_stroop_correct und filtern Sie diesen so dass er nur Trials mit richtigen Antworten enthält. Schauen Sie in der Variable keyResp_test_run.corr, ob tatsächlich nur noch richtige Antworten übrig geblieben sind.\nAchtung: Arbeiten Sie in den weiteren Schritten nicht mit diesem Datensatz weiter, da wir die falschen Antworten in einem nächsten Schritt noch im Datensatz brauchen.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#variablen-auswählen-select",
    "href": "datawrangling.html#variablen-auswählen-select",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.7 Variablen auswählen: select()",
    "text": "8.7 Variablen auswählen: select()\nEin komplexer Datensatz mit sehr vielen Variablen wird oft für die Analyse aus Gründen der Einfachheit oder Anonymisierung reduziert. Das bedeutet, dass man sich die nötigen Variablen herausliest, und nur mit diesem reduzierten Datensatz weiterarbeitet. Hierzu eignet sich die Funktion select() sehr gut: Mit select(.data, variablenname, ...) können die zu behaltenden Variablen ausgewählt werden. Wird ein ! vor einen Variablennamen gesetzt, wird die Variable nicht behalten.\nMit select() können wir auch die Variablen sortieren und umbenennen, damit unser Datensatz so strukturiert ist, wie wir ihn gebrauchen können.\nBeispiele:\n\n# Variable word und color behalten ohne Pipe\nd_simpler &lt;- select(d_stroop, word, color)\n\n# Variable word und color behalten mit Pipe\nd_simpler &lt;- d_stroop |&gt; select(word, color)\n\n# alle Variablen ausser word behalten\nd_simpler &lt;- d_stroop |&gt; select(!word)\n\n# Variablennamen verändern\nd_simpler &lt;- d_stroop |&gt; select(newvariablename = word)\n\nSollen mehrere Variablen am Stück ausgewählt werden, kann man die erste Variable in der Reihe (z.B. word) und die letzte in der Reihe (z.B. congruent) als word:congruent eingeben, dann werden auch alle dazwischen liegenden Variablen ausgewählt.\n\n\n\n\n\n\nHands-on: Variablen auswählen\n\n\n\nSchauen Sie sich Ihren Datensatz an, welche Variablen benötigen Sie für die weitere Analysen?\nErstellen Sie einen neuen Datensatz d_stroop_clean in welchem Sie die entsprechenden Variablen auswählen und umbennen, wenn Sie Ihnen zu lange/kompliziert erscheinen.\nUntenstehend finden Sie ein Beispiel, wie der Datensatz danach aussehen könnte.\n\n\n\n\nRows: 120\nColumns: 10\n$ id         &lt;chr&gt; \"sub-154989\", \"sub-154989\", \"sub-154989\", \"sub-154989\", \"su…\n$ experiment &lt;chr&gt; \"stroop_test\", \"stroop_test\", \"stroop_test\", \"stroop_test\",…\n$ trial      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ word       &lt;chr&gt; \"rot\", \"rot\", \"blau\", \"gelb\", \"rot\", \"blau\", \"blau\", \"gelb\"…\n$ color      &lt;chr&gt; \"red\", \"red\", \"blue\", \"yellow\", \"yellow\", \"yellow\", \"red\", …\n$ corrAns    &lt;chr&gt; \"r\", \"r\", \"b\", \"g\", \"g\", \"g\", \"r\", \"r\", \"b\", \"g\", \"b\", \"b\",…\n$ congruent  &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,…\n$ response   &lt;chr&gt; \"r\", \"r\", \"b\", \"g\", \"g\", \"g\", \"r\", \"r\", \"b\", \"g\", \"b\", \"b\",…\n$ rt         &lt;dbl&gt; 1.0639791, 0.7370255, 1.1883303, 1.2007897, 1.6688681, 1.58…\n$ accuracy   &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#neue-variablen-generieren-und-verändern-mutate-und-case_when",
    "href": "datawrangling.html#neue-variablen-generieren-und-verändern-mutate-und-case_when",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.8 Neue Variablen generieren und verändern: mutate() und case_when()",
    "text": "8.8 Neue Variablen generieren und verändern: mutate() und case_when()\nMit der mutate(.data, …) Funktion können im Datensatz neue Variablen generiert oder bestehende verändert werden.\nBeispiel:\n\n# Neue Variablen erstellen\nd_new &lt;- d_stroop_clean |&gt;\n    mutate(num_variable = 1.434,\n           chr_variable = \"1.434\",\n           sumofxy_variable = rt + 1,\n           copy_variable = word)\n\n# Bestehende Variablen verändern\nd_new &lt;- d_new |&gt;\n    mutate(num_variable = num_variable * 1000) # z.B. um Sekunden zu Millisekunden zu machen\n\nMit case_when() kann eine neue Variable erstellt werden in Abhängigkeit von Werten anderer Variablen. Damit kann z.B. eine Variable accuracy erstellt werden, die den Wert correct hat, wenn die Aufgabe richtig gelöst wurde (z.B. Bedingung rot und Tastendruck r) und sonst den Wert error hat.\nBeispiel:\n\nd_condvariable &lt;- d_stroop_clean |&gt;\n    mutate(cond_variable = case_when(rt &gt; 0.8 ~ \"higher\",\n                                     rt &lt;= 0.8 ~ \"lower\",\n                                     .default = NA))\n\n\n\n\n\n\n\nHands-on: Variablen generieren und verändern\n\n\n\n\nErstellen Sie im Datensatz d_stroop_clean eine neue Variable mit dem Namen researcher, den Ihren Namen enthält.\nErstellen Sie zudem eine Variable accuracy_check, mit correct für korrekte und error für inkorrekte Trials. Kontrollieren Sie mit der Variable keyResp_test_run.corr (oder Ihrem neuen Variablennamen, wenn Sie diese umbenannt haben) im Datensatz, ob Sie die Aufgabe richtig gelöst haben.\nÄndern Sie die Trialnummer, so dass sie nicht mehr mit 0 beginnt, sondern mit 1.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#variablenklasse-verändern-as.factor-as.numeric",
    "href": "datawrangling.html#variablenklasse-verändern-as.factor-as.numeric",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.9 Variablenklasse verändern: as.factor(), as.numeric(), …",
    "text": "8.9 Variablenklasse verändern: as.factor(), as.numeric(), …\nVariablen können verschiedene Klassen haben, sie können z.B. kategoriale (factor, character) oder numerische (integer, numeric, double) Informationen enthalten. Beim Einlesen “rät” R, welche Klasse eine Variable hat. Teilweise möchten wir dies ändern. Wenn wir eine Variable zu einem Faktor machen möchten, verwenden wir as.factor(). Dies macht z.B. Sinn, wenn die Versuchspersonennummer als Zahl eingelesen wurde. Um von einem Faktor zu einer numerischen Variable zu kommen, verwenden wir as.numeric().\n\n# Die Variable \"congruent\" zu einem Faktor machen\nd_stroop_clean |&gt; \n    mutate(congruent = as.factor(congruent))\n\n\n\n\n\n\n\nHands-on: Variablenklassen\n\n\n\nSchauen Sie sich den Datensatz mit glimpse() oder mit View() an. Welche Klassen enthält Ihr Datensatz und was bedeuten Sie?",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "href": "datawrangling.html#daten-gruppieren-und-zusammenfassen-group_by-und-summarise",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.10 Daten gruppieren und zusammenfassen: group_by() und summarise()",
    "text": "8.10 Daten gruppieren und zusammenfassen: group_by() und summarise()\nMit diesen beiden Funktionen können wir mit wenig Code den Datensatz gruppieren und zusammenfassen.\n\n# Nach Wörter gruppieren\nd_stroop_clean |&gt; group_by(word) |&gt;\n    summarise(mean_rt = mean(rt),\n              sd_rt = sd(rt))\n\n# A tibble: 3 × 3\n  word  mean_rt sd_rt\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 blau     1.23 0.490\n2 gelb     1.26 0.447\n3 rot      1.16 0.552\n\n\n\n\n\n\n\n\nHands-on: Daten zusammenfassen\n\n\n\nErstellen Sie einen neuen Datensatz d_stroop_summary\n\nGruppieren Sie den Datensatz für Wortfarbe und Kongruenz.\nFassen Sie für diese Gruppen die durchschnittliche Antwortzeit und Accuracy sowie die Standardabweichungen zusammen.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#datensätze-speichern-write.csv",
    "href": "datawrangling.html#datensätze-speichern-write.csv",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.11 Datensätze speichern: write.csv()",
    "text": "8.11 Datensätze speichern: write.csv()\n\nwrite.csv(d_stroop_clean, file = \"data/dataset_stroop_clean.csv\", row.names = FALSE)\n\n\n\n\n\n\n\nHands-on: Datensätze speichern\n\n\n\nSpeichern Sie einen neuen Datensatz mit den vorverarbeiteten Daten.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling.html#data-wrangling-workflow-implementieren",
    "href": "datawrangling.html#data-wrangling-workflow-implementieren",
    "title": "8  Daten importieren und vorverarbeiten",
    "section": "8.12 Data wrangling workflow implementieren",
    "text": "8.12 Data wrangling workflow implementieren\n\n\n\n\n\n\nHands-on: Data wrangling workflow\n\n\n\nErstellen Sie nun ein Projekt für das Random-Dot Experiment und führen Sie die gelernten data wrangling Schritte selbstständig durch.\n\n\n\nZu den gelernten Funktionen finden Sie hier Grafiken die evtl. helfen, sich die Funktions-Namen zu merken.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Daten importieren und vorverarbeiten</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html",
    "href": "datawrangling_automatisiert.html",
    "title": "9  Automatisiertes Preprocessing",
    "section": "",
    "text": "9.1 Setup\n# Package laden (bei jedem Öffnen von R zu Beginn des Skripts ausführen)\nlibrary(\"tidyverse\")",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#stroop-experiment-data-wrangling",
    "href": "datawrangling_automatisiert.html#stroop-experiment-data-wrangling",
    "title": "9  Automatisiertes Preprocessing",
    "section": "9.2 Stroop-Experiment data wrangling",
    "text": "9.2 Stroop-Experiment data wrangling\n\n# Daten vorverarbeiten\ndata_stroop &lt;- read_csv(\"data/stroop_example2.csv\")\nglimpse(data_stroop)\n\nd_stroop &lt;- read_csv(\"data/stroop_example2.csv\") |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color,\n           congruent,\n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#daten-mit-eigener-funktion-einlesen",
    "href": "datawrangling_automatisiert.html#daten-mit-eigener-funktion-einlesen",
    "title": "9  Automatisiertes Preprocessing",
    "section": "9.3 Daten mit eigener Funktion einlesen",
    "text": "9.3 Daten mit eigener Funktion einlesen\n\nread_stroop &lt;- function(path){\n    # Code kopiert von oben\n    d_stroop &lt;- read_csv(path) |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color, \n           congruent, \n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)\n    # ---------------------\n    return(d_stroop)\n}\n\nd_stroop_fun &lt;- read_stroop(path = \"data/stroop_example2.csv\")\n\nRows: 161 Columns: 92\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (26): wordCTK, colorCTK, corrAnsCTK, wordPractice, colorPractice, corrAn...\ndbl (65): congruentCTK, congruentPractice, congruent, trials_CTK.thisRepN, t...\nlgl  (1): notes\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\nHands-on 1: Eigene Funktion schreiben\n\n\n\nSchreiben Sie eine Funktion, die nur reaction times von &lt;0.5 wählt, und den Prozent von korrekten Antworten ausgibt.\n\nfast_correct &lt;- function(data){\n    ___ # Code einfügen\n}\n\nfast_correct(d_stroop)",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#einlesen-automatisieren",
    "href": "datawrangling_automatisiert.html#einlesen-automatisieren",
    "title": "9  Automatisiertes Preprocessing",
    "section": "9.4 Einlesen Automatisieren",
    "text": "9.4 Einlesen Automatisieren\nWir benötigen eine Liste aller Datenfiles. Die Funktion list.files() gibt einer Liste aller Dokumente in einem Ordner zurück. Mit dem Argument pattern = ... kann spezifiziert werden, welche Buchstaben(folgen) der Filenamen entahlten soll.\n\nlist.files(path = 'data/raw')\n\n  [1] \"sub-001_random_dot.csv\"  \"sub-001_stroop_test.csv\"\n  [3] \"sub-002_random_dot.csv\"  \"sub-002_stroop_test.csv\"\n  [5] \"sub-003_random_dot.csv\"  \"sub-003_stroop_test.csv\"\n  [7] \"sub-004_random_dot.csv\"  \"sub-004_stroop_test.csv\"\n  [9] \"sub-005_random_dot.csv\"  \"sub-005_stroop_test.csv\"\n [11] \"sub-006_random_dot.csv\"  \"sub-006_stroop_test.csv\"\n [13] \"sub-007_random_dot.csv\"  \"sub-007_stroop_test.csv\"\n [15] \"sub-008_random_dot.csv\"  \"sub-008_stroop_test.csv\"\n [17] \"sub-009_random_dot.csv\"  \"sub-009_stroop_test.csv\"\n [19] \"sub-010_random_dot.csv\"  \"sub-010_stroop_test.csv\"\n [21] \"sub-011_random_dot.csv\"  \"sub-011_stroop_test.csv\"\n [23] \"sub-012_random_dot.csv\"  \"sub-012_stroop_test.csv\"\n [25] \"sub-013_random_dot.csv\"  \"sub-013_stroop_test.csv\"\n [27] \"sub-014_random_dot.csv\"  \"sub-014_stroop_test.csv\"\n [29] \"sub-015_random_dot.csv\"  \"sub-015_stroop_test.csv\"\n [31] \"sub-016_random_dot.csv\"  \"sub-016_stroop_test.csv\"\n [33] \"sub-017_random_dot.csv\"  \"sub-017_stroop_test.csv\"\n [35] \"sub-018_random_dot.csv\"  \"sub-018_stroop_test.csv\"\n [37] \"sub-019_random_dot.csv\"  \"sub-019_stroop_test.csv\"\n [39] \"sub-020_random_dot.csv\"  \"sub-020_stroop_test.csv\"\n [41] \"sub-021_random_dot.csv\"  \"sub-021_stroop_test.csv\"\n [43] \"sub-022_random_dot.csv\"  \"sub-022_stroop_test.csv\"\n [45] \"sub-023_random_dot.csv\"  \"sub-023_stroop_test.csv\"\n [47] \"sub-024_random_dot.csv\"  \"sub-024_stroop_test.csv\"\n [49] \"sub-025_random_dot.csv\"  \"sub-025_stroop_test.csv\"\n [51] \"sub-026_random_dot.csv\"  \"sub-026_stroop_test.csv\"\n [53] \"sub-027_random_dot.csv\"  \"sub-027_stroop_test.csv\"\n [55] \"sub-028_random_dot.csv\"  \"sub-028_stroop_test.csv\"\n [57] \"sub-029_random_dot.csv\"  \"sub-029_stroop_test.csv\"\n [59] \"sub-030_random_dot.csv\"  \"sub-030_stroop_test.csv\"\n [61] \"sub-031_random_dot.csv\"  \"sub-031_stroop_test.csv\"\n [63] \"sub-032_random_dot.csv\"  \"sub-032_stroop_test.csv\"\n [65] \"sub-033_random_dot.csv\"  \"sub-033_stroop_test.csv\"\n [67] \"sub-034_random_dot.csv\"  \"sub-034_stroop_test.csv\"\n [69] \"sub-035_random_dot.csv\"  \"sub-035_stroop_test.csv\"\n [71] \"sub-036_random_dot.csv\"  \"sub-036_stroop_test.csv\"\n [73] \"sub-037_random_dot.csv\"  \"sub-037_stroop_test.csv\"\n [75] \"sub-038_random_dot.csv\"  \"sub-038_stroop_test.csv\"\n [77] \"sub-039_random_dot.csv\"  \"sub-040_random_dot.csv\" \n [79] \"sub-040_stroop_test.csv\" \"sub-041_random_dot.csv\" \n [81] \"sub-041_stroop_test.csv\" \"sub-042_random_dot.csv\" \n [83] \"sub-042_stroop_test.csv\" \"sub-043_random_dot.csv\" \n [85] \"sub-043_stroop_test.csv\" \"sub-044_random_dot.csv\" \n [87] \"sub-044_stroop_test.csv\" \"sub-045_random_dot.csv\" \n [89] \"sub-045_stroop_test.csv\" \"sub-046_random_dot.csv\" \n [91] \"sub-046_stroop_test.csv\" \"sub-047_random_dot.csv\" \n [93] \"sub-047_stroop_test.csv\" \"sub-048_random_dot.csv\" \n [95] \"sub-048_stroop_test.csv\" \"sub-049_random_dot.csv\" \n [97] \"sub-049_stroop_test.csv\" \"sub-050_random_dot.csv\" \n [99] \"sub-050_stroop_test.csv\" \"sub-051_random_dot.csv\" \n[101] \"sub-051_stroop_test.csv\" \"sub-052_random_dot.csv\" \n[103] \"sub-052_stroop_test.csv\" \"sub-053_random_dot.csv\" \n[105] \"sub-053_stroop_test.csv\" \"sub-054_random_dot.csv\" \n[107] \"sub-054_stroop_test.csv\" \"sub-055_random_dot.csv\" \n[109] \"sub-055_stroop_test.csv\" \"sub-056_random_dot.csv\" \n[111] \"sub-057_random_dot.csv\"  \"sub-057_stroop_test.csv\"\n[113] \"sub-058_random_dot.csv\"  \"sub-058_stroop_test.csv\"\n[115] \"sub-059_random_dot.csv\"  \"sub-059_stroop_test.csv\"\n[117] \"sub-060_random_dot.csv\"  \"sub-060_stroop_test.csv\"\n[119] \"sub-061_random_dot.csv\"  \"sub-061_stroop_test.csv\"\n[121] \"sub-062_random_dot.csv\"  \"sub-062_stroop_test.csv\"\n[123] \"sub-063_random_dot.csv\"  \"sub-063_stroop_test.csv\"\n[125] \"sub-064_random_dot.csv\"  \"sub-064_stroop_test.csv\"\n[127] \"sub-065_random_dot.csv\"  \"sub-065_stroop_test.csv\"\n[129] \"sub-066_random_dot.csv\"  \"sub-066_stroop_test.csv\"\n[131] \"sub-067_random_dot.csv\"  \"sub-067_stroop_test.csv\"\n[133] \"sub-068_random_dot.csv\"  \"sub-068_stroop_test.csv\"\n[135] \"sub-069_random_dot.csv\"  \"sub-069_stroop_test.csv\"\n[137] \"sub-070_random_dot.csv\"  \"sub-070_stroop_test.csv\"\n[139] \"sub-071_random_dot.csv\"  \"sub-071_stroop_test.csv\"\n[141] \"sub-072_random_dot.csv\"  \"sub-072_stroop_test.csv\"\n[143] \"sub-073_random_dot.csv\"  \"sub-073_stroop_test.csv\"\n[145] \"sub-074_random_dot.csv\"  \"sub-074_stroop_test.csv\"\n[147] \"sub-075_random_dot.csv\"  \"sub-075_stroop_test.csv\"\n[149] \"sub-076_random_dot.csv\"  \"sub-076_stroop_test.csv\"\n[151] \"sub-077_random_dot.csv\"  \"sub-077_stroop_test.csv\"\n[153] \"sub-078_random_dot.csv\"  \"sub-078_stroop_test.csv\"\n[155] \"sub-079_random_dot.csv\"  \"sub-079_stroop_test.csv\"\n[157] \"sub-080_random_dot.csv\"  \"sub-080_stroop_test.csv\"\n[159] \"sub-081_random_dot.csv\"  \"sub-082_random_dot.csv\" \n[161] \"sub-082_stroop_test.csv\" \"sub-083_random_dot.csv\" \n[163] \"sub-083_stroop_test.csv\" \"sub-084_random_dot.csv\" \n[165] \"sub-084_stroop_test.csv\" \"sub-085_random_dot.csv\" \n[167] \"sub-085_stroop_test.csv\" \"sub-086_random_dot.csv\" \n[169] \"sub-086_stroop_test.csv\" \"sub-087_random_dot.csv\" \n[171] \"sub-087_stroop_test.csv\" \"sub-088_random_dot.csv\" \n[173] \"sub-088_stroop_test.csv\" \"sub-089_random_dot.csv\" \n[175] \"sub-089_stroop_test.csv\" \"sub-090_random_dot.csv\" \n[177] \"sub-090_stroop_test.csv\" \"sub-091_random_dot.csv\" \n[179] \"sub-091_stroop_test.csv\" \"sub-092_random_dot.csv\" \n[181] \"sub-092_stroop_test.csv\" \"sub-093_random_dot.csv\" \n[183] \"sub-093_stroop_test.csv\" \"sub-094_stroop_test.csv\"\n[185] \"sub-095_random_dot.csv\"  \"sub-095_stroop_test.csv\"\n[187] \"sub-096_random_dot.csv\"  \"sub-096_stroop_test.csv\"\n[189] \"sub-097_random_dot.csv\"  \"sub-097_stroop_test.csv\"\n[191] \"sub-098_random_dot.csv\"  \"sub-098_stroop_test.csv\"\n[193] \"sub-099_random_dot.csv\"  \"sub-099_stroop_test.csv\"\n[195] \"sub-100_random_dot.csv\"  \"sub-100_stroop_test.csv\"\n[197] \"sub-101_random_dot.csv\"  \"sub-101_stroop_test.csv\"\n[199] \"sub-102_random_dot.csv\"  \"sub-102_stroop_test.csv\"\n[201] \"sub-103_random_dot.csv\"  \"sub-103_stroop_test.csv\"\n[203] \"sub-104_random_dot.csv\"  \"sub-104_stroop_test.csv\"\n[205] \"sub-105_random_dot.csv\"  \"sub-105_stroop_test.csv\"\n[207] \"sub-106_random_dot.csv\"  \"sub-106_stroop_test.csv\"\n[209] \"sub-107_random_dot.csv\"  \"sub-107_stroop_test.csv\"\n[211] \"sub-108_random_dot.csv\"  \"sub-108_stroop_test.csv\"\n[213] \"sub-109_random_dot.csv\"  \"sub-109_stroop_test.csv\"\n[215] \"sub-110_random_dot.csv\"  \"sub-110_stroop_test.csv\"\n[217] \"sub-111_random_dot.csv\"  \"sub-111_stroop_test.csv\"\n[219] \"sub-112_random_dot.csv\"  \"sub-112_stroop_test.csv\"\n[221] \"sub-113_random_dot.csv\"  \"sub-113_stroop_test.csv\"\n[223] \"sub-114_random_dot.csv\"  \"sub-114_stroop_test.csv\"\n[225] \"sub-115_random_dot.csv\"  \"sub-115_stroop_test.csv\"\n[227] \"sub-116_random_dot.csv\"  \"sub-116_stroop_test.csv\"\n[229] \"sub-117_random_dot.csv\"  \"sub-117_stroop_test.csv\"\n[231] \"sub-118_random_dot.csv\"  \"sub-118_stroop_test.csv\"\n[233] \"sub-119_random_dot.csv\"  \"sub-119_stroop_test.csv\"\n[235] \"sub-120_random_dot.csv\"  \"sub-120_stroop_test.csv\"\n[237] \"sub-121_random_dot.csv\"  \"sub-121_stroop_test.csv\"\n[239] \"sub-122_random_dot.csv\"  \"sub-122_stroop_test.csv\"\n[241] \"sub-123_random_dot.csv\"  \"sub-123_stroop_test.csv\"\n[243] \"sub-124_random_dot.csv\"  \"sub-124_stroop_test.csv\"\n[245] \"sub-125_random_dot.csv\"  \"sub-125_stroop_test.csv\"\n[247] \"sub-126_random_dot.csv\"  \"sub-126_stroop_test.csv\"\n[249] \"sub-127_random_dot.csv\"  \"sub-127_stroop_test.csv\"\n[251] \"sub-128_random_dot.csv\"  \"sub-128_stroop_test.csv\"\n[253] \"sub-129_random_dot.csv\"  \"sub-129_stroop_test.csv\"\n[255] \"sub-130_random_dot.csv\"  \"sub-130_stroop_test.csv\"\n[257] \"sub-131_random_dot.csv\"  \"sub-131_stroop_test.csv\"\n[259] \"sub-132_random_dot.csv\"  \"sub-132_stroop_test.csv\"\n[261] \"sub-133_random_dot.csv\"  \"sub-133_stroop_test.csv\"\n[263] \"sub-134_random_dot.csv\"  \"sub-134_stroop_test.csv\"\n[265] \"sub-135_random_dot.csv\"  \"sub-135_stroop_test.csv\"\n[267] \"sub-136_random_dot.csv\"  \"sub-136_stroop_test.csv\"\n[269] \"sub-137_random_dot.csv\"  \"sub-137_stroop_test.csv\"\n[271] \"sub-138_random_dot.csv\"  \"sub-138_stroop_test.csv\"\n[273] \"sub-139_random_dot.csv\"  \"sub-139_stroop_test.csv\"\n[275] \"sub-140_random_dot.csv\"  \"sub-140_stroop_test.csv\"\n[277] \"sub-141_random_dot.csv\"  \"sub-141_stroop_test.csv\"\n[279] \"sub-142_random_dot.csv\"  \"sub-142_stroop_test.csv\"\n[281] \"sub-143_random_dot.csv\"  \"sub-143_stroop_test.csv\"\n[283] \"sub-144_random_dot.csv\"  \"sub-144_stroop_test.csv\"\n[285] \"sub-145_random_dot.csv\"  \"sub-145_stroop_test.csv\"\n[287] \"sub-146_random_dot.csv\"  \"sub-146_stroop_test.csv\"\n[289] \"sub-147_random_dot.csv\"  \"sub-147_stroop_test.csv\"\n[291] \"sub-148_random_dot.csv\"  \"sub-148_stroop_test.csv\"\n[293] \"sub-149_random_dot.csv\"  \"sub-149_stroop_test.csv\"\n[295] \"sub-150_random_dot.csv\"  \"sub-150_stroop_test.csv\"\n[297] \"sub-151_random_dot.csv\"  \"sub-151_stroop_test.csv\"\n[299] \"sub-152_random_dot.csv\"  \"sub-152_stroop_test.csv\"\n[301] \"sub-153_random_dot.csv\"  \"sub-153_stroop_test.csv\"\n[303] \"sub-154_random_dot.csv\"  \"sub-154_stroop_test.csv\"\n[305] \"sub-155_random_dot.csv\"  \"sub-155_stroop_test.csv\"\n[307] \"sub-156_random_dot.csv\"  \"sub-156_stroop_test.csv\"\n[309] \"sub-157_random_dot.csv\"  \"sub-157_stroop_test.csv\"\n[311] \"sub-158_random_dot.csv\"  \"sub-158_stroop_test.csv\"\n[313] \"sub-159_random_dot.csv\"  \"sub-159_stroop_test.csv\"\n[315] \"sub-160_random_dot.csv\"  \"sub-160_stroop_test.csv\"\n[317] \"sub-161_random_dot.csv\"  \"sub-161_stroop_test.csv\"\n[319] \"sub-162_random_dot.csv\"  \"sub-162_stroop_test.csv\"\n[321] \"sub-163_random_dot.csv\"  \"sub-163_stroop_test.csv\"\n[323] \"sub-164_random_dot.csv\"  \"sub-164_stroop_test.csv\"\n[325] \"sub-165_random_dot.csv\"  \"sub-165_stroop_test.csv\"\n[327] \"sub-166_random_dot.csv\"  \"sub-167_random_dot.csv\" \n[329] \"sub-167_stroop_test.csv\" \"sub-168_random_dot.csv\" \n[331] \"sub-168_stroop_test.csv\" \"sub-169_random_dot.csv\" \n[333] \"sub-169_stroop_test.csv\" \"sub-170_random_dot.csv\" \n[335] \"sub-170_stroop_test.csv\" \"sub-171_random_dot.csv\" \n[337] \"sub-171_stroop_test.csv\" \"sub-172_random_dot.csv\" \n[339] \"sub-172_stroop_test.csv\" \"sub-173_random_dot.csv\" \n[341] \"sub-173_stroop_test.csv\" \"sub-174_random_dot.csv\" \n[343] \"sub-174_stroop_test.csv\" \"sub-175_random_dot.csv\" \n[345] \"sub-175_stroop_test.csv\" \"sub-176_random_dot.csv\" \n[347] \"sub-176_stroop_test.csv\" \"sub-177_random_dot.csv\" \n[349] \"sub-177_stroop_test.csv\" \"sub-178_random_dot.csv\" \n[351] \"sub-178_stroop_test.csv\" \"sub-179_random_dot.csv\" \n[353] \"sub-179_stroop_test.csv\" \"sub-180_random_dot.csv\" \n[355] \"sub-180_stroop_test.csv\" \"sub-181_random_dot.csv\" \n[357] \"sub-181_stroop_test.csv\" \"sub-182_random_dot.csv\" \n[359] \"sub-182_stroop_test.csv\" \"sub-183_random_dot.csv\" \n[361] \"sub-183_stroop_test.csv\" \"sub-184_random_dot.csv\" \n[363] \"sub-184_stroop_test.csv\" \"sub-185_random_dot.csv\" \n[365] \"sub-185_stroop_test.csv\" \"sub-186_random_dot.csv\" \n[367] \"sub-186_stroop_test.csv\" \"sub-187_random_dot.csv\" \n[369] \"sub-187_stroop_test.csv\" \"sub-188_random_dot.csv\" \n[371] \"sub-188_stroop_test.csv\" \"sub-189_random_dot.csv\" \n[373] \"sub-189_stroop_test.csv\" \"sub-190_random_dot.csv\" \n[375] \"sub-190_stroop_test.csv\" \"sub-191_random_dot.csv\" \n[377] \"sub-191_stroop_test.csv\" \"sub-192_random_dot.csv\" \n[379] \"sub-192_stroop_test.csv\" \"sub-193_random_dot.csv\" \n[381] \"sub-193_stroop_test.csv\" \"sub-194_random_dot.csv\" \n[383] \"sub-194_stroop_test.csv\" \"sub-195_random_dot.csv\" \n[385] \"sub-195_stroop_test.csv\" \"sub-196_random_dot.csv\" \n[387] \"sub-196_stroop_test.csv\" \"sub-197_random_dot.csv\" \n[389] \"sub-197_stroop_test.csv\" \"sub-198_random_dot.csv\" \n[391] \"sub-198_stroop_test.csv\" \"sub-199_random_dot.csv\" \n[393] \"sub-199_stroop_test.csv\" \"sub-200_random_dot.csv\" \n[395] \"sub-200_stroop_test.csv\" \"sub-201_random_dot.csv\" \n[397] \"sub-201_stroop_test.csv\" \"sub-202_random_dot.csv\" \n[399] \"sub-202_stroop_test.csv\" \"sub-203_random_dot.csv\" \n[401] \"sub-203_stroop_test.csv\" \"sub-204_random_dot.csv\" \n[403] \"sub-204_stroop_test.csv\" \"sub-205_random_dot.csv\" \n[405] \"sub-205_stroop_test.csv\" \"sub-206_random_dot.csv\" \n[407] \"sub-206_stroop_test.csv\" \"sub-207_random_dot.csv\" \n[409] \"sub-207_stroop_test.csv\" \"sub-208_random_dot.csv\" \n[411] \"sub-208_stroop_test.csv\" \"sub-209_random_dot.csv\" \n[413] \"sub-209_stroop_test.csv\" \"sub-210_random_dot.csv\" \n[415] \"sub-210_stroop_test.csv\" \"sub-211_random_dot.csv\" \n[417] \"sub-211_stroop_test.csv\" \"sub-212_random_dot.csv\" \n[419] \"sub-212_stroop_test.csv\" \"sub-213_random_dot.csv\" \n[421] \"sub-213_stroop_test.csv\" \"sub-214_random_dot.csv\" \n[423] \"sub-214_stroop_test.csv\" \"sub-215_random_dot.csv\" \n[425] \"sub-215_stroop_test.csv\" \"sub-216_random_dot.csv\" \n[427] \"sub-216_stroop_test.csv\" \"sub-217_random_dot.csv\" \n[429] \"sub-217_stroop_test.csv\" \"sub-218_random_dot.csv\" \n[431] \"sub-218_stroop_test.csv\" \"sub-219_random_dot.csv\" \n[433] \"sub-219_stroop_test.csv\" \"sub-220_random_dot.csv\" \n[435] \"sub-220_stroop_test.csv\" \"sub-221_random_dot.csv\" \n[437] \"sub-221_stroop_test.csv\" \"sub-222_random_dot.csv\" \n[439] \"sub-222_stroop_test.csv\" \"sub-223_random_dot.csv\" \n[441] \"sub-223_stroop_test.csv\" \"sub-224_random_dot.csv\" \n[443] \"sub-224_stroop_test.csv\" \"sub-225_random_dot.csv\" \n[445] \"sub-225_stroop_test.csv\" \"sub-226_random_dot.csv\" \n[447] \"sub-226_stroop_test.csv\" \"sub-227_random_dot.csv\" \n[449] \"sub-227_stroop_test.csv\" \"sub-228_random_dot.csv\" \n[451] \"sub-228_stroop_test.csv\" \"sub-229_random_dot.csv\" \n[453] \"sub-229_stroop_test.csv\" \"sub-230_random_dot.csv\" \n[455] \"sub-230_stroop_test.csv\" \"sub-231_random_dot.csv\" \n[457] \"sub-231_stroop_test.csv\" \"sub-232_random_dot.csv\" \n[459] \"sub-232_stroop_test.csv\" \"sub-233_random_dot.csv\" \n[461] \"sub-233_stroop_test.csv\" \"sub-234_random_dot.csv\" \n[463] \"sub-234_stroop_test.csv\" \"sub-235_random_dot.csv\" \n[465] \"sub-235_stroop_test.csv\" \"sub-236_random_dot.csv\" \n[467] \"sub-236_stroop_test.csv\" \"sub-237_random_dot.csv\" \n[469] \"sub-237_stroop_test.csv\" \"sub-238_random_dot.csv\" \n[471] \"sub-238_stroop_test.csv\" \"sub-239_random_dot.csv\" \n[473] \"sub-240_random_dot.csv\" \n\nlist.files(path = 'data/raw', pattern = 'stroop')\n\n  [1] \"sub-001_stroop_test.csv\" \"sub-002_stroop_test.csv\"\n  [3] \"sub-003_stroop_test.csv\" \"sub-004_stroop_test.csv\"\n  [5] \"sub-005_stroop_test.csv\" \"sub-006_stroop_test.csv\"\n  [7] \"sub-007_stroop_test.csv\" \"sub-008_stroop_test.csv\"\n  [9] \"sub-009_stroop_test.csv\" \"sub-010_stroop_test.csv\"\n [11] \"sub-011_stroop_test.csv\" \"sub-012_stroop_test.csv\"\n [13] \"sub-013_stroop_test.csv\" \"sub-014_stroop_test.csv\"\n [15] \"sub-015_stroop_test.csv\" \"sub-016_stroop_test.csv\"\n [17] \"sub-017_stroop_test.csv\" \"sub-018_stroop_test.csv\"\n [19] \"sub-019_stroop_test.csv\" \"sub-020_stroop_test.csv\"\n [21] \"sub-021_stroop_test.csv\" \"sub-022_stroop_test.csv\"\n [23] \"sub-023_stroop_test.csv\" \"sub-024_stroop_test.csv\"\n [25] \"sub-025_stroop_test.csv\" \"sub-026_stroop_test.csv\"\n [27] \"sub-027_stroop_test.csv\" \"sub-028_stroop_test.csv\"\n [29] \"sub-029_stroop_test.csv\" \"sub-030_stroop_test.csv\"\n [31] \"sub-031_stroop_test.csv\" \"sub-032_stroop_test.csv\"\n [33] \"sub-033_stroop_test.csv\" \"sub-034_stroop_test.csv\"\n [35] \"sub-035_stroop_test.csv\" \"sub-036_stroop_test.csv\"\n [37] \"sub-037_stroop_test.csv\" \"sub-038_stroop_test.csv\"\n [39] \"sub-040_stroop_test.csv\" \"sub-041_stroop_test.csv\"\n [41] \"sub-042_stroop_test.csv\" \"sub-043_stroop_test.csv\"\n [43] \"sub-044_stroop_test.csv\" \"sub-045_stroop_test.csv\"\n [45] \"sub-046_stroop_test.csv\" \"sub-047_stroop_test.csv\"\n [47] \"sub-048_stroop_test.csv\" \"sub-049_stroop_test.csv\"\n [49] \"sub-050_stroop_test.csv\" \"sub-051_stroop_test.csv\"\n [51] \"sub-052_stroop_test.csv\" \"sub-053_stroop_test.csv\"\n [53] \"sub-054_stroop_test.csv\" \"sub-055_stroop_test.csv\"\n [55] \"sub-057_stroop_test.csv\" \"sub-058_stroop_test.csv\"\n [57] \"sub-059_stroop_test.csv\" \"sub-060_stroop_test.csv\"\n [59] \"sub-061_stroop_test.csv\" \"sub-062_stroop_test.csv\"\n [61] \"sub-063_stroop_test.csv\" \"sub-064_stroop_test.csv\"\n [63] \"sub-065_stroop_test.csv\" \"sub-066_stroop_test.csv\"\n [65] \"sub-067_stroop_test.csv\" \"sub-068_stroop_test.csv\"\n [67] \"sub-069_stroop_test.csv\" \"sub-070_stroop_test.csv\"\n [69] \"sub-071_stroop_test.csv\" \"sub-072_stroop_test.csv\"\n [71] \"sub-073_stroop_test.csv\" \"sub-074_stroop_test.csv\"\n [73] \"sub-075_stroop_test.csv\" \"sub-076_stroop_test.csv\"\n [75] \"sub-077_stroop_test.csv\" \"sub-078_stroop_test.csv\"\n [77] \"sub-079_stroop_test.csv\" \"sub-080_stroop_test.csv\"\n [79] \"sub-082_stroop_test.csv\" \"sub-083_stroop_test.csv\"\n [81] \"sub-084_stroop_test.csv\" \"sub-085_stroop_test.csv\"\n [83] \"sub-086_stroop_test.csv\" \"sub-087_stroop_test.csv\"\n [85] \"sub-088_stroop_test.csv\" \"sub-089_stroop_test.csv\"\n [87] \"sub-090_stroop_test.csv\" \"sub-091_stroop_test.csv\"\n [89] \"sub-092_stroop_test.csv\" \"sub-093_stroop_test.csv\"\n [91] \"sub-094_stroop_test.csv\" \"sub-095_stroop_test.csv\"\n [93] \"sub-096_stroop_test.csv\" \"sub-097_stroop_test.csv\"\n [95] \"sub-098_stroop_test.csv\" \"sub-099_stroop_test.csv\"\n [97] \"sub-100_stroop_test.csv\" \"sub-101_stroop_test.csv\"\n [99] \"sub-102_stroop_test.csv\" \"sub-103_stroop_test.csv\"\n[101] \"sub-104_stroop_test.csv\" \"sub-105_stroop_test.csv\"\n[103] \"sub-106_stroop_test.csv\" \"sub-107_stroop_test.csv\"\n[105] \"sub-108_stroop_test.csv\" \"sub-109_stroop_test.csv\"\n[107] \"sub-110_stroop_test.csv\" \"sub-111_stroop_test.csv\"\n[109] \"sub-112_stroop_test.csv\" \"sub-113_stroop_test.csv\"\n[111] \"sub-114_stroop_test.csv\" \"sub-115_stroop_test.csv\"\n[113] \"sub-116_stroop_test.csv\" \"sub-117_stroop_test.csv\"\n[115] \"sub-118_stroop_test.csv\" \"sub-119_stroop_test.csv\"\n[117] \"sub-120_stroop_test.csv\" \"sub-121_stroop_test.csv\"\n[119] \"sub-122_stroop_test.csv\" \"sub-123_stroop_test.csv\"\n[121] \"sub-124_stroop_test.csv\" \"sub-125_stroop_test.csv\"\n[123] \"sub-126_stroop_test.csv\" \"sub-127_stroop_test.csv\"\n[125] \"sub-128_stroop_test.csv\" \"sub-129_stroop_test.csv\"\n[127] \"sub-130_stroop_test.csv\" \"sub-131_stroop_test.csv\"\n[129] \"sub-132_stroop_test.csv\" \"sub-133_stroop_test.csv\"\n[131] \"sub-134_stroop_test.csv\" \"sub-135_stroop_test.csv\"\n[133] \"sub-136_stroop_test.csv\" \"sub-137_stroop_test.csv\"\n[135] \"sub-138_stroop_test.csv\" \"sub-139_stroop_test.csv\"\n[137] \"sub-140_stroop_test.csv\" \"sub-141_stroop_test.csv\"\n[139] \"sub-142_stroop_test.csv\" \"sub-143_stroop_test.csv\"\n[141] \"sub-144_stroop_test.csv\" \"sub-145_stroop_test.csv\"\n[143] \"sub-146_stroop_test.csv\" \"sub-147_stroop_test.csv\"\n[145] \"sub-148_stroop_test.csv\" \"sub-149_stroop_test.csv\"\n[147] \"sub-150_stroop_test.csv\" \"sub-151_stroop_test.csv\"\n[149] \"sub-152_stroop_test.csv\" \"sub-153_stroop_test.csv\"\n[151] \"sub-154_stroop_test.csv\" \"sub-155_stroop_test.csv\"\n[153] \"sub-156_stroop_test.csv\" \"sub-157_stroop_test.csv\"\n[155] \"sub-158_stroop_test.csv\" \"sub-159_stroop_test.csv\"\n[157] \"sub-160_stroop_test.csv\" \"sub-161_stroop_test.csv\"\n[159] \"sub-162_stroop_test.csv\" \"sub-163_stroop_test.csv\"\n[161] \"sub-164_stroop_test.csv\" \"sub-165_stroop_test.csv\"\n[163] \"sub-167_stroop_test.csv\" \"sub-168_stroop_test.csv\"\n[165] \"sub-169_stroop_test.csv\" \"sub-170_stroop_test.csv\"\n[167] \"sub-171_stroop_test.csv\" \"sub-172_stroop_test.csv\"\n[169] \"sub-173_stroop_test.csv\" \"sub-174_stroop_test.csv\"\n[171] \"sub-175_stroop_test.csv\" \"sub-176_stroop_test.csv\"\n[173] \"sub-177_stroop_test.csv\" \"sub-178_stroop_test.csv\"\n[175] \"sub-179_stroop_test.csv\" \"sub-180_stroop_test.csv\"\n[177] \"sub-181_stroop_test.csv\" \"sub-182_stroop_test.csv\"\n[179] \"sub-183_stroop_test.csv\" \"sub-184_stroop_test.csv\"\n[181] \"sub-185_stroop_test.csv\" \"sub-186_stroop_test.csv\"\n[183] \"sub-187_stroop_test.csv\" \"sub-188_stroop_test.csv\"\n[185] \"sub-189_stroop_test.csv\" \"sub-190_stroop_test.csv\"\n[187] \"sub-191_stroop_test.csv\" \"sub-192_stroop_test.csv\"\n[189] \"sub-193_stroop_test.csv\" \"sub-194_stroop_test.csv\"\n[191] \"sub-195_stroop_test.csv\" \"sub-196_stroop_test.csv\"\n[193] \"sub-197_stroop_test.csv\" \"sub-198_stroop_test.csv\"\n[195] \"sub-199_stroop_test.csv\" \"sub-200_stroop_test.csv\"\n[197] \"sub-201_stroop_test.csv\" \"sub-202_stroop_test.csv\"\n[199] \"sub-203_stroop_test.csv\" \"sub-204_stroop_test.csv\"\n[201] \"sub-205_stroop_test.csv\" \"sub-206_stroop_test.csv\"\n[203] \"sub-207_stroop_test.csv\" \"sub-208_stroop_test.csv\"\n[205] \"sub-209_stroop_test.csv\" \"sub-210_stroop_test.csv\"\n[207] \"sub-211_stroop_test.csv\" \"sub-212_stroop_test.csv\"\n[209] \"sub-213_stroop_test.csv\" \"sub-214_stroop_test.csv\"\n[211] \"sub-215_stroop_test.csv\" \"sub-216_stroop_test.csv\"\n[213] \"sub-217_stroop_test.csv\" \"sub-218_stroop_test.csv\"\n[215] \"sub-219_stroop_test.csv\" \"sub-220_stroop_test.csv\"\n[217] \"sub-221_stroop_test.csv\" \"sub-222_stroop_test.csv\"\n[219] \"sub-223_stroop_test.csv\" \"sub-224_stroop_test.csv\"\n[221] \"sub-225_stroop_test.csv\" \"sub-226_stroop_test.csv\"\n[223] \"sub-227_stroop_test.csv\" \"sub-228_stroop_test.csv\"\n[225] \"sub-229_stroop_test.csv\" \"sub-230_stroop_test.csv\"\n[227] \"sub-231_stroop_test.csv\" \"sub-232_stroop_test.csv\"\n[229] \"sub-233_stroop_test.csv\" \"sub-234_stroop_test.csv\"\n[231] \"sub-235_stroop_test.csv\" \"sub-236_stroop_test.csv\"\n[233] \"sub-237_stroop_test.csv\" \"sub-238_stroop_test.csv\"\n\n\nUm die Files einzulesen, reichen nur die Namen der Dateien nicht aus. Dazu benötigen wir die kompletten Pfade.\n\nfiles &lt;- list.files(path = 'data/raw/', pattern = 'stroop') %&gt;% \n    paste('data/raw/', ., sep = '')\n\n\nHier wird die Pipe des magritter-Packages verwendet (%&gt;%) statt die Base-R Pipe (|&gt;). Mit %&gt;% haben wir die Möglichkeit mit dem . zu bestimmen wo die weitergeleiteten Inhalte der Pipe eingefügt werden (nach data/). Informationen zu den Unterschieden der Pipes finden Sie hier.\n\n\n9.4.1 Alle Files von Hand einlesen\nJedes Daten File wird einzeln eingelesen. Anschliessend müssen alle Files zusammengefügt werden. Diese Lösung ist einfach zu verstehen, ist bei vielen Dokumenten aber zu aufwändig.\n\nfile1 &lt;- files[1]\nfile2 &lt;- files[2]\nfile3 &lt;- files[3]\n\nd1 &lt;- read_stroop(file1)\n\nRows: 161 Columns: 110\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (77): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd2 &lt;- read_stroop(file2)\n\nRows: 161 Columns: 111\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (78): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd3 &lt;- read_stroop(file3)\n\nRows: 161 Columns: 111\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (21): wordCTK, colorCTK, corrAnsCTK, keyResp_CTK.keys, wordPractice, col...\ndbl (78): congruentCTK, thisN, thisTrialN, thisRepN, keyResp_CTK.corr, keyRe...\nlgl (12): keyResp_CTK.duration, respPractice.duration, keyResp_test_run.dura...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nd_hand &lt;- bind_rows(d1, d2, d3)\n\n\n\n9.4.2 Alle Files mit for-Loop einlesen\nDas Einlesen kann mit einem for-Loop automatisiert werden. Der Loop iteriert über alle Daten Files. Als erstes muss ein leerer Data Frame d_loop erstellt werden. Bei jeder Iteration des Loops wird ein Daten File eingelesen und dem erstellten Data Frame d_loop angehängt.\n\nd_loop &lt;- tibble()\n\nfor (file in files){\n    d_tmp &lt;- read_stroop(file)\n    d_loop &lt;- bind_rows(d_loop, d_tmp)\n}\n\n\n\n9.4.3 Alle Files mit der Funktion map() einlesen\nmap() wendet eine Funktion auf alle Elemente eines Vektors an. Der Vektor files enthält die Pfade zu den Daten Files. Mit map() können wir also unsere selbst erstellte Funktion read_stroop() auf jeden Pfad anwenden. Im Anschluss müssen die Dataframes noch verbunden werden.\n\nd_map1 &lt;- files |&gt;\n    map(read_stroop) %&gt;%\n    bind_rows()\n\nDie Funktion map_dfr() macht das gleiche wie map() fügt aber zusätzlich die einzelnen Data Frames automatisch zusammen.\n\nd_map2 &lt;- files |&gt;\n    map_dfr(read_stroop)\n\n\n\n\n\n\n\n\nHands-on 2: map Funktion anweden\n\n\n\nBenutzen Sie die Funktion map() um unsere Funktion fast_correct() gleichzeitig auf d1, d2 und d3 anzuwenden.\nTIPP: map() braucht als Argument eine Liste!",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#kompletter-stroop-code-an-einem-ort",
    "href": "datawrangling_automatisiert.html#kompletter-stroop-code-an-einem-ort",
    "title": "9  Automatisiertes Preprocessing",
    "section": "9.5 Kompletter Stroop Code an einem Ort",
    "text": "9.5 Kompletter Stroop Code an einem Ort\n\nread_stroop &lt;- function(path){\n    d_stroop &lt;- read_csv(path) |&gt;\n    filter(!is.na(trials_test.thisN)) |&gt;\n    mutate(trial = trials_test.thisN + 1,\n           condition = case_when(congruent == 1 ~ \"congruent\",\n                                 congruent == 0 ~ \"incongruent\")) |&gt;\n    select(id = participant, \n           trial,\n           word, \n           color, \n           congruent, \n           condition,\n           resp = keyResp_test_run.keys, \n           corr = keyResp_test_run.corr, \n           rt = keyResp_test_run.rt)\n    d_stroop\n}\n\nd &lt;- list.files(path = 'data/raw/', pattern = 'stroop') %&gt;% \n    paste('data/raw/', ., sep = '') |&gt;\n    map_dfr(read_stroop)\n\nd |&gt; write.csv(file = \"data/clean/dataset_stroop_clean.csv\", row.names = FALSE) # neuer Datensatz in anderen Ordner speichern um Verdoppelung zu vermeiden\n\n\nAchten Sie darauf, den neu erstellten Datensatz nicht in den raw-Ordner zu speichern. Sonst wird er (weil er stroop im Namen hat) beim nächsten Ausführen der Funktion read_stroop ebenfalls eingelesen, was einen Fehler verursacht.\n\n\n\n\n\n\n\nHands-on Lösungen\n\n\n\n\n\n\n9.5.1 Hands-on 1\n\nfast_correct &lt;- function(data){\n  d &lt;- data %&gt;% \n    filter(rt&lt;0.5)\n  p &lt;- mean(d$corr) * 100   \n  return(p)\n}\n\nfast_correct(d_stroop)\n\n[1] 100\n\n\n\n\n9.5.2 Hands-on 2\n\ndata_list &lt;- list(d1, d2, d3)\n\ndata_list |&gt; \n    map(fast_correct)\n\n[[1]]\n[1] 89.65517\n\n[[2]]\n[1] 100\n\n[[3]]\n[1] 100",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "datawrangling_automatisiert.html#footnotes",
    "href": "datawrangling_automatisiert.html#footnotes",
    "title": "9  Automatisiertes Preprocessing",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden!↩︎",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Automatisiertes Preprocessing</span>"
    ]
  },
  {
    "objectID": "uebung_2.html",
    "href": "uebung_2.html",
    "title": "Übung 2",
    "section": "",
    "text": "Auftrag\nArbeiten Sie die Datenvorverarbeitungsschritte im Kapitel Daten importieren und vorverarbeiten durch.",
    "crumbs": [
      "Data wrangling",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebung_2.html#abgabetermin",
    "href": "uebung_2.html#abgabetermin",
    "title": "Übung 2",
    "section": "Abgabetermin",
    "text": "Abgabetermin\nBei dieser Übung muss nichts abgegeben werden.\nBeim Termin vom 14. März 2024 werden wir jedoch stark auf dieses Vorwissen aufbauen.",
    "crumbs": [
      "Data wrangling",
      "Übung 2"
    ]
  },
  {
    "objectID": "uebung_2.html#trouble-shooting",
    "href": "uebung_2.html#trouble-shooting",
    "title": "Übung 2",
    "section": "Trouble shooting",
    "text": "Trouble shooting\nSie dürfen gerne in den Pausen der vorherigen Termine auf uns zukommen, falls etwas nicht klappt oder Sie eine Frage haben.\nFalls Sie zusätzliche Übungsaufgaben wünschen, finden Sie hier weitere Aufgaben:\n\nWalk-through mit Lösungen\nÜbungsaufgaben\n\nSie können auch Kurse auf DataCamp besuchen, z.B.\n👉🏼 Introduction to R",
    "crumbs": [
      "Data wrangling",
      "Übung 2"
    ]
  },
  {
    "objectID": "data_visualization_1.html",
    "href": "data_visualization_1.html",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "",
    "text": "10.1 Daten\nDie wichtigste Komponente einer Grafik sind die Daten. Bevor eine Grafik erstellt wird, müssen die Eigenschaften des Datensatzes bekannt sein.\n# Einlesen des Datensatzes\nd &lt;- read.csv(\"data/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition)) # Variable condition zu Faktor konvertieren\n\n# Datensatz anschauen\nglimpse(d)\n\nRows: 1,846\nColumns: 3\n$ condition &lt;fct&gt; away, away, away, away, away, away, away, away, away, away, …\n$ value1    &lt;dbl&gt; 32.33111, 53.42146, 63.92020, 70.28951, 34.11883, 67.67072, …\n$ value2    &lt;dbl&gt; 61.411101, 26.186880, 30.832194, 82.533649, 45.734551, 37.11…",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#daten",
    "href": "data_visualization_1.html#daten",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "",
    "text": "Der verwendete Datensatz stammt von Matejka and Fitzmaurice (2017).\n\n\n\n10.1.1 Datenformat\nAm einfachsten ist das Plotten mit ggplot(), wenn die Daten im long-Format vorliegen. Das bedeutet:\n\nJede Variable die gemessen/erhoben wird, hat eine Spalte (z.B. Versuchspersonennummer, Reaktionszeit, Taste).\nJede Messung hat eine Zeile. (In unserem PsychoPy-Experiment entspricht dies einer Zeile pro Trial.)\n\nDie hier eingelesenen Daten sind schon im long-Format.\n\nFalls die Daten im wide-Format abgespeichert sind, lohnt es sich diese umzuformatieren z.B. mit pivot_longer().\n\n\n\n10.1.2 Variablen\nFür die Grafik ist es relevant, welches Skalenniveau die zu visualisierenden Variablen haben. Je nach Anzahl Variablen und den entsprechenden Skalenniveaus eignen sich andere Grafik-Formate. Eine häufige Schwierigkeit beim Visualisieren der Daten ist, dass die Daten nicht das für den gewählten Plot passenden Skalenniveaus haben.\n\n\n\nCC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=724035\n\n\n\n\n\n\n\n\nHands-on: Datensatz anschauen\n\n\n\nSchauen Sie sich den Datensatz an.\n\nWie viele unterschiedliche Variablen gibt es?\nWie heissen die Variablen?\nWelches Skalenniveau haben sie?\n\n\n\n\n\n10.1.3 Subsetting\nWenn nur ein gewisser Teil der Daten visualisiert werden soll, muss der Datensatz gefiltert werden. Der aktuelle Datensatz enthält beispielsweise verschiedene Bedingungen, jeweils mit Werten für Variable value1 und value2. Folgende 13 Bedingungen sind enthalten:\n\nunique(d$condition)\n\n [1] away       bullseye   circle     dino       dots       h_lines   \n [7] high_lines slant_down slant_up   star       v_lines    wide_lines\n[13] x_shape   \n13 Levels: away bullseye circle dino dots h_lines high_lines ... x_shape\n\n\nFürs erste entscheiden wir uns für die Bedingung away.\n\nd_away &lt;- d %&gt;%\n    filter(condition == \"away\")\n\nWir können für diese Bedingung zusätzlich summary statistics berechnen, hier Mittelwert und Standardabweichung.\n\nd_away_summary &lt;- d_away %&gt;%\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1),\n              mean_value2 = mean(value2),\n              sd_value2 = sd(value2))\n\nglimpse(d_away_summary)\n\nRows: 1\nColumns: 4\n$ mean_value1 &lt;dbl&gt; 54.2661\n$ sd_value1   &lt;dbl&gt; 16.76982\n$ mean_value2 &lt;dbl&gt; 47.83472\n$ sd_value2   &lt;dbl&gt; 26.93974\n\n\nDiese Werte geben einen Anhaltspunkt, in welchem Bereich sich die Werte bewegen werden.\n\n\n10.1.4 Plot\nIn den folgenden Beispielen werden die Daten der Bedingung away verwendet. Als erstes Argument wird der Funktion ggplot() der Datensatz übergeben (data = data_away).\n\nggplot(data = d_away)",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#mapping",
    "href": "data_visualization_1.html#mapping",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "10.2 Mapping",
    "text": "10.2 Mapping\nDas mapping beschreibt, welche Variable auf der X- und Y-Achse abgetragen werden sollen. Es wird also definiert, wie die Variablen auf die Formen (aesthetics) gemappt werden sollen. Am einfachsten wird dies zu Beginn in festgelegt (das mapping kann aber auch in der Funktion geom_ selbst definiert werden). Weitere Variablen könnten als Argumente z.B. unter group = ... oder color = ... eingefügt werden.\n\nggplot(data = d_away,\n       mapping = aes(x = value1,\n                     y = value2)) \n\n\n\n\n\n\n\n\nDie Grafik verfügt nun über Achsen, diese werden automatisch mit den Variablennamen beschriftet. Da noch keine Formen (geoms) hinzugefügt wurde ist die Grafik in der Mitte aber leer.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#geom-formen",
    "href": "data_visualization_1.html#geom-formen",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "10.3 Geom / Formen",
    "text": "10.3 Geom / Formen\nAls dritte Komponente wird in ggplot() die Form mit geom_ hinzugefügt. Jede Form, die eingefügt wird, benötigt Angaben zum mapping. Falls kein mapping angegeben wird, wird dieses aus der ggplot()-Funktion in der ersten Zeile übernommen.\nEs stehen viele verschiedene Formen zur Auswahl. Beispielsweise werden mit geom_point() Punkte erstellt, mit geom_line() Linien, mit geom_boxplot Boxplots, usw. Bei der Wahl der passenden Form kommt es einerseits auf die Daten an. Sind die Daten z.B. Faktoren oder numerische Werte (siehe auch Skalenniveau oben)? Wie viele Variablen werden gleichzeitig in die Grafik eingebunden? Andererseits ist es wichtig, was mit der Grafik gezeigt werden soll: Unterschiede? Gemeinsamkeiten? Veränderungen über Zeit?\nGeome zur Visualisierung von Datenpunkten und Verläufen:\n\nPunkte / Scatterplots - geom_point()\nLinien - geom_line()\n\nGeome zur Visualisierung von zusammenfassenden Werten:\n\nHistogramme - geom_histogram()\nMittelwerte und Standardabweichungen - geom_pointrange()\nDichteplots - geom_density()\nBoxplots - geom_boxplot()\nViolinplots - geom_violin()\n\n\nEs gibt auch weitere, sehr informative Arten der Visualisierung, wie heat maps oder shift functions, auf die wir in dieser Veranstaltung nicht eingehen.\n\n\n\n\n\n\n\nHands-on: Geoms\n\n\n\nWelche geoms eignen sich für welches Skalenniveau und welche Variablenanzahl?\nTipps:\n\nSchauen Sie sich den Datensatz mit glimpse(), head() oder summary() an.\nSchauen Sie sich die verschiedenen Formen von Plots hier an. \n\n👉 `{ggplot2}-Cheatsheet zum Herunterladen\n\n\n\n10.3.1 Kombinieren von mehreren geoms in einer Grafik\nTeilweise werden in Visualisierungen mehrere geoms kombiniert. In vielen Fällen macht es beispielsweise Sinn, nicht nur die Rohwerte oder Werte für jedes Subjekt, sondern in derselben Grafik auch zusammenfassende Masse, z.B. einen Boxplot, zu visualisieren.\n\nWeiterführende Info zum Kombinieren von Plots finden Sie hier.\n\nVerwenden verschiedener geoms in einem Plot:\n\nggplot(data = d_away, \n       mapping = aes(x = condition,\n                     y = value2)) +\n    geom_boxplot(width = 0.3) +\n    geom_jitter(width = 0.1) \n\n\n\n\n\n\n\n\nKombiniert werden können aber nicht nur verschiedene Formen, sondern auch mehrere Datensätze. Dies kann in ggplot() einfach umgesetzt werden indem mehrere Geoms übereinandergelegt werden und nicht das mapping aus der ggplot()-Funktion genutzt wird. Stattdessen wird für jedes geom ein separater Datensatz und ein separates mapping spezifiziert.\n\nggplot(data = d_away, \n       mapping = aes(x = condition,\n                     y = value2)) +\n    geom_jitter(width = 0.1) + # verwendet Datensatz \"d_away\"\n    geom_point(data = d_away_summary, # verwendet Datensatz \"d_away_summary\"\n               aes(x = \"away\", y = mean_value1), # condition ist nicht im Datensatz enthalten, deshalb hier hardcoded\n               color = \"red\", # Punkt rot einfärben\n               size = 3) # Punkt vergrössern",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#beschriftungen-und-themes",
    "href": "data_visualization_1.html#beschriftungen-und-themes",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "10.4 Beschriftungen und Themes",
    "text": "10.4 Beschriftungen und Themes\nSchönere und informativere Plots lassen sich gestalten, wenn wir einen Titel hinzufügen, die Achsenbeschriftung anpassen und das theme verändern:\n\nggplot(data = d_away,\n       mapping = aes(x = value1,\n                     y = value2)) +\n    geom_point() +\n    labs(title = \"Ein etwas schönerer Plot\", \n         subtitle = \"Verteilung der Rohwerte\",\n        x = \"Wert 1  [a.u.]\",\n        y = \"Wert 2 [a.u.]\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\nAuch theme_classic() oder theme_bw() ergeben schlichte aber schöne Plots.\n\n\n\n\n\n\n\nHands-on\n\n\n\nErstellen Sie eine Grafik.\n\nFügen Sie mit labs() passende Beschriftungen hinzu. Gibt es noch weitere, oben nicht verwendete Optionen?\nWechseln Sie das theme. Welches gefällt Ihnen am besten?\n\ntheme_bw()\ntheme_classic()\ntheme_dark()\n… (schreiben Sie theme_ und drücken Sie Tab, um weitere Vorschläge zu sehen.)",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#daten-plotten-tipps-und-tricks",
    "href": "data_visualization_1.html#daten-plotten-tipps-und-tricks",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "10.5 Daten plotten: Tipps und Tricks",
    "text": "10.5 Daten plotten: Tipps und Tricks\n\n\n\n\n\n\nHands-on: Informative Grafik erstellen\n\n\n\nIm Folgenden können Sie den Datensatz mit Grafiken erkunden.\nSie können entweder in Ihrem RScript / RNotebook weiterarbeiten oder Sie können ein GUI (graphical user interface) verwenden, dass für Sie den Code schreibt.\n\nWelche geom_s/Formen eignen sich gut für diesen Datensatz?\nWelche Abbildungen können alle 3 Variablen des Datensatzes berücksichtigen?\nWie kann man Bedingungen miteinander vergleichen?\nWie können Grösse und Farbe der geom_s bestimmt werden?\nWie passt man Schriftgrössen an?\nKönnen Sie eine Grafik speichern?\nLassen Sie sich den Code direkt ins RScript / RNotebook einfügen und verändern Sie den Code dort weiter.\n\n\n\n\n10.5.1 Daten plotten mit esquisser()\nUm in RStudio ein GUI für das Datenvisualisieren zu verwenden, kann das Package {esquisse} genutzt werden.\n\nInstallieren Sie das Package {esquisse} mit install.packages(\"esquisse\") in der Konsole oder über Tools &gt; Install packages...\nGeben Sie in Ihrer Konsole esquisse::esquisser() ein und wählen Sie dann unter Import Data den schon eingelesenen Datensatz DatasaurusDozen.csv aus.\n\n\nEin weiteres R-basiertes Visualisierungstool in welchem der Code per GUI erstellt wird, ist trelliscopejs\n\n\n\n10.5.2 Mehrere Plots in einer Grafik darstellen\nDies können Sie mit dem Package patchwork sehr einfach machen. Sie finden oben oder hier ein Beispiel.\n\nWenn Sie das Package {patchwork} zum ersten Mal nutzen, können Sie es in der Konsole mit install.packages(\"patchwork\") installieren.\n\n\n\n10.5.3 Grafik abspeichern\nEine Grafik lässt sich abspeichern unter dem Reiter Plots &gt; Export oder mit der Funktion ggsave().\n\n\n10.5.4 Inspiration\n\nGrafiken für verschiedene Datenarten: From Data to Viz\nSimple bis crazy Chartideen: R Charts: Ggplot\nFarben für Grafiken: R Charts: Colors, noch mehr Farben\n\n\n\n10.5.5 Weiterführende Ressourcen zur Datenvisualisierung mit ggplot()\n\nDokumentation von ggplot2\nKurzweilige, kompakte und sehr informative Informationen und Videos über das Erstellen von Grafiken in ggplot finden Sie hier: Website PsyTeachR: Data Skills for reproducible research\nHier ist der Start der PsyTeachR Videoliste von Lisa deBruine, dort finden sich auch hilfreiche Kurzvideos zu Themen von Daten einlesen bis zu statistischen Analysen. Beispielsweise zu Basic Plots, Common Plots und Plot Themes and Customization\nEinführung in R von Andrew Ellis und Boris Mayer\n\n\n\n\n\nMatejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 1290–94. Denver Colorado USA: ACM. https://doi.org/10.1145/3025453.3025912.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_1.html#footnotes",
    "href": "data_visualization_1.html#footnotes",
    "title": "10  Datenvisualisierung mit ggplot2",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden!↩︎",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Datenvisualisierung mit ggplot2</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html",
    "href": "data_visualization_2.html",
    "title": "11  Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "11.1 Diagnostik: Daten untersuchen\nDatensätze können sehr komplex sein, deshalb ist die Visualisierung der Daten ein hilfreicher erster Schritt. Mit Hilfe von Visualisierungen können Aussagen über die Qualität der Daten gemacht werden, z.B. über:\nDiagnostische Grafiken dienen dazu, rasch an Informationen zu können und Probleme in Datensätzen zu entdecken. Die Grafiken müssen daher nicht ästhetisch ansprechend oder für Aussenstehende verständlich sein. Im Sinne der Reproduzierbarkeit lohnt es sich aber, auch diese Visualisierungen gut zu dokumentieren.\nIm Folgenden schauen wir uns Beispiele für diagnostische Grafiken an.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#diagnostik-daten-untersuchen",
    "href": "data_visualization_2.html#diagnostik-daten-untersuchen",
    "title": "11  Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "Fehlende Werte\nAufgabenschwierigkeit\nExtreme Datenpunkte (Ausreisser)\nZeitverläufe\nVerteilung der Daten\n\n\n\n\n11.1.1 Fehlende Werte\nHierbei ist es wichtig, vor allem systematisch fehlende Datenpunkte zu entdecken: Fehlt bei einer Person die Hälfte der Antworten? Möchten wir diese ausschliessen?\nDiese können mit dem Package {naniar} relativ schnell sichtbar gemacht werden. Es gibt keine missings in unserem Fall.\n\nnaniar::vis_miss(d)\n\n\n\n\n\n\n\n\n\nBevor Sie das Package verwenden können, müssen Sie dies erst herunterladen. Sie können dies unter dem Reiter Tools &gt; Install Packages ... tun oder in der Konsole mit install.packages(\"naniar\").\n\nFür die Analyse schliessen wir alle Reaktionszeiten unter 100ms und über 8 Sekunden aus.\n\n# zu schnelle und zu langsame Antworten ausschliessen\nd &lt;- d |&gt;\n    filter(rt &gt; 0.099 & rt &lt; 8)\n\nWir berechnen nun für die kommenden Grafiken die Anzahl Trials pro Person, die accuracy, sowie die mittlere Reaktionszeit für die Bedingungen congruent und incongruent (wie im Kapitel Aggregierte Statistiken beschrieben).\n\n# Daten gruppieren:  Anzahl Trials, Accuracy und mittlere Reaktionszeit berechnen\nacc_rt_individual &lt;- d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\nacc_rt_individual\n\n# A tibble: 468 × 6\n# Groups:   id [234]\n   id      condition       N ncorrect accuracy median_rt\n   &lt;fct&gt;   &lt;fct&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 sub-001 congruent      60       56    0.933     0.487\n 2 sub-001 incongruent    60       55    0.917     0.535\n 3 sub-002 congruent      60       60    1         0.544\n 4 sub-002 incongruent    60       54    0.9       0.619\n 5 sub-003 congruent      60       59    0.983     0.704\n 6 sub-003 incongruent    60       59    0.983     0.708\n 7 sub-004 congruent      60       60    1         0.606\n 8 sub-004 incongruent    60       49    0.817     0.778\n 9 sub-005 congruent      60       58    0.967     0.616\n10 sub-005 incongruent    60       35    0.583     0.863\n# ℹ 458 more rows\n\n\nNachdem wir Trials ohne Antwort ausgeschlossen haben, interessiert es uns, wie viele Trials jede Versuchsperson gelöst hat:\n\n# Plot: Anzahl Trials pro Bedingung für jede Versuchsperson \nacc_rt_individual |&gt; \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einfügen\n    theme_minimal()\n\n\n\n\n\n\n\n\nWir könnten alle Personen ausschliessen, die weniger als 40 gültige Trials hatten (in unserem Beispiel nicht nötig, da alle genügend Trials haben).\n\n\n\n\n\n\nCode: Daten ausschliessen\n\n\n\n\n\n\n# Datensatz mit allen Ids, welche zuwenig Trials hatten\nn_exclusions &lt;- acc_rt_individual |&gt;\n    filter(N &lt; 40) \n\n# Aus dem Hauptdatensatz diese Ids ausschliessen\nd &lt;- d |&gt;\n    filter(!id %in% n_exclusions$id) \n\n# Check\nd_acc_rt_individual &lt;- d |&gt;\n    group_by(id, condition) |&gt;\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\n\nd_acc_rt_individual |&gt; \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einfügen\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.1.2 Extreme Datenpunkte (Ausreisser)\nWir können Visualisierungen auch verwenden, um extreme Datenpunkte zu identifizieren. Dafür teilen wir hier die Accuracywerte in 3 Gruppen ein und plotten diese:\n\n# Trials nach accuracy einteilen\nd_acc_rt_individual_grouped &lt;- d_acc_rt_individual %&gt;% \n  mutate(\n    performance = case_when(\n      accuracy &gt; 0.75 ~ \"good\",\n      accuracy &lt; 0.40 ~ \"bad\",\n      TRUE ~ \"ok\") %&gt;% \n      factor(levels = c(\"good\", \"ok\", \"bad\")))\n\n# Outlier visualisieren\nd_acc_rt_individual_grouped %&gt;% \n    ggplot(aes(x = id, y = accuracy, color = performance, shape = performance)) +\n    geom_point(size = 2, alpha = 0.6) + \n    geom_point(data = filter(d_acc_rt_individual_grouped, performance != \"OK\"), \n               alpha = 0.9) + \n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray40\", \"steelblue\", \"red\")) +\n    geom_hline(yintercept = 0.33, linetype='dotted', col = 'black')+\n    annotate(\"text\", x = \"sub-100\", y = 0.33, label = \"chance level\", vjust = -1, size = 3) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\nDasselbe könnte man für die Reaktionszeiten machen. Informationen dazu, wie Ausreisser in Reaktionszeiten gefunden und visualisiert werden können, finden Sie hier.\n\n\n\n11.1.3 Werte löschen\nEs können einzelne Trials oder auch die gesamten Daten einer Versuchsperson ausgeschlossen werden, weil z.B. die Accuracy zu tief war, fehlende Werte bestanden, etc.\nHierbei ist wichtig:\n\nDatenpunkte werden nie aus den Rohdaten gelöscht, sondern nur aus dem aktuell geladenen Datensatz, welcher für die Analysen verwendet und neu abgespeichert wurde. So können wir uns immer noch umentscheiden und verlieren nicht die Information, welche Daten gefehlt haben.\nDadurch, dass die Datenverarbeitung in R mit reproduzierbarem Code geschrieben ist, können wir immer überprüfen, ob ein Fehler in unserer Datenverarbeitung zu den missings geführt hat und diesen evtl. korrigieren.\nEs macht nicht immer Sinn die Trials mit missing data zu löschen! Dies muss von Fall zu Fall entschieden werden. Wenn Versuchspersonen zum Beispiel teilweise zu lange brauchten um eine Aufgabe zu lösen, dann ist das eine wichtige Information, wird diese rausgelöscht, wird die Leistung der Versuchsperson systematisch überschätzt.\n\nIn unserem Beispiel macht es Sinn, die drei Versuchspersonen, die extrem tiefe Accuracy hatten (wahrscheinlich weil sie die Aufgabe falsch verstanden hatten) vor den Analysen aus dem Datensatz auszuschliessen.Zuerst schauen wir uns an, welche Versuchspersonen sehr tiefe accuracy-Werte hatten:\n\nacc_rt_individual |&gt;\n    filter(accuracy &lt; 0.33) # 0.33 ist das chance level\n\n# A tibble: 3 × 6\n# Groups:   id [3]\n  id      condition       N ncorrect accuracy median_rt\n  &lt;fct&gt;   &lt;fct&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 sub-009 incongruent    60        4   0.0667     1.25 \n2 sub-180 incongruent    60        1   0.0167     0.653\n3 sub-201 incongruent    60        1   0.0167     0.629\n\n\nDann schliessen wir diese 3 Personen aus. Hierbei empfiehlt es sich, den Code so zu kommentieren, dass man später direkt sieht, weshalb eine Person ausgeschlossen wurde.\n\n# Aussschluss dieser Personen\nd &lt;- d |&gt;\n    filter(id != \"sub-009\") |&gt; # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n    filter(id != \"sub-180\") |&gt; # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n    filter(id != \"sub-201\") # Ausschluss wegen zu tiefer Accuracy (&lt; 0.33)\n\n\n\n11.1.4 Verlaufseffekte: Ermüdung und Lernen\nVerlaufseffekte sind relevant, wenn man z.B. Ermüdungs- oder Lerneffekte ausschliessen möchte. Sie könnten aber auch inhaltlich interessant sein, z.B. in einem Trainingskontext, wenn man sich dafür interessiert, wie viele Trials nötig sind, damit sich jemand in einer Aufgabe verbessert.\nIn unserem Experiment möchten wir sicher sein, dass die Performanz sich über die Zeit hinweg nicht zu stark verändert. Hierzu können wir beispielsweise die accuracy plotten:\n\nd_acc_rt_trial &lt;- d |&gt;\n    group_by(condition, trial) |&gt;\n    summarise(\n        accuracy = mean(corr),\n        median_rt = median(rt)\n        )\n\nd_acc_rt_trial |&gt;\n    ggplot(aes(x = trial, y = accuracy, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nOder wir können uns die Reaktionszeiten über die Zeit hinweg anschauen.\n\nd_acc_rt_trial |&gt;\n    ggplot(aes(x = trial, y = median_rt, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nDas tun wir hier für 3 Versuchspersonen.\n\n# Plot: Reaktionszeit über die Trials hinweg (für 3 Versuchspersonen)\nd |&gt;\n    filter(id %in% c(\"sub-001\", \"sub-100\", \"sub-150\")) |&gt;\n    ggplot(aes(x = trial, y = rt, color = condition)) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_point(alpha = 0.5) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    facet_wrap(~ id) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n11.1.5 Aufgabenschwierigkeit und Performanz der Versuchspersonen\nBevor wir die Daten analysieren, möchten wir wissen, ob die Personen die Aufgabe einigermassen gut lösen konnten (und wollten). In unserem Experiment erwarten wir eine Genauigkeit (accuracy) über dem Rateniveau von 33%. Wir plotten hierfür die accuracy für jede Person und Bedingung.\n\n# Plot accuracy per person and condition\np1 &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Proportion correct\",\n         title = \"Accuracy\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np2 &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = median_rt, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\nlibrary(patchwork)\n\np1 + p2\n\n\n\n\n\n\n\n\nUnd wir interessieren uns, wie sich die accuracy zwischen den Bedingungen unterscheidet. Das zeigt uns, ob die Instruktion eine Wirkung hatte. Dafür fügen wir Linien ein, die die accuracy- Werte pro Versuchsperson verbindet:\n\np3 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = condition, y = accuracy, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Proportion correct\",\n         title = \"Accuracy\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np4 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = condition, y = median_rt, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(x = \"Congruency\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time\",\n         subtitle = \"per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np3 + p4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on: Datenqualität\n\n\n\nBesprechen Sie miteinander, was Sie nun über unsere Daten wissen.\n\nHaben die Versuchspersonen die Aufgaben lösen können?\nWar die Aufgabe zu einfach, zu schwierig?\nDenken Sie, die Personen waren motiviert?\nWelche Datensätze / Trials möchten wir ausschliessen? (Achtung: Dies müsste eigentlich vor dem Anschauen der Daten entschieden werden, um zu verhindern, dass man Datenpunkte ausschliesst, welche die Hypothese nicht bestätigen.)\nWie gut eignen sich die Daten, um die Forschungsfrage zu beantworten?\nWas könnte bei einem nächsten Experiment besser gemacht werden?",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#analyse-daten-zusammenfassen-und-explorieren",
    "href": "data_visualization_2.html#analyse-daten-zusammenfassen-und-explorieren",
    "title": "11  Grundlagen der Datenvisualisierung",
    "section": "11.2 Analyse: Daten zusammenfassen und explorieren",
    "text": "11.2 Analyse: Daten zusammenfassen und explorieren\nGrafiken können einerseits eine Ergänzung zur statistischen Datenanalyse sein, wie auch die Resultate der Analysen (bspw. geschätzte Parameterwerte) visualisieren. Sie haben den Vorteil, dass Informationen über Daten oder Analyseergebnisse gleichzeitig ersichtlich sind, sie können also vom Betrachtenden direkt verglichen werden.\nWir möchten die Daten hinsichtlich der Forschungsfragen visualisieren. Die Grafiken müssen vor allem präzise und informativ sein. Um Schlüsse aus Daten ziehen zu können, müssen diese zusammengefasst werden. Dazu eignen sich Lagemasse oder Masse der zentralen Tendenz, also beispielsweise der Mittelwert, Median oder Modus. Gleichzeitig ist es wichtig, dass auch Verteilungsmasse berichtet werden, wie Standardabweichungen oder Standardfehler. Wir können auch mit Werte aus statistischen Modellen, wie Parameterschätzungen und Konfidenzintervalle, grafisch darstellen.\nMit Hilfe von Visualisierungen können z.B. Aussagen können gemacht werden über:\n\nVerteilung der Daten\nZusammenhänge von Variablen (Korrelationen, Zeitverläufe)\nVergleiche und Unterschiede von Gruppen / Bedingungen\n\n\n11.2.1 Verteilung der Rohdaten\nDaten von neurowissenschaftlichen Studien können wichtige Informationen enthalten, die ohne Grafiken übersehen werden können (Rousselet, Pernet, and Wilcox (2017)). Das Visualisieren kann Muster zum Vorschein bringen, die durch statistische Auswertungen nicht sichtbar sind. Die Wichtigkeit von Datenvisualisierung für das Entdecken von Mustern in den Daten zeigte Francis Anscombe 1973 mit dem Anscombe’s Quartet. Dies diente als Inspiration für das Erstellen des “künstlichen” Datensatzes DatasaurusDozen, welchen wir in der letzten Veranstaltung visualisiert haben. Verschiedene Rohwerte, können dieselben Mittelwerte, Standardabweichungen und Korrelationen ergeben. Nur wenn man die Rohwerte plottet erkennt man, wie unterschiedlich die Datenpunkte verteilt sind.\nDies wird ersichtlich, wenn wir die Mittelwerte und Standardabweichungen für jede Gruppe berechnen und plotten:\n\n# load DatasaurusDozen dataset\ndino_data &lt;- read.csv(\"data/DatasaurusDozen.csv\") %&gt;%\n    mutate(condition = as.factor(condition))\n\n# Plot mean and standard deviation for value 1 per condition \ndino_data |&gt;   \n    group_by(condition) |&gt;\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1)) |&gt;\n    ggplot(mapping = aes(x = mean_value1,\n                     y = condition)) +\n    geom_point() +\n    geom_errorbar(aes(xmin = mean_value1 - sd_value1, \n                      xmax = mean_value1 + sd_value1), \n                  width = 0.2) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nUnd dann die Rohwerte visualisieren:\n\n# Plot raw values\ndino_data |&gt; \n    ggplot(aes(x = value1, y = value2)) +\n    geom_point(size = 1) +\n    facet_wrap(~condition) +\n    theme_minimal()\n\n\n\n\n\n\n\n\nHier sehen Sie das Ganze animiert:\n\n\n\nDatensatz und Visualisierung von Matejka and Fitzmaurice (2017)\n\n\n\n\n11.2.2 Zentrale Tendenz und Verteilungsmasse\nMasse der zentralen Tendenz sind beispielsweise der Mittelwert, der Median und Modus. Wenn wir uns dafür interessieren, wie sich die accuracy in Bezug auf alle Teilnehmenden verhält, schauen wir uns die zentrale Tendenz über alle Personen hinweg an. Es sollte nie nur die zentrale Tendenz, sondern immer auch ein passendes Verteilungsmass berichtet werden.\nWie oben schon gezeigt können wir dies z.B. mit Boxplots umsetzen Diese zeigen uns den Median und die Quartile sowie Ausreisser an. Eine andere Möglichkeit Verteilungen anzuzeigen sind die Violinplots. Hier wurden mit geom_jitter() auch die Mittelwerte der einzelnen Personen im Plot eingefügt.\n\n# Boxplot\np_boxplot &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.25, width = 0.2) +\n    geom_boxplot(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Boxplot\",\n         x = \"Congruency\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n# Violin Plot\np_violin &lt;- d_acc_rt_individual |&gt; \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.5, width = 0.2) +\n    geom_violin(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Violin Plot\",\n         x = \"Congruency\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np_boxplot + p_violin\n\n\n\n\n\n\n\n\nDas Package {ggridges} bietet die Möglichkeit die Verteilungen zu plotten. Mehr Informationen hierzu finden Sie hier in der Dokumentation.\n\nlibrary(ggridges)\np5 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = accuracy, y = condition, fill = condition)) + geom_density_ridges2(scale = 0.5, alpha = 0.5) +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Accuracy\",\n         x = \"Proportion corect\",\n         y = \"Congruency\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np6 &lt;- d_acc_rt_individual |&gt; \n    ggplot(aes(x = median_rt, y = condition, fill = condition)) + geom_density_ridges2(scale = 1, alpha = 0.5) +\n    scale_fill_manual(values = c(congruent = \"skyblue3\",\n                                 incongruent = \"tomato3\")) +\n    labs(title = \"Median Response Time\",\n         x = \"Median Response Time [s]\",\n         y = \"Congruency\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np5 + p6\n\n\n\n\n\n\n\n\n\n\n11.2.3 Aggregierte Statistiken\nWenn wir Mittelwerte und Standardfehler angeben möchten können wir dies wie folgt tun. Wichtig ist hier, dass wir within-subject Standardfehler berechnen. Genaueres zu den Unterschieden zwischen within- und between-subject Standardfehlern finden Sie hier. Wir verwenden das Package {Rmisc}. Achtung: Da dieses jedoch wegen der Namen der Funktionen oft Namens-Konflikte auslöst, laden wir Rmisc nicht mit der library()-Funktion, sondern stellen es einfach vor die benötigte Funktion, z.B. so Rmisc::summarySEwithin().\n\nd_acc_within &lt;- d |&gt;\n    Rmisc::summarySEwithin(measurevar = \"corr\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np7 &lt;- d_acc_within |&gt;\n    ggplot(aes(x = condition, y = corr, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = corr-se, ymax = corr+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Accuracy\",\n         x = \"Congruency\",\n         y = \"Accuracy\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n\nd_rt_within &lt;- d |&gt;\n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np8 &lt;- d_rt_within |&gt;\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Median Response Time\",\n         x = \"Congruency\",\n         y = \"Median Response Time [s]\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np7 + p8\n\n\n\n\n\n\n\n\n\nHier finden Sie weitere Code-Beispiele für das Plotten von Verteilungsmassen.\nHier finden Sie Informationen, wie Reaktionszeiten zusammengefasst und visualisiert werden könnten.\n\n\n\n11.2.4 Visualisieren von Modellschätzungen\nWenn für die statistische Analyse ein Modell geschätzt wurde, kann auch dies visualisiert werden. Auf diese Form der Visualisierung wird in diesem Kapitel aber nicht eingegangen.\n\nsjPlot: Package zum Plotten von Fixed Effects\nsee: Package zum Visualisieren von Statistischen Modellen",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#kommunikation-forschungsergebnisse-visualisieren",
    "href": "data_visualization_2.html#kommunikation-forschungsergebnisse-visualisieren",
    "title": "11  Grundlagen der Datenvisualisierung",
    "section": "11.3 Kommunikation: Forschungsergebnisse visualisieren",
    "text": "11.3 Kommunikation: Forschungsergebnisse visualisieren\nKommunikation der Ergebnisse findet vor allem in den wissenschaftlichen Artikeln, Postern oder Präsentationen statt. Bei Visualisierungen die der Kommunkation dienen sind folgende Merkmale wichtig:\n\n11.3.1 Beschriftungen\nDie genaue Beschriftung und deren Lesbarkeit ist für diese Form von Grafiken zentral. Achten Sie sich auf Folgendes:\n\nDie Achsenbeschriftungen enthalten die verwendete Variable in Klartext (nicht den R Variablennamen) und wenn zutreffend auch die Masseinheit (z.B. Response Time [ms]). Beschriftungen können Sie einfügen mit labs().\n\n\np_boxplot +\nlabs(title = \"Der Titel der Grafik\", \n     subtitle = \"Der Subtitel der Grafik\",\n     x = \"hier kommt Label x [Masseinheit]\", \n     y = \"hier kommt Label y [Masseinheit]\",\n     caption = \" Hier kommt eine Caption\")\n\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's fill values.\n\n\n\n\n\n\n\n\n\n\nFarben / Formen usw. werden in einer Legende den Gruppen zugeordnet (Ausnahme: wenn Daten von einzelnen Personen geplottet werden, wird die Versuchspersonennummer nicht aufgeführt).\nMasse der zentralen Tendenz und Varianzmasse werden beschrieben (z.B. Standardfehler oder Standardabweichung?)\n\n\n\n11.3.2 Fünf Merkmale einer guten Grafik\nEs gibt unzählige Optionen die eigenen Daten zu visualisieren. Folgende Prinzipien helfen beim Erstellen einer informativen Grafik, die zur Kommunikation der Ergebnisse dient.\n\nDie Punkte 3-5 wurden aus dem Buch “The Visual Display of Quantitative Information” von Edward Tufte, 1986 entnommen.\n\n\n1. Eine Frage beantworten\nJede Grafik sollte mindestens eine teilweise aber auch mehrere Fragen beantworten.\n👉 Welche Frage möchte ich beantworten? Welche Form der Visualisierung beantwortet diese Frage am besten?\nHierbei kann es hilfreich sein den “Arbeitstitel” der Grafik als Frage zu formulieren.\n\n\n2. Zielgruppe berücksichtigen\nBeim Erstellen der Grafik sollte beachtet werden, an wen sich die Grafik richtet. Für eine Präsentation müssen die Achsenbeschriftungen vergrössert und die Grafik simpel gehalten werden. In einem wissenschaftlichen Artikel kann die Grafik komplexer gestaltet werden, da die Lesenden sich mehr Zeit zum Anschauen nehmen können. Zudem sollten hier die Vorgaben des Journals berücksichtigt werden. Auch wichtig ist das Verwenden von “farbenblind-freundlichen” Palletten, rot und grün ist z.B. eine schlechte Wahl.\n👉 Für welchen Zweck / für wen erstelle ich die Grafik? Wie ist das Vorwissen des Zielpublikums?\n\nFür einen Fachartikel lohnt es sich, zu Beginn die Vorgaben der Fachzeitschrift zu berücksichtigen.\n\n\n\n3. Die Daten zeigen\nDas tönt simpel, wird aber oft nicht berücksichtigt. Bei einer Grafik geht es in erster Linie um die Daten. Es sollte die simpelste Form gewählt werden, welche die Informationen vermittelt. Oft braucht es keine ausgefallenen Grafikideen oder neuartigen Formate. Hierbei ist es wichtig, die Art der Daten zu berücksichtigen: Wie viele Variablen sind es? Sind diese kontinuierlich (z.B. Reaktionszeiten) oder diskret (z.B. Experimentalbedingungen)? Wie viele Dimensionen haben meine Daten? Mit zwei Achsen lassen sich zwei Dimensionen darstellen, zusätzlich können mit Farben und Formen noch weitere Dimensionen abgebildet werden (z.B. Millisekunden, Bedingung 1 und Bedingung 2). Es können Rohwerte geplottet werden oder summary statistics (z.B. Mittelwerte, Standardabweichungen)\n👉 Welche Art Grafik eignet sich für meine Frage und meine Daten? Schauen Sie z.B. hier nach oder nutzen Sie das esquisse-Package.\n\nBeispiele für verschiedenen Plots in R sind z.B. histogram, boxplot, violin plot, scatter plot / correlogram, jitter plot, raincloud plot, percentiles / shift functions, area chart, heat map.\n\n\n\n4. Optimieren des data-ink ratios\nDas Daten-Tinte-Verhältnis sollte so optimal wie möglich sein. Das bedeutet, das idealerweise jeder Strich, jeder Punkt, jedes Textfeld Information beinhaltet. Alles was keine Information transportiert oder nur wiederholt kann weggelassen werden.\n👉 Was kann ich weglassen?\n\nIn R kann zum Schluss des Plots + theme_minimal() hinzugefügt werden, dies entfernt u.a. den grauen Hintergrund. Das Grau des Hintergrunds ist Farbe (ink), welche keine Information transportiert, das Weglassen lässt die Grafik ruhiger wirken.\n\n\n\n5. Feedback einholen und revidieren\nDas Erstellen einer guten Grafik ist iterativ, das heisst, sie wird immer wieder überarbeitet, bis sie die Information möglichst einfach, genau aber klar kommuniziert. Hierbei ist Feedback oft unerlässlich.\n👉 Was denken andere über Ihre Grafik?\n\n\n\n\nMatejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics Through Simulated Annealing.” In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, 1290–94. Denver Colorado USA: ACM. https://doi.org/10.1145/3025453.3025912.\n\n\nRousselet, Guillaume A., Cyril R. Pernet, and Rand R. Wilcox. 2017. “Beyond Differences in Means: Robust Graphical Methods to Compare Two Groups in Neuroscience.” European Journal of Neuroscience 46 (2): 1738–48. https://doi.org/10.1111/ejn.13610.",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "data_visualization_2.html#footnotes",
    "href": "data_visualization_2.html#footnotes",
    "title": "11  Grundlagen der Datenvisualisierung",
    "section": "",
    "text": "Für das Entzippen mit Windows machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre RProject-Ordner speichern. Für das Entzippen mit Mac speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre RProject-Ordner speichern und Doppelklicken Sie danach auf den Ordner. Nur entzippte Ordner können einwandfrei verwendet werden!↩︎",
    "crumbs": [
      "Datenvisualisieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Grundlagen der Datenvisualisierung</span>"
    ]
  },
  {
    "objectID": "uebung_3.html",
    "href": "uebung_3.html",
    "title": "Übung 3",
    "section": "",
    "text": "Auftrag\nTeil A: Datapreprocessing-Pipeline  Erstellen Sie eine automatisierte Datenverarbeitungs-Pipeline, die die Daten des Random Dot Experiments einlesen und vorverarbeiten.\nTeil B: Datenvisualisieren Erstellen Sie einen Plot der Random Dot Daten. Verwenden Sie dazu ggplot(). Alle Plots und der entsprechende Code werden in der Galerie auf der Kurshomepage anonym veröffentlicht.\nWichtig:",
    "crumbs": [
      "Datenvisualisieren",
      "Übung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#auftrag",
    "href": "uebung_3.html#auftrag",
    "title": "Übung 3",
    "section": "",
    "text": "Information zum Arbeiten in Kleingruppen:\n\nÜbungen dürfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen müssen die Übung auf Ilias hochladen, um die Übung zu bestehen.\nDie Files von Gruppenarbeiten müssen folgendermassen benannt werden, damit wir sehen, welche Übungsabgaben zusammengehören: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_1_GW_EW.R. Geben Sie bei allen Files die Initialen in derselben Reihenfolge an.\n\nArbeitsanweisung unter dem Unterkapitel Vorgehen:\n\nLesen Sie die Anweisungen genau durch und geben Sie die Dateien in diesem Format ab (z.B. Benennung der Dateien).\nArbeiten Sie entlang der Arbeitsanweisung, um den Prozess zu vereinfachen.",
    "crumbs": [
      "Datenvisualisieren",
      "Übung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#vorgehen",
    "href": "uebung_3.html#vorgehen",
    "title": "Übung 3",
    "section": "Vorgehen",
    "text": "Vorgehen\n\nDownload und Setup\n\nLaden Sie das R-Project uebung-3 herunter und entzippen Sie den Ordner. Im data-Ordner finden Sie die Einzeldateien vom Experiment.\nAchtung: Sie müssen nur die Daten des Random Dot Experiments einlesen, vorverarbeiten und visualisieren. Die Daten des Stroop Experiments wurden in der Veranstaltung bearbeitet.\n\n\n\nA. Datapreprocessing-Pipeline\n\n\n\n\n\n\nTipp\n\n\n\nAm besten erstellen Sie zuerst für einen Datensatz einen funktionierenden Vorverarbeitungsablauf. Dann erstellen Sie eine Funktion für diesen Ablauf. In einem letzten Schritt automatisieren Sie dann diesen Ablauf für alle Datensätze im Datenordner indem Sie eine Liste mit allen Filenamen erstellen. Sie können sich an dem Automatisierungsbeispiel mit dem Stroop Datensatz orientieren.\nDas Einlesen kann eine Weile dauern, es sind sehr viele Datensätze.\n\n\n\nErstellen Sie ein neues .R-File und speichern Sie dieses unter preprocessing_random_dot.R im Projekt-Ordner. Sie können auch ein RNotebook erstellen! Falls Sie in einer Gruppe arbeiten speichern Sie dieses mit den Initialen ab, z.B. preprocessing_random_dot_initialen_initialen_initialen.R.\na. Packages laden: Laden Sie das Package {tidyverse}.\nb. Daten einlesen (read.csv())\nc. Daten filtern, so dass nur Experimenttrials im Datensatz sind, keine Übungsaufgaben. (filter())\nd. Erstellen zwei neuer Variablen namens trial (diese Variable gibt die Trialnummer startend mit 1 an und initials (diese Variable gibt Ihre Initialen an) mit (mutate()). Falls Sie in einer Gruppe arbeiten, geben Sie mehrere Initialen in den Variablen initals1, initials2 und initials3 an.\ne. Datensatz vereinfachen: Der Datensatz soll in dieser Reihenfolge folgende Informationen/Variablennamen enthalten (select()):\n  - Versuchspersonenidentifikation (`id`)\n  - Trialnummer (`trial`)\n  - Bewegungsrichtung der Punkte (`direction`)\n  - Instruktionsbedingung (`condition`)\n  - Korrekte Antwort für diesen Trial (`corrAns`)\n  - Antwort der Versuchsperson (`resp`), \n  - war die Antwort der Versuchsperson korrekt? (`corr`)\n  - Antwortzeit der Versuchsperson (`rt`)\n  - Initialen der ausführenden Person (`initials`)\nf. Automatisieren\n\nErstellen Sie nun eine Funktion, die dies für alle Random Dot Datensätze ausführt und einen aggregierten Datensatz erstellt.\n\ng. Erstellter Datensatz kontrollieren:\n\nLöschen Sie nun alle Variablen in der RStudio Umgebung (Environment) mit dem Besen-Icon oben rechts und führen Sie den Code nochmals aus. Wenn alles funktioniert, fahren Sie weiter.\n\nh. Datensatz speichern: Speichern Sie den neuen Datensatz (der jetzt alle Datensätze vorverarbeitet und zusammengefügt enthält) als .csv-File namens dataset_random_dot_clean_initialen.csv in Ihren data-Ordner.\ni. Gespeicherten Datensatz kontrollieren:\n\nIhr Datensatz sollte nun wie untenstehend aussehen. Benutzen Sie dazu in Ihrem Code den Sie abgeben zwingend die Funktion glimpse(). (Ohne glimpse() ist Ihre Abgabe ungültig.)\n\n\n\n\nRows: 28,680\nColumns: 8\n$ id        &lt;chr&gt; \"sub-001\", \"sub-001\", \"sub-001\", \"sub-001\", \"sub-001\", \"sub-…\n$ trial     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ direction &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"right\", …\n$ condition &lt;chr&gt; \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed\", \"speed…\n$ corrAns   &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"right\", …\n$ resp      &lt;chr&gt; \"right\", \"left\", \"right\", \"left\", \"right\", \"left\", \"left\", \"…\n$ corr      &lt;int&gt; 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, …\n$ rt        &lt;dbl&gt; 49.83123, 49.61717, 49.31203, 49.57549, 50.58607, 49.55812, …\n\n\n\n\nB. Datenvisualisieren\n\nIm Ordner finden Sie eine Datei namens initialen_plot.R. Öffnen Sie die die Datei initialen_plot.R. Der Inhalt dieser Datei muss gleich aussehen, wie im Beispiel unten.\nÄndern Sie den Namen der Datei initialen_plot.R, indem Sie Ihre Initialen (oder mehrere: initialen_initialen_initialen_plot.R) einsetzen. Das File muss korrekt benannt werden für eine gültige Abgabe!\nDer Code auf von Zeile 1 bis Zeile 8 darf nicht verändert werden!\nFügen Sie den Code für Ihre Abbildung ab Zeile 9 ein.\nDer eingefügte Code muss die Abbildung erstellen (vgl. Zeile 9-12) und anzeigen (vgl. Zeile 12).\n\n\n# Code innerhalb der folgenden 2 Linien darf nicht verändert werden\n# ---------------------------------------------------------------------\nlibrary(tidyverse)\nd = read_csv('data/dataset_random_dot_clean.csv')\n# ---------------------------------------------------------------------\n\n# Beginnen Sie hier mit Ihrem Code:\n\np = d |&gt;\n    ggplot(...) +\n    ...\np\n\n\nDer Plot muss Folgendes beinhalten:\n\nBeides, Rohdaten UND mind. 1 zusammenfassendes Mass(z.B. Mittelwert mit Standardabweichungen, Box-/Violinplot, etc.). TIPP: Mehrere Geoms können übereinander gelegt werden.\nMind. 2 unterschiedliche Farben (schwarz und weiss ausgenommen).\nBeschriftungen: Titel, Subtitel, Achsenbeschriftungen, (optional: Captions)\nDer Subtitel beinhaltet die Frage, welche der Plot beantwortet.\n\nEin Theme verwenden.\nOptional: Facets verwenden.\n\n\n\n\nHochladen der Dateien auf Ilias\nLaden Sie folgende Dateien unter Übung 3 auf Ilias hoch:\n\ndataset_random_dot_clean_initialen.csv-File\npreprocessing_randomdot_initialen_initialen_initialen.R\ninitialen_initialen_initialen_plot.R\n.jpg oder .png (oder anderes Bildformat) Ihres Plots\n\n\n\n\n\n\n\nWichtig\n\n\n\nIhr Plot und der dazugehörige Code wird in der Galerie anonym veröffentlich. Deshalb ist es wichtig, dass die oben aufgelisteten Voraussetzungen erfüllt sind.",
    "crumbs": [
      "Datenvisualisieren",
      "Übung 3"
    ]
  },
  {
    "objectID": "uebung_3.html#abgabetermin",
    "href": "uebung_3.html#abgabetermin",
    "title": "Übung 3",
    "section": "Abgabetermin",
    "text": "Abgabetermin\nDer Abgabetermin für diese Übung ist der 18. April 2025.",
    "crumbs": [
      "Datenvisualisieren",
      "Übung 3"
    ]
  },
  {
    "objectID": "gallery.html",
    "href": "gallery.html",
    "title": "Galerie",
    "section": "",
    "text": "Hier werden in Kürze die Plots der Übung 3 gezeigt.",
    "crumbs": [
      "Datenvisualisieren",
      "Galerie"
    ]
  },
  {
    "objectID": "webrconsole.html",
    "href": "webrconsole.html",
    "title": "WebR Konsole",
    "section": "",
    "text": "In der WebR-Konsole können Sie R-Code ausführen. Erstellte Variablen werden gespeichert, so lange das Browserfenster nicht geschlossen wird.\n\n Konsole Tipp Lösung\n\n\nGeben Sie hier Code ein.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPackages\nLaden Sie zuerst das {tidyverse} mit library(tidyverse).\nDatensätze\nEs stehen Ihnen folgende Datensätze zur Verfügung:\n\ncars\niris\n\nEs können weitere Datensätze durch das Laden von Packages genutzt werden:\n\npenguins aus {palmerpenguins}\n\n\n# Laden vom penguins-Datensatz aus dem {palmerpenguins} Package\nlibrary(palmerpenguins)\nd &lt;- penguins\n\n\n\n\nlibrary(tidyverse)\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\nplot(cars)",
    "crumbs": [
      "Anhang",
      "WebR Konsole"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License and Authorship",
    "section": "",
    "text": "This course material is written by Gerda Wyssen & Enea Weber…\n…and (sometimes heavily!) adapted from previous course material from\n\nAndrew Ellis\n\nComplab 2021\n\nComplab 2022\nComplab 2023\n\nDaniel Fitze\n\nComplab 2024\n\n\n\nThe course experiments and their descriptions were created by Rebekka Borer (Complab 2024-2025)\n We also thank all previous students who gave valuable feedback on the course and material!\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.",
    "crumbs": [
      "Anhang",
      "License and Authorship"
    ]
  }
]