[
  {
    "objectID": "ddm.html",
    "href": "ddm.html",
    "title": "22  Drift Diffusion Modell",
    "section": "",
    "text": "22.1 DDM: Modell eines Entscheidungsprozesses\nIn unserem Random dot Experiment wurde neben der Antwort der Versuchspersonen (links, rechts) auch die Zeit (rt) gemessen, welche benötigt wurde um diese Antworten zu geben. Diese Information wurde in den vorherigen Modellen nicht gleichzeitig mit der Antwortgenauigkeit berücksichtigt.\nEin Modell mit dem solche Entscheidungsprozesse modelliert werden sind Drift-Diffusion-Modelle. Es geht davon aus, dass binäre Entscheidungen auf der Anhäufung von verrauschten Beweisen basieren, beginnend am Ausgangspunkt und endend an einer Entscheidungsschwelle, die mit einer bestimmten Entscheidung verbunden ist.\nDas Modell hat mindestens vier Parameter:\nDie Gesamtzeit für eine Reaktion ist die Zeit für die Ausbreitung vom Startpunkt bis zur Grenze plus die Non-decision time.\nIm Modell wird die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt (diskrete Zeitschritte). Diese Evidenz wird in einer Entscheidungsvariable (decision variable: dv) gesammelt.\nUm nachzuvollziehen, wie sich eine Entscheidung (in unserem Beispiel: rechts und links) innerhalb eines Trials entwickelt, kann dieser Prozess in R simuliert werden.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#der-entscheidungsprozess",
    "href": "ddm.html#der-entscheidungsprozess",
    "title": "22  Drift Diffusion Modell",
    "section": "",
    "text": "Es gibt 2 Möglichkeiten die gewählt werden können (in unserem Beispiel: rechts und links).\nEs wird angenommen, dass die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt ist (diskrete Zeitschritte).\nAusserdem wird davon ausgegangen, dass die Person den Stimulus verarbeitet und über die Zeit Evidenz akkumuliert (sequential sampling).\n\n\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('links', '0', 'rechts')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#random-walk",
    "href": "ddm.html#random-walk",
    "title": "22  Drift Diffusion Modell",
    "section": "22.2 Random walk",
    "text": "22.2 Random walk\nEin Random walk ist das Resultat der Aufsummierung von Zufallszahlen. Dies kann in R selbst nachvollzogen werden:\nDazu wird ein Random walk mit 100 Zeitschritten simuliert (mit rnorm()). Es wird mit \\(0\\) begonnen und dann werden 99 normalverteilte Zufallszahlen dazuaddiert, also die kumulierte Summe berechnet (hierfür eignet sich die Funktion cumsum()).\n\nRandom walkCode\n\n\n\n\n\n\nlibrary(gganimate) # library for animation\nset.seed(546)\n\n# 0 + 100 standardnormalverteilte Zufallszahlen\nzufallszahlen_1 = c(0, rnorm(99, 0, 1))\nrandom_walk_1 = cumsum(zufallszahlen_1)\n\nd1 = tibble(t = 1:100,\n            rand_walk = random_walk_1)\n\nd1 |&gt;\n    ggplot(aes(x = t, y = rand_walk)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Random walk') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    theme_classic() +\n    transition_reveal(nb) # animate\n\n\n\n\nDie aktuelle decision variable zu Zeitpunkt \\(t\\) als wird hier als normalverteilte Zufallszahl modelliert. Dieser Random walk hat keinen Trend, weil jeder Wert aus einer Normalverteilung mit Mittelwert \\(\\mu=0\\) gezogen wird.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenzakkumulierung",
    "href": "ddm.html#evidenzakkumulierung",
    "title": "22  Drift Diffusion Modell",
    "section": "22.4 Evidenzakkumulierung",
    "text": "22.4 Evidenzakkumulierung\nDie Evidenzakkumulierung kann als Iterationen über einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# Für jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on für Interessierte: Funktion erstellen\n\n\n\n22.5 Hands-on:\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.5,\n                sd = 0.1,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # Für jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\n\n\nDie Decision Variable dv repräsentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable grösser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#auswirkungen-der-parameter",
    "href": "ddm.html#auswirkungen-der-parameter",
    "title": "22  Drift Diffusion Modell",
    "section": "22.5 Auswirkungen der Parameter",
    "text": "22.5 Auswirkungen der Parameter\nUm den Effekt dieser Parameter zu visualisieren, können Trials mit unterschiedlichen Parameterwerten geplottet werden.\n\n22.5.1 Drift rate\nWenn die drift rate viel grösser als \\(0\\) ist, also \\(&gt;&gt; 0\\), wird die obere Entscheidungsgrenze (decision boundary) schnell erreicht. Zudem wird es nur wenige Fehler geben. Ist die drift rate kleiner, aber immer noch \\(&gt; 0\\), wird die durschnittliche Zeit länger, um eine korrekte Antwort zu geben.\n\nHohe vs. tiefe drift rateCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(829)\n\nslow = drift_diffusion(driftrate = 0.8) |&gt; mutate(type = \"slow\")\nfast = drift_diffusion(driftrate = 1.2) |&gt; mutate(type = \"fast\")\n\nfastslow = bind_rows(fast, slow) \n\nfastslow |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue3\", \"skyblue\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.2 Bias\nWenn der bias \\(&gt;0.5\\) ist, wird die obere Entscheidungsgrenze schneller erreicht. Hier gibt es nun eine Interaktion mit der drift rate—ist diese klein, und der bias \\(&lt;0.5\\), ist die Chance, schnelle Fehler zu machen erhöht.\n\nStarting point (bias)Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(29)\n\nunbiased = drift_diffusion(bias = 0.5) |&gt; mutate(type = \"unbiased\")\nupbiased = drift_diffusion(bias = 0.7) |&gt; mutate(type = \"upbiased\")\ndownbiased = drift_diffusion(bias = 0.3) |&gt; mutate(type = \"downbiased\")\n\nbias = bind_rows(unbiased, upbiased, downbiased) \n\nbias |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\",\"skyblue3\", \"skyblue4\")) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n22.5.3 Boundary separation\nLiegen die Grenzen weiter auseinander, braucht es mehr akkumulierte Evidenz, um eine der Grenzen zu erreichen. Dies führt dazu, dass weniger Fehler gemacht werden, da die zufällige Fluktuation über längere Zeit hinweg einen weniger starken Einfluss hat. Deshalb kann eine Verschiebung der Grenzen den Speed-Accuracy Trade-off erklären.\n\nDecision boundariesCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(90)\n\ncarefree = drift_diffusion(decision_boundary = 1.6) |&gt; mutate(type = \"carefree\")\ncautious = drift_diffusion(decision_boundary = 2.1) |&gt; mutate(type = \"cautious\")\n\ncautiouscareless = bind_rows(carefree, cautious) \n\ndecision_boundaries = tribble(~type, ~decision_boundary,\n                               \"carefree\", 1.6,\n                               \"cautious\", 2.1)\ncautiouscareless |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_hline(aes(yintercept = decision_boundary, color = type), data = decision_boundaries) +\n    geom_hline(aes(yintercept = -decision_boundary, color = type), data = decision_boundaries) +\n    theme_classic()\n\n\n\n\n\n\n22.5.4 Non-decision time\nEine Veränderung der non-decision time hat eine Auswirkung auf die durschnittliche Reaktionszeit, hat aber keinen Einfluss auf die Fehlerrate.\n\nNon-decision timeCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4534)\n\nlongndt = drift_diffusion(ndt = 0.7) |&gt; mutate(type = \"longndt\")\nshortndt = drift_diffusion(ndt = 0.2) |&gt; mutate(type = \"shortndt\")\n\nndt = bind_rows(longndt, shortndt) \n\nndts = tribble(~type, ~ndt,\n                \"longndt\", 0.7,\n                \"shortndt\", 0.2)\n\nndt |&gt; \n    ggplot(aes(time, dv, color = type)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    geom_line() +\n    scale_color_manual(values = c(\"skyblue\", \"skyblue4\")) +\n    geom_vline(aes(xintercept = ndt, color = type), data = ndts) +\n    geom_hline(yintercept = c(-2, 2)) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\n\nHands-on: Interpretation der Random Dot DDM Parameter\n\n\n\n\nDDM Random Dot ExperimentCodeDaten\n\n\nWie können die DDM Parameter interpretiert werden?\n\n\n\n\n\nterm\nestimate\n\n\n\n\nDrift rate\n0.01\n\n\nbs_accuracy\n3.07\n\n\nbs_speed\n2.48\n\n\nndt\n0.00\n\n\nbias\n0.50\n\n\n\n\n\n\n\n\nlibrary(brms)\nlibrary(cmdstanr)\n\nfit = brm(bf(rt | dec(resp) ~ 0,\n             bs ~ 0 + condition),\n          data = d,\n          family = wiener(link_bs = \"identity\",\n                          link_ndt = \"identity\",\n                          link_bias = \"identity\"),\n          cores = parallel::detectCores(),\n          chains = 4,\n          backend = \"cmdstanr\")\n\n\n\nDie Daten stammen aus dem Random Dot Experiment FS24. Das Experiment war identisch mit dem diesjährig durchgeführten.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#diffusions-modell-in-der-forschung",
    "href": "ddm.html#diffusions-modell-in-der-forschung",
    "title": "22  Drift Diffusion Modell",
    "section": "22.6 Diffusions Modell in der Forschung",
    "text": "22.6 Diffusions Modell in der Forschung\nWeil mit dem Diffusionsmodell verschiedene Aspekte des Entscheidungsprozesses spezifisch modelliert und unterschieden werden können, wird dieses Modell häufig in der Forschung verwendet. So können detaillierte Einsichten in den Entscheidungsprozess gewonnen werden. Hier ein paar Beispiele:\n\nUntersuchung der kognitiven Eigenschaften bei ADHS Review\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Abhängigkeit (Tabak, Alkohol und Glücksspiel)\nUntersuchung des Entscheidungsverhaltens im Zusammenhang mit Depression, und Angst.\nUntersuchung von verändertem Entscheidungsverhalten aufgrund von strukturellen oder funktionalen Veränderungen des Gehirns z.B. bei Parkinson.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#footnotes",
    "href": "ddm.html#footnotes",
    "title": "22  Drift Diffusion Modell",
    "section": "",
    "text": "Bogacz, Rafal; Eric Brown, Jeff Moehlis, Philip Holmes, Jonathan D. Cohen (2006). “The Physics of Optimal Decision Making: A Formal Analysis of Models of Performance in Two-Alternative Forced-Choice Tasks”. Psychological Review. 113 (4): 700–765. https://doi.org/10.1037/0033-295X.113.4.700↩︎",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "webrconsole.html",
    "href": "webrconsole.html",
    "title": "WebR Konsole",
    "section": "",
    "text": "In der WebR-Konsole können Sie R-Code ausführen. Erstellte Variablen werden gespeichert, so lange das Browserfenster nicht geschlossen wird.\n\n Konsole Tipp Lösung\n\n\nGeben Sie hier Code ein.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPackages\nLaden Sie zuerst das {tidyverse} mit library(tidyverse).\nDatensätze\nEs stehen Ihnen folgende Datensätze zur Verfügung:\n\ncars\niris\n\nEs können weitere Datensätze durch das Laden von Packages genutzt werden:\n\npenguins aus {palmerpenguins}\n\n\n# Laden vom penguins-Datensatz aus dem {palmerpenguins} Package\nlibrary(palmerpenguins)\nd &lt;- penguins\n\n\n\n\nlibrary(tidyverse)\n\nglimpse(cars)\n\nRows: 50\nColumns: 2\n$ speed &lt;dbl&gt; 4, 4, 7, 7, 8, 9, 10, 10, 10, 11, 11, 12, 12, 12, 12, 13, 13, 13…\n$ dist  &lt;dbl&gt; 2, 10, 4, 22, 16, 10, 18, 26, 34, 17, 28, 14, 20, 24, 28, 26, 34…\n\nplot(cars)",
    "crumbs": [
      "Anhang",
      "WebR Konsole"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License and Authorship",
    "section": "",
    "text": "The complab course was initially conceptualized and written by Andrew Ellis (2021-2023), extended by Gerda Wyssen (2021-2025), Daniel Fitze (2024), and Enea Weber (2025). The course experiments (Complab 2024-2025) and their descriptions were created by Rebekka Borer.\nPrevious course material:\n\nComplab 2021\n\nComplab 2022\nComplab 2023\nComplab 2024\n\nWe thank all current and previous students who gave valuable feedback on the course and material!\nCite as: Wyssen, G., Ellis, A., Weber, E., Fitze, D. (2025). Neurowissenschaft im Computerlab. Skript FS 2025. https://kogpsy.github.io/neuroscicomplabFS25.\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Anhang",
      "License and Authorship"
    ]
  },
  {
    "objectID": "ddm.html#random-walk-1",
    "href": "ddm.html#random-walk-1",
    "title": "22  Drift Diffusion Modell",
    "section": "22.3 Random walk",
    "text": "22.3 Random walk\n\n\n\n\n\n\n\n\n\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#random-walk-2",
    "href": "ddm.html#random-walk-2",
    "title": "22  Drift Diffusion Modell",
    "section": "22.5 Random walk",
    "text": "22.5 Random walk\n\n\n\n\n\n\n\n\n\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenz-über-die-zeit",
    "href": "ddm.html#evidenz-über-die-zeit",
    "title": "22  Drift Diffusion Modell",
    "section": "22.4 Evidenz über die Zeit",
    "text": "22.4 Evidenz über die Zeit\nWenn wir dieses Prozess nun über einen Zeitraum wiederholen, und die evidence Werte aufsummieren, erhalten wir die decision variable. Diese sieht aus wie ein random walk mit einem Drift in die Richtung der durchschnittlichen Evidenz.\n:::",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidence",
    "href": "ddm.html#evidence",
    "title": "22  Drift Diffusion Modell",
    "section": "22.3 Evidence",
    "text": "22.3 Evidence\nIst der Mittelwert für die decision variable positiv wird zunehmend Evidenz für die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin “Stück” Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungefähr 0.5 beträgt. Da die Evidenz die durchschnittliche Steigung repräsentiert, wird Evidenz \\(&gt;0\\) dazu führen, dass ein Schritt in Richtung der oberen Grenze gemacht wird. Wäre die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also möglich, dass die Evidenz zufällig negativ wird, obwohl die drift rate, d.h. die Repräsentation der Stimulusstärke, positiv ist.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#evidenzakkumulierung-über-die-zeit",
    "href": "ddm.html#evidenzakkumulierung-über-die-zeit",
    "title": "22  Drift Diffusion Modell",
    "section": "22.3 Evidenzakkumulierung über die Zeit",
    "text": "22.3 Evidenzakkumulierung über die Zeit\nIst der Mittelwert für die decision variable positiv wird zunehmend Evidenz für die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin “Stück” Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4442915\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.7051354\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungefähr 0.71 beträgt. Da die Evidenz die durchschnittliche Steigung repräsentiert, wird Evidenz \\(&gt;0\\) dazu führen, dass ein Schritt in Richtung der oberen Grenze gemacht wird. Wäre die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also möglich, dass die Evidenz zufällig negativ wird, obwohl die drift rate, d.h. die Repräsentation der Stimulusstärke, positiv ist.\nWenn dieser Prozess nun über mehrere Zeitschritte hinweg wiederholt wird und die evidence Werte aufsummiert werden, ergibt sich die decision variable. Diese gleicht einem Random walk, hat aber einen Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk mit und ohne DriftCode\n\n\n\n\n\n\nset.seed(546)\n\nt = 100\n\nd3 &lt;- tibble(\n    nb = 1:t,\n    random_walk_neg = cumsum(c(0, rnorm(t-1, -0.3, 1))),\n    random_walk_neutral = random_walk_1,\n    random_walk_pos = cumsum(c(0, rnorm(t-1, 0.3, 1)))\n    ) |&gt;\n    pivot_longer(cols = c(random_walk_neg, random_walk_neutral, random_walk_pos),\n                 names_to = \"name\",\n                 values_to = \"value\")\n\n# aggregate dataset and plot\nd3 |&gt;\n    ggplot(aes(x = nb, y = value, color = name)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    lims(y = c(-30, 30)) +\n    labs(x = 'Time', y = 'Random walk', color = '') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    scale_color_manual(labels = c('negative drift', 'no drift', 'positive drift'), values = c(\"tomato4\", \"black\", \"skyblue\")) +\n    theme_classic()\n\n\n\n\n\n22.3.1 Evidenzakkumulierung in R modellieren\nDie Evidenzakkumulierung kann als Iterationen über einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# Für jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on für Interessierte: Funktion erstellen\n\n\n\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # Für jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#hands-on",
    "href": "ddm.html#hands-on",
    "title": "22  Drift Diffusion Modell",
    "section": "22.4 Hands-on:",
    "text": "22.4 Hands-on:\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # Für jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time",
    "href": "ddm.html#non-decision-time",
    "title": "22  Drift Diffusion Modell",
    "section": "22.7 Non-decision time",
    "text": "22.7 Non-decision time\nWir können nun noch die non-decision time hinzufügen, und den Anfangspunkt der Evidenzakkumulierung. Dieser Anfangspunkt ist ein sehr wichtiger Parameter, denn wenn der Anfagnspunkt nicht genau in der Mitte zwischen den beiden Grenzen liegt, dann braucht es natürlich weniger Evindenz, um die Grenze zu erreichen, welche näher beim Anfangspunkt liegt.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualität der Evidenz pro Zeiteinheit\nTask Schwierigkeit, Fähigkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Präferenz für eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerzögerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5,\n                            driftrate = 0.8,\n                            decision_boundary = 2,\n                            ndt = 0.5,\n                            diffvar = 0.1,\n                            dt = 0.001,\n                            max_time = 6) {\n\n    assertthat::assert_that(diffvar &gt; 0)\n\n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n\n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n\n    # start acumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n\n    for (j in 2:time_steps) {\n\n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                 min(dv[j], decision_boundary),\n                                 max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                         dv = dv,\n                         steps = seq_along(dv),\n                         driftrate = driftrate,\n                         decision_boundary = decision_boundary,\n                         bias = bias,\n                         ndt = ndt)\n    return(d)\n}",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time-und-bias",
    "href": "ddm.html#non-decision-time-und-bias",
    "title": "22  Drift Diffusion Modell",
    "section": "22.4 Non-decision time und Bias",
    "text": "22.4 Non-decision time und Bias\nDie Decision Variable dv repräsentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable grösser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.\nWir können nun noch die non-decision time hinzufügen, und den Anfangspunkt (bias) der Evidenzakkumulierung.\nDie non-decision time beschreibt die Zeit, welche nicht der Evidenzakkumulierung dient. Vor dem Entscheidungsprozess ist das z.B. das Ausrichten des Blicks auf die Aufgabe, nach dem Entscheidungsprozes ist dies z.B. die Ausführung des Tastendrucks.\nDer bias, also der Anfangspunkt ist ein sehr wichtiger Parameter der beeinflusst, ob schon vor dem Entscheidungsprozess zu einer gewissen Antwort tendiert wird (Antworttendenz). Wenn beispielsweise der Anfangspunkt unterhalb der Mitte liegt, braucht es weniger Evidenz um die untere Grenze zu überschreiten und mehr Evidenz für die obere Grenze zu überschreiten.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualität der Evidenz pro Zeiteinheit\nTask Schwierigkeit, Fähigkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Präferenz für eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerzögerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5, # z\n                           driftrate = 0.8, # v\n                           decision_boundary = 2, # a\n                           ndt = 0.5, # t0\n                           diffvar = 0.1, \n                           dt = 0.001, # t step duration\n                           max_time = 6) {\n    \n    assertthat::assert_that(diffvar &gt; 0)\n    \n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n    \n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n    \n    # start accumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n    \n    for (j in 2:time_steps) {\n        \n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                       min(dv[j], decision_boundary),\n                                       max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                      dv = dv,\n                      steps = seq_along(dv),\n                      driftrate = driftrate,\n                      decision_boundary = decision_boundary,\n                      bias = bias,\n                      ndt = ndt)\n    return(d)\n}\n\n\n\n\n\n\n\n\n\n\nHands-on: DDM Parameter\n\n\n\nVerändern Sie im Code die Werte der Variablen\n\nmean_driftrate (positive und negative Werte)\nsd_driftrate\nbias\nboundary\ntimesteps.\n\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "Herzlich Willkommen\nHier finden Sie das Wichtigste zum Kurs FS2025.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#ilias",
    "href": "index.html#ilias",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Ilias",
    "text": "Ilias\nUnter diesen Links finden Sie die Iliasgruppen:\nILIAS-Gruppe Freitag 08.15-10.00 👉 468703-FS2025-0\nILIAS-Gruppe Freitag 10.15-12.00 👉 468703-FS2025-1",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#kursvoraussetzungen",
    "href": "index.html#kursvoraussetzungen",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Kursvoraussetzungen",
    "text": "Kursvoraussetzungen\nWir werden mit der Programmiersprache R und zu einem kleinen Teil mit Python arbeiten. Sie benötigen in der Veranstaltung deshalb einen eigenen Laptop (Tablets sind nicht geeignet!) mit ca. 20 GB freiem Speicherplatz und mit einer installierten (aktuellen) Version von R und RStudio (Link zum Download von R und RStudio).\nR Kenntnisse (gemäss Statistik I-IV in Psychologie) werden vorausgesetzt. Zur Auffrischung dient folgender Link (https://methodenlehre.github.io/einfuehrung-in-R/) oder für Fortgeschrittene die Bücher „Advanced R” und „R for Data Scientists” von Hadley Wickham.\nZusätzlich dient Übung 2 zur Auffrischung der Vorkenntnisse auf die im späteren Verlauf des Kurses aufgebaut wird.\nBitte installieren Sie bis zum 2. Kurstermine folgende Software:\n\nNeue Versionen von R und RStudio\nPsychoPy\nJASP",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#leistungsnachweise",
    "href": "index.html#leistungsnachweise",
    "title": "Neurowissenschaft im Computerlab",
    "section": "Leistungsnachweise",
    "text": "Leistungsnachweise\nDer Kurs entspricht 5 ETCS. Dafür müssen 3 Bereiche erfüllt werden:\n\nAnwesenheit im Kurs\nbestandene Übungen\nbestandenes Abschlussquiz\n\nAlle Leistungsnachweise werden in den Veranstaltungen angekündigt. Die Termine für die Leistungsnachweise finden Sie unter Termine der Leistungsnachweise.\n\nAnwesenheit\nDie Anwesenheit im Kurs wird vorausgesetzt, an 2 Terminen darf gefehlt werden.\nDas Online-Skript erlaubt das Nacharbeiten des wichtigsten Stoffes im Eigenstudium, wir können jedoch nicht für die Vollständigkeit garantieren. Hilfestellung beim Programmieren und Verstehen der Inhalte erhalten Sie während der Kurszeiten. Aus zeitlichen Gründen können wir keine ausführliche Beantwortung von Fragen zum Kursinhalt per E-Mail anbieten. Bitte stellen Sie Ihre Fragen in der Veranstaltung - auch Ihre Mitstudierenden werden davon profitieren, oft haben mehrere Personen dieselbe Frage.\n\n\nÜbungen\nEs gibt fünf Übungen.\n\nDie Übungen werden auf der Website aufgeschaltet und in der Veranstaltung erklärt.\nDie Ergebnisse der Übungen müssen in den entsprechenden Ordner auf ILIAS hochgeladen werden. Je nach Umfang der Übung wird die Zeit bis zur Abgabe unterschiedlich ausfallen. Sie wird jedoch immer mindestens zwei Wochen betragen.\nAusser Übung 2 müssen alle Übungen abgegeben und als bestanden bewertet werden. Wird eine ungenügende Übungen abgegeben erhalten Sie eine zweite Frist für die Abgabe oder einen Zusatzauftrag.\nÜbungen dürfen alleine oder in Gruppen von max. 3 Personen erledigt werden. Alle Personen müssen die Übung abgeben. Damit wir sehen, welche Übungsabgaben zusammengehören: Nennen Sie das File mit der Aufgabe und allen Initialen der Gruppe. Z.B. uebung_3_GW_EW.R\nAlle Übungen müssen bestanden werden. Ob die Übung bestanden wurde, sehen Sie auf Ilias. Bei Nicht-Bestehen muss die Übung nochmals abgeben werden oder eine Zusatzaufgabe erledigt werden.\n\nVerwenden von LLMs für Übungen: Sie dürfen LLMs gerne als Tool nutzen, um die Übung zu bearbeiten. Es liegt in Ihrer Verantwortung, den Output von LLMs vor der Abgabe gründlich zu prüfen. Halten Sie sich an Folgendes:\n\nLLMs geben Code aus. Aber sogar wenn dieser problemlos ausgeführt werden kann, muss genau überprüft werden, ob der Code das Richtige tut. Dieses Überprüfen kann unter Umständen genau so lange dauern, wie das Lesen und Verstehen der Dokumentation.\nDas Überprüfen von Code erfordert gewisse Grundkenntnisse. Das Verwenden von LLMs ersetzt kein Lernaufwand.1\nDas direkte Verwenden von Code ohne kompetente Prüfung ist in der Forschung unethisch!\nEs dürfen keine sensiblen Daten eingegeben werden bzw. auch keine Datensätze die nicht öffentlich sind.\n\n\n\nAbschlussquiz\nDas Abschlussquiz wird gegen Ende des Semesters auf Ilias freigeschaltet und dient dazu das Gelernte zu prüfen und so Feedback zu geben, wie gut man die Lerninhalte erinnert. Sie haben die Möglichkeit das Quiz mehrmals zu wiederholen.",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#datacamp",
    "href": "index.html#datacamp",
    "title": "Neurowissenschaft im Computerlab",
    "section": "DataCamp",
    "text": "DataCamp\nDataCamp ist eine Online-Lernplattform, welche sich auf Data Science und Datenanalyse konzentriert. Es bietet interaktive Kurse, Tutorials und Projekte in verschiedenen Programmiersprachen wie Python, R und SQL auf unterschiedlichen Niveaus an; sowohl für Anfänger als auch für Fortgeschrittene gibt es ein breites Angebot.\nIm Rahmen dieser Lehrveranstaltung können alle Teilnehmenden sich unter folgendem Link mit ihrer Uni Bern E-Mail Adresse (*students.unibe.ch) registrieren und die Kurse kostenlos nutzen:\n👉🏼 Einladungslink DataCamp Registration (zuerst muss ein DataCamp Zugang erstellt werden.)\nWir werden jeweils die empfohlenen Datacamp Kurse verlinken. Sie haben mit dem Link Zugriff auf alle Datacamp-Kurse bis Ende FS25.\n👉🏼 Zur Auffrischung von R-Kenntnissen eignet sich dieser Kurs: Introduction to R\n👉🏼 Als Einführung in Python eignet sich folgender Kurs: Introduction to Python",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Neurowissenschaft im Computerlab",
    "section": "",
    "text": "↩︎",
    "crumbs": [
      "Herzlich Willkommen"
    ]
  },
  {
    "objectID": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "href": "ddm.html#ddm-modell-eines-entscheidungsprozesses",
    "title": "22  Drift Diffusion Modell",
    "section": "",
    "text": "Das Modell wurde von Roger Ratcliff entwickelt und hat seinen Ursprung in Modellen zu den Bewegungen von Partikeln in einer Flüssigkeit, und geht auf Arbeiten von Albert Einstein und Norbert Wiener zurück.\n\n\n\nDrift rate steht für die durchschnittliche Anzahl von Beweisen pro Zeiteinheit und ist ein Index für die Schwierigkeit der Aufgabe oder die Fähigkeit des Subjekts.\nBoundary separation stellt die Vorsicht dar; eine größere Trennung der Grenzen führt zu weniger Fehlern (wegen geringerer Auswirkung des Diffusionsrauschens innerhalb des Trials), jedoch um den Preis einer langsameren Reaktion (speed-accuracy tradeoff).\nStarting point repräsentiert die a-priori Präferenz für eine der Wahlalternativen.\nNon-decision time ist ein Verzögerungsparameter, der die Zeit für periphere Prozesse (Kodierung eines Reizes, Umwandlung der Repräsentation des Reizes in eine entscheidungsbezogene Repräsentation) und Ausführung einer Reaktion misst.\n\n\n\n\n\n\n\n\nAnnahmen des DDM\n\n\n\n\n\nDas DDM geht von folgenden Annahmen aus:\n\nBinary decision making: DDM ist ein Model für binäre Entscheidungen. Es gibt also 2 Möglichkeiten zwischen denen entschieden werden muss (in unserem Beispiel: rechts und links).\nContinuous sampling: Es wird davon ausgegangen, dass die Person den Stimulus verarbeitet und über die Zeit Evidenz akkumuliert (sequential sampling). Entscheidungen beruhen demnach auf einem kontinuierlichen Verarbeitung von Daten.\nSingle-stage processing: Entscheidungen basieren auf einer einstufigen Verarbeitung.\nParameter sind konstant. Das heisst z.B. die drift rate kann sich nicht über Zeit verändern.\n\n\n\n\n\n\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('left', '0', 'right')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#entscheidungen-im-ddm",
    "href": "ddm.html#entscheidungen-im-ddm",
    "title": "22  Drift Diffusion Modell",
    "section": "22.2 Entscheidungen im DDM",
    "text": "22.2 Entscheidungen im DDM\nIm Modell wird die Zeit in ganz kleine Schritte \\(\\Delta_t\\) unterteilt (diskrete Zeitschritte). Diese Evidenz wird in einer Entscheidungsvariable (decision variable: dv) gesammelt.\nUm nachzuvollziehen, wie sich eine Entscheidung innerhalb eines Trials entwickelt, kann dieser Prozess in R simuliert werden.\n\nEntscheidungsprozessCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n    geom_hline(yintercept = c(-1, 1)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(-1, 0, 1),\n                       labels = c('links', '0', 'rechts')) +\n    theme_minimal()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#drift-rate-evidenzakkumulierung-über-die-zeit",
    "href": "ddm.html#drift-rate-evidenzakkumulierung-über-die-zeit",
    "title": "22  Drift Diffusion Modell",
    "section": "22.3 Drift rate: Evidenzakkumulierung über die Zeit",
    "text": "22.3 Drift rate: Evidenzakkumulierung über die Zeit\nWenn stattdessen aus einer Verteilung mit \\(\\mu=0.1\\) gezogen werden würde, ergäbe dies einen positiven Trend über die Zeit hinweg und es würde sich Evidenz für eine Entscheidungsrichtung ansammeln.\nDie driftrate entspricht also dem Mittelwert der Evidenz und sd deren Standardabweichung.\n\n\n\n\n\n\nHands-on: Drift rate\n\n\n\nModellieren Sie die aktuelle decision variable zu Zeitpunkt \\(t\\) als normalverteilte Zufallszahl, bei der die driftrate nicht 0 entspricht.\nVerändern Sie dafür die Werte der Variablen mean_driftrate (positive und negative Werte) und sd_driftrate im Code.\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nIst der Mittelwert für die decision variable positiv wird zunehmend Evidenz für die positive Entscheidungsoption gesammelt.\n\ndriftrate = 0.5\nsd = 0.1\n\nEin “Stück” Evidenz ist also meistens positiv:\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4962433\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.4442915\n\n\n\nevidence = rnorm(n = 1, mean = driftrate, sd = sd)\nevidence\n\n[1] 0.7051354\n\n\nDies bedeutet, dass zum Zeitpunkt \\(t\\) die Evidenz ungefähr 0.71 beträgt. Da die Evidenz die durchschnittliche Steigung repräsentiert, wird Evidenz \\(&gt;0\\) dazu führen, dass ein Schritt in Richtung der oberen Grenze gemacht wird. Wäre die Evidenz negativ, wird ein Schritt nach unten gemacht. Da die Evidenz aus einer Normalverteilung gezogen wird, ist es also möglich, dass die Evidenz zufällig negativ wird, obwohl die drift rate, d.h. die Repräsentation der Stimulusstärke, positiv ist.\nWenn dieser Prozess nun über mehrere Zeitschritte hinweg wiederholt wird und die evidence Werte aufsummiert werden, ergibt sich die decision variable. Diese gleicht einem Random walk, hat aber einen Drift in die Richtung der durchschnittlichen Evidenz.\n\nRandom walk mit und ohne DriftCode\n\n\n\n\n\n\nset.seed(546)\n\nt = 100\n\nd3 &lt;- tibble(\n    nb = 1:t,\n    random_walk_neg = cumsum(c(0, rnorm(t-1, -0.3, 1))),\n    random_walk_neutral = random_walk_1,\n    random_walk_pos = cumsum(c(0, rnorm(t-1, 0.3, 1)))\n    ) |&gt;\n    pivot_longer(cols = c(random_walk_neg, random_walk_neutral, random_walk_pos),\n                 names_to = \"name\",\n                 values_to = \"value\")\n\n# aggregate dataset and plot\nd3 |&gt;\n    ggplot(aes(x = nb, y = value, color = name)) +\n    geom_step() +\n    geom_hline(yintercept = c(-30, 30)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    lims(y = c(-30, 30)) +\n    labs(x = 'Time', y = 'Random walk', color = '') +\n    scale_y_continuous(breaks = c(-30, 0, 30),\n                       labels = c('left', '0', 'right')) +\n    scale_color_manual(labels = c('negative drift', 'no drift', 'positive drift'), values = c(\"tomato4\", \"black\", \"skyblue\")) +\n    theme_classic()\n\n\n\n\n\n22.3.1 Evidenzakkumulierung in R modellieren\nDie Evidenzakkumulierung kann als Iterationen über einzelne Zeitschritte hinweg modelliert werden. In R kann dies mit einem for Loop gemacht werden.\n\ndriftrate = 0.5\nsd = 0.1\n\nn_steps = 10\nevidence = rep(NA, n_steps)\n\ndv = rep(NA, n_steps)\n\ntime_steps = 1:n_steps\n\n# Ersten Wert aus der Verteilung ziehen\nevidence[1] = rnorm(1, mean = driftrate, sd = sd)\ndv[1] = evidence[1]\n\n# Für jeden weitern Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\nfor (t in 2:n_steps) {\n    evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n    dv[t] = dv[t-1] + evidence[t]}\n\n\n\n\n\n\n\nHands-on für Interessierte: Funktion erstellen\n\n\n\n\nFunktion erstellenBeispielscode\n\n\n\nErstellen Sie aus dem obigen Code eine custom function:\n\n\nWie soll die Funktion heissen? (-&gt; name)\nWas sind Inputs der Funktion? (-&gt; ())\nWas soll die Funktion tun? (-&gt; {})\n\n\n# Zur Erinnerung die Struktur einer custom Funktion\n\nname = function(){\n    ...\n    ...\n}\n\n\nDer Output der Funktion soll ein data frame sein mit evidence und dv.\n\n\ndata_ddm &lt;- name()\n\n\nMachen Sie eine Abbildung dieser Daten\n\n\nupper = ... # upper boundary\nlower = ... # lower boundary\n\ndata_ddm |&gt;\n    ggplot() +\n    ...\n    ...\n    geom_hline(yintercept = c(upper, loewr)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()\n\n\n\n\nddm_function = function(driftrate = 0.3,\n                sd = 0.5,\n                n_steps = 100){\n    evidence = rep(NA, n_steps)\n    dv = rep(NA, n_steps)\n\n    time_steps = 1:n_steps\n\n    # Ersten Wert aus der Verteilung ziehen\n    evidence[1] = rnorm(1, mean = driftrate, sd = sd)\n    dv[1] = evidence[1]\n\n    # Für jeden weiteren Zeitpunkt eine Zufallszahl ziehen und zur kumulierten DV addieren\n    for (t in 2:n_steps) {\n        evidence[t] = rnorm(1, mean = driftrate, sd = sd)\n        dv[t] = dv[t-1] + evidence[t]}\n    \n    return(tibble(t = 1:n_steps, evidence, dv))\n}\n\n\ndata_ddm &lt;- ddm_function()\n\n\nupper = 20 # upper boundary\nlower = -20 # lower boundary\n\ndata_ddm |&gt;\n    ggplot(aes(x = t, y = dv)) +\n    geom_step() +\n    geom_hline(yintercept = c(upper, lower)) +\n    geom_hline(yintercept = 0, linetype = 3) +\n    labs(x = 'Time', y = 'Evidence (dv)') +\n    scale_y_continuous(breaks = c(upper, 0, lower),\n                       labels = c('right', '0', 'left')) +\n    theme_classic()",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  },
  {
    "objectID": "ddm.html#non-decision-time-bias-und-boundaries",
    "href": "ddm.html#non-decision-time-bias-und-boundaries",
    "title": "22  Drift Diffusion Modell",
    "section": "22.4 Non-decision time, bias und boundaries",
    "text": "22.4 Non-decision time, bias und boundaries\nDie Decision Variable dv repräsentiert nun die kumulierten Evidenz, aufgrund dessen das Gehirn eine Entscheidung treffen kann. Wenn der Wert der decision variable grösser als die obere Grenze oder kleiner als die untere Grenze wird, wird die Evidenzakkumulierung abgebrochen, und eine Entscheidung getroffen.\nWir können nun noch die non-decision time und den Anfangspunkt (bias) der Evidenzakkumulierung hinzufügen.\nDie non-decision time beschreibt die Zeit, welche nicht der Evidenzakkumulierung dient. Vor dem Entscheidungsprozess ist das z.B. das Ausrichten des Blicks auf die Aufgabe, nach dem Entscheidungsprozes ist dies z.B. die Ausführung des Tastendrucks.\nDer bias, also der Anfangspunkt ist ein sehr wichtiger Parameter der beeinflusst, ob schon vor dem Entscheidungsprozess zu einer gewissen Antwort tendiert wird (Antworttendenz). Wenn beispielsweise der Anfangspunkt unterhalb der Mitte liegt, braucht es weniger Evidenz um die untere Grenze zu überschreiten und mehr Evidenz für die obere Grenze zu überschreiten.\nDie boundaries beeinflussen, wie viel Evidenz ausreicht, um eine Entscheidung zu treffen. Will man sich ganz sicher sein, sind die boundaries weiter auseinander.\n\nModel ParametersFunction\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nBedeutung\nAnwendung\n\n\n\n\ndrift rate\nQualität der Evidenz pro Zeiteinheit\nTask Schwierigkeit, Fähigkeit\n\n\nbias\nAnfangspunkt der Evidenzakkumulierung\nA priori Präferenz für eine der beiden Alternativen\n\n\nboundary separation\nVorsicht (caution)\nSpeed-Accuracy Trade-off\n\n\nnon-decision time\nVerzögerung\nPeriphere Prozesse\n\n\n\n\n\n\n\n\ndrift_diffusion = function(bias = 0.5, # z\n                           driftrate = 0.8, # v\n                           decision_boundary = 2, # a\n                           ndt = 0.5, # t0\n                           diffvar = 0.1, \n                           dt = 0.001, # t step duration\n                           max_time = 6) {\n    \n    assertthat::assert_that(diffvar &gt; 0)\n    \n    # rescale bias so that 0.5 lies halfway between upper and lower bound\n    bias = as.numeric(2 * decision_boundary * bias - decision_boundary)\n    \n    # initialize time_steps and dv\n    time_steps = max_time/dt\n    dv = array(dim = time_steps)\n    \n    # start accumulating from bias (starting point)\n    dv[1] = rnorm(1, mean = bias, sd = sqrt(dt))\n    \n    for (j in 2:time_steps) {\n        \n        # non-decision time\n        if (j &lt;= ndt/dt) {\n            dv[j] = dv[j-1]\n        }\n        else {\n            error = rnorm(1, 0, sqrt(diffvar * dt))\n            dv[j] = dv[j-1] + driftrate * dt + error  # Cobb & Zacks (1985), Eq. 1.14\n            if (abs(dv[j]) &gt; decision_boundary) {\n                dv[j] = dplyr::if_else(dv[j] &gt; 0,\n                                       min(dv[j], decision_boundary),\n                                       max(dv[j], -decision_boundary))\n                break()\n            }\n        }\n    }\n    d = dplyr::tibble(time = round(seq_along(dv) * dt, 3),\n                      dv = dv,\n                      steps = seq_along(dv),\n                      driftrate = driftrate,\n                      decision_boundary = decision_boundary,\n                      bias = bias,\n                      ndt = ndt)\n    return(d)\n}\n\n\n\n\n\n\n\n\n\n\nHands-on: DDM Parameter\n\n\n\nVerändern Sie im Code die Werte der Variablen\n\nmean_driftrate (positive und negative Werte)\nsd_driftrate\nbias\nboundary\ntimesteps.\n\nWas passiert?\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Datenmodellierung",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Drift Diffusion Modell</span>"
    ]
  }
]