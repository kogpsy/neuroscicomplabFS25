{
  "hash": "f6fa60941fb2f6b6b0b6b96e409b793f",
  "result": {
    "engine": "knitr",
    "markdown": "# Grundlagen der Datenvisualisierung\n\nDatenvisualisierung ist ein wichtiger Schritt in der Analyse neurowissenschaftlicher Daten. \nDas grafische Darstellen von Informationen dient dazu die Datenkomplexität zu reduzieren und wichtige Eigenschaften herauszuheben und zusammenzufassen. \n\nDabei geht es nicht nur darum Ergebnisse zu kommunizieren, sondern auch dazu Einsichten über die Daten zu gewinnen: Auch wenn in den meisten wissenschaftlichen Artikeln nur wenige Grafiken gezeigt werden, wurden die Daten oft während der Analyse zahlreiche Male visualisiert.\n\n<aside> Spannende Beispiele für Datenvisualisierungen finden Sie auf dieser [Website](https://www.cedricscherer.com/top/dataviz). </aside>\n\nWir schauen uns drei Kernaufgaben der Datenvisualisierung an: \n\n- __Diagnostik__: Daten untersuchen\n- __Analyse__: Daten zusammenfassen\n- __Kommunikation__: Forschungsergebnisse visualisieren\n\nJe nachdem welchem Zweck eine Grafik dienen soll, müssen andere Grafikeigenschaften berücksichtigt werden. \nDiagnostische Grafiken müssen beispielsweise nicht in erster Linie ästhetisch ansprechend sein, sondern aufzeigen, wo Probleme im Datensatz vorliegen könnten. \nEine \"gute\" Grafik komprimiert die Information in den Daten so, dass Erkenntnisse gewonnen werden können. \n\n::: callout-caution\n## Hands-on: Vorbereitung\n\n__Variante A: *RProject* selbst erstellen:__\n\n- Erstellen Sie ein _RProject_ in _R_.\n- Laden Sie den Datensatz [hier](data/dataset_rdk_clean.csv) herunter und speichern Sie diesen in dem Ordner `data` im Ordner Ihres _RProjects_.\n- Öffnen Sie ein neues RScript (`.R`) oder RMarkdown-File (`.Rmd`). In einem RMarkdown-File können Code und Text verbunden werden und die die Outputs des Codes (z.B. Grafiken) werden anzeigt.\n\n__Variante B: *RProject* herunterladen:__\n\n_Dies ist nicht nötig, falls Sie den Ordner im Kapitel [Datenvisualisierung mit {ggplot2}](data_visualization_1.qmd) schon heruntergeladen haben._\n\n- Laden Sie [den _RProject_-Ordner](data/data-visualization.zip) herunter und entzippen Sie diesen.^[Für das Entzippen mit _Windows_ machen Sie einen Rechtsklick auf den Ordner mit dem Reissverschluss und wählen Sie Entpacken nach und geben Sie den Ordner an, in dem Sie alle Ihre _RProject_-Ordner speichern. Für das Entzippen mit _Mac_ speichern Sie den heruntergeladenen Ordner in den Ordner, in dem Sie alle Ihre _RProject_-Ordner speichern und Doppelklicken Sie danach auf den Ordner. __Nur entzippte Ordner können einwandfrei verwendet werden!__]\n\nDie Daten stammen von unserem [Random Dot Experiment](https://kogpsy.github.io/neuroscicomplabFS25/random_dot_experiment.qmd). \n\nIm Projekt wird mit einem _RNotebook_ gearbetet: So kann Code und Text verbunden werden, und Code-Outputs z.B. Grafiken können _inline_ angezeigt werden, zudem ermöglicht dieses Vorgehen reproduzierbare Grafiken.\nSie können in das _RNotebook_ den untenstehenden Code kopieren und modifizieren, um die Datenvisualisierungen nachzuvollziehen und damit zu üben.\n\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Packages laden\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# Daten einlesen und Textvariablen zu Faktoren umwandeln\nd <- read_csv(\"data/dataset_rdk_clean.csv\") |>\n    mutate(across(where(is.character), as.factor))\n\n# Datensatz anschauen\nd |> slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 8\n   id           trial direction condition corrAns resp   corr    rt\n   <fct>        <dbl> <fct>     <fct>     <fct>   <fct> <dbl> <dbl>\n 1 sub-10209782     1 left      speed     left    right     0 5.88 \n 2 sub-10209782     2 right     speed     right   right     1 0.822\n 3 sub-10209782     3 left      speed     left    left      1 0.935\n 4 sub-10209782     4 right     speed     right   right     1 0.745\n 5 sub-10209782     5 right     speed     right   right     1 1.51 \n 6 sub-10209782     6 left      speed     left    left      1 0.940\n 7 sub-10209782     7 right     speed     right   right     1 1.64 \n 8 sub-10209782     8 left      speed     left    left      1 2.17 \n 9 sub-10209782     9 right     speed     right   right     1 1.38 \n10 sub-10209782    10 left      speed     left    left      1 1.55 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n<!-- Hier Info zu `across` einfügen/verweisen. -->\n\n# Diagnostik: Daten untersuchen\n\nDatensätze können sehr komplex sein, deshalb ist die Visualisierung der Daten ein hilfreicher erster Schritt. \nMit Hilfe von Visualisierungen können Aussagen über die Qualität der Daten gemacht werden, z.B. über:\n\n- Fehlende Werte\n- Aufgabenschwierigkeit\n- Extreme Datenpunkte (Ausreisser)\n- Zeitverläufe\n- Verteilung der Daten\n\nDiagnostische Grafiken dienen dazu, rasch an Informationen zu können und Probleme in Datensätzen zu entdecken. \nDie Grafiken müssen daher nicht ästhetisch ansprechend oder für Aussenstehende verständlich sein. \nIm Sinne der Reproduzierbarkeit lohnt es sich aber, auch diese Visualisierungen gut zu dokumentieren.\n\nIm Folgenden schauen wir uns Beispiele für diagnostische Grafiken an.\n\n## Fehlende Werte\n\nHierbei ist es wichtig, vor allem systematisch fehlende Datenpunkte zu entdecken: Fehlt bei einer Person die Hälfte der Antworten? Möchten wir diese ausschliessen?\n\nDiese können mit dem Package {naniar} relativ schnell sichtbar gemacht werden. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnaniar::vis_miss(d)\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n<aside>Bevor Sie das Package verwenden können, müssen Sie dies erst herunterladen. Sie können dies unter dem Reiter `Tools` > `Install Packages ...` tun oder in der Konsole mit `install.packages(\"naniar\")`. </aside>\n\n:::{.callout-caution}\n## Hands-on: Missings\n\n- Was sehen Sie in der Grafik? (Wie viele Datenpunkte fehlen? In welchen Variablen?)\n\nUm mehr über die fehlenden Werte zu erfahren, können wir uns die betroffenen Zeilen anschauen. Das kann direkt im Datensatz betrachtet werden oder indem eine zusätzliche Variable mit der `naniar::add_label_missings()`-Funktion erstellt wird, die angibt ob in dieser Zeile missings vorliegen:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_missings <- d |> naniar::add_label_missings() |>\n    filter(any_missing == \"Missing\")\n\nhead(d_missings)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 9\n  id           trial direction condition corrAns resp   corr    rt any_missing\n  <fct>        <dbl> <fct>     <fct>     <fct>   <fct> <dbl> <dbl> <chr>      \n1 sub-16853779     1 right     accuracy  right   right     1    NA Missing    \n2 sub-16853779     2 left      accuracy  left    left      1    NA Missing    \n3 sub-16853779     3 right     accuracy  right   left      0    NA Missing    \n4 sub-16853779     4 left      accuracy  left    right     0    NA Missing    \n5 sub-16853779     5 right     accuracy  right   right     1    NA Missing    \n6 sub-16853779     6 left      accuracy  left    left      1    NA Missing    \n```\n\n\n:::\n:::\n\n\n\n\n\n\n- Was könnte die Ursache für die Missings sein?\n\n- Was ist zu tun?\n\n:::\n\n:::{.callout-tip collapse=\"true\"}\n## Fehlende Werte\n\nJe nachdem wie die fehlenden Werte zustande gekommen sind, gehen wir anders vor. Ein Ansatz könnte sein, dass wir die Trials, die keine Reaktionszeiten enthalten rauslöschen:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- d |>\n    filter(rt != \"NA\")\n\nnaniar::vis_miss(d)\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nDrei wichtige Punkte: \n\n- Wir löschen die Datenpunkte __nie__ aus den Rohdaten, sondern nur aus dem aktuell geladenen Datensatz, den wir für die Analysen verwenden. So können wir uns immer noch umentscheiden und verlieren nicht die Information, welche Daten gefehlt haben.\n\n- Dadurch, dass wir die Datenverarbeitung in reproduzierbarem Code geschrieben haben, konnten wir überprüfen, ob ein Fehler in unserer Datenverarbeitung zu den missings geführt hat und diesen evtl. korrigieren.\n\n- Es macht nicht immer Sinn die Trials mit missing data zu löschen! Dies muss von Fall zu Fall entschieden werden. Wenn Versuchspersonen zum Beispiel teilweise zu lange brauchten um eine Aufgabe zu lösen, dann ist das eine wichtige Information, wird diese rausgelöscht, wird die Leistung der Versuchsperson systematisch überschätzt.\n:::\n\nWir berechnen nun für die kommenden Grafiken die Anzahl Trials pro Person, die *accuracy*, sowie die mittlere Reaktionszeit (wie im Kapitel [Aggregierte Statistiken](https://kogpsy.github.io/neuroscicomplabFS23/pages/chapters/summarizing-data.html) beschrieben).\n\nWir schliessen vorher alle Reaktionszeiten unter 100ms und über 10 Sekunden aus.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# zu schnelle und zu langsame Antworten ausschliessen\nd <- d |>\n    filter(rt > 0.09 & rt < 15)\n\n# Daten gruppieren:  Anzahl Trials, Accuracy und mittlere Reaktionszeit berechnen\nacc_rt_individual <- d |>\n    group_by(id, condition) |>\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\n```\n:::\n\n\n\n\n\n\nNachdem wir Trials ohne Antwort ausgeschlossen haben, interessiert es uns, wie viele Trials jede Versuchsperson gelöst hat:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot: Anzahl Trials pro Bedingung für jede Versuchsperson \nacc_rt_individual |> \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einfügen\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nWir schliessen alle Personen aus, die weniger als 40 gültige Trials hatten\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Datensatz mit allen Ids, welche zuwenig Trials hatten\nn_exclusions <- acc_rt_individual |>\n    filter(N < 40) \n\n# Aus dem Hauptdatensatz diese Ids ausschliessen\nd <- d |>\n    filter(!id %in% n_exclusions$id) \n\n# Check\nd_acc_rt_individual <- d |>\n    group_by(id, condition) |>\n    summarise(\n        N = n(),\n        ncorrect = sum(corr),\n        accuracy = mean(corr),\n        median_rt = median(rt)\n    )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n```\n\n\n:::\n\n```{.r .cell-code}\nd_acc_rt_individual |> \n    ggplot(aes(x = id, y = N)) +\n    geom_point() +\n    facet_wrap(~ condition) +\n    geom_hline(yintercept = 40) + # Horizontale Linie einfügen\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n## Extreme Datenpunkte (Ausreisser)\n\nWir können Visualisierungen auch verwenden, um extreme Datenpunkte zu identifizieren. Dafür teilen wir hier die Accuracywerte in 3 Gruppen ein und plotten diese:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Trials nach accuracy einteilen\nd_acc_rt_individual_grouped <- d_acc_rt_individual %>% \n  mutate(\n    performance = case_when(\n      accuracy > 0.75 ~ \"good\",\n      accuracy < 0.4 ~ \"bad\",\n      TRUE ~ \"chance level\") %>% \n      factor(levels = c(\"good\", \"chance level\", \"bad\")))\n\n# Outlier visualisieren\nd_acc_rt_individual_grouped %>% \n    ggplot(aes(x = id, y = accuracy, color = performance, shape = performance)) +\n    geom_point(size = 2, alpha = 0.6) + \n    geom_point(data = filter(d_acc_rt_individual_grouped, performance != \"OK\"), \n               alpha = 0.9) + \n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray40\", \"steelblue\", \"red\")) +\n    geom_hline(yintercept = 0.5, linetype='dotted', col = 'black')+\n    annotate(\"text\", x = \"sub-36817827\", y = 0.5, label = \"chance level\", vjust = -1, size = 3) +\n    theme_minimal(base_size = 12)\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n<aside>Dasselbe könnte man für die Reaktionszeiten machen. Informationen dazu, wie Ausreisser in Reaktionszeiten gefunden und visualisiert werden können, finden Sie [hier](https://kogpsy.github.io/neuroscicomplab/07-mental-chronometry.html).</aside>\n\n\n## Verlaufseffekte: Ermüdung und Lernen\n\nVerlaufseffekte können uns interessieren, weil wir starke Ermüdungs- oder Lerneffekte ausschliessen möchten. Sie könnten aber auch inhaltlich interessant sein.\n\nIn unserem Experiment möchten wir sicher sein, dass die Performanz sich über die Zeit hinweg nicht zu stark verändert. Hierzu können wir beispielsweise die *accuracy* in den beiden Blöcken plotten:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_acc_rt_trial <- d |>\n    group_by(condition, trial) |>\n    summarise(\n        accuracy = mean(corr),\n        median_rt = median(rt)\n        )\n\nd_acc_rt_trial |>\n    ggplot(aes(x = trial, y = accuracy, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(accuracy = \"tomato3\",\n                                  speed = \"skyblue3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nOder wir können die Reaktionszeiten über die Zeit hinweg anschauen. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_acc_rt_trial |>\n    ggplot(aes(x = trial, y = median_rt, color = condition)) +\n    geom_point(size = 2, alpha = 0.8) +\n    geom_line() +\n    scale_color_manual(values = c(accuracy = \"tomato3\",\n                                  speed = \"skyblue3\")) +\n    facet_wrap(~ condition) +\n    theme_minimal(base_size = 12)\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\nDas tun wir hier für 3 Versuchspersonen.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot: Reaktionszeit über die Trials hinweg (für 3 Versuchspersonen)\nd |>\n    filter(id %in% c(\"sub-10209782\", \"sub-36817827\", \"sub-48177911\")) |>\n    ggplot(aes(x = trial, y = rt, color = condition)) +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    geom_point(alpha = 0.5) +\n    scale_color_manual(values = c(accuracy = \"tomato3\",\n                                 speed = \"skyblue3\")) +\n    facet_wrap(~ id) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n## Aufgabenschwierigkeit und Performanz der Versuchspersonen\n\nBevor wir die Daten analysieren, möchten wir wissen, ob die Personen die Aufgabe einigermassen gut lösen konnten (und wollten). \nIn unserem Experiment erwarten wir eine Genauigkeit (accuracy) über dem Rateniveau von 50%. Wir plotten hierfür die `accuracy` für jede Person und Bedingung.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot accuracy per person and condition\np1 <- d_acc_rt_individual |> \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(accuracy = \"tomato2\",\n                                 speed = \"skyblue3\")) +\n    labs(x = \"Instruction\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np2 <- d_acc_rt_individual |> \n  ggplot(aes(x = condition, y = median_rt, color = condition)) +\n    geom_jitter(size = 3, alpha = 0.4, \n                width = 0.2, height = 0) +\n    geom_boxplot(width = 0.1, alpha = 0, color = \"black\") +\n    scale_color_manual(values = c(accuracy = \"tomato2\",\n                                 speed = \"skyblue3\")) +\n    labs(x = \"Instruction\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\nlibrary(patchwork)\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nUnd wir interessieren uns, wie sich die `accuracy` zwischen den Bedingungen unterscheidet. \nDas zeigt uns, ob die Instruktion eine Wirkung hatte. \nDafür fügen wir Linien ein, die die `accuracy`- Werte pro Versuchsperson verbindet:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np3 <- d_acc_rt_individual |> \n    ggplot(aes(x = condition, y = accuracy, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(accuracy = \"tomato2\",\n                                 speed = \"skyblue3\")) +\n    labs(x = \"Instruction\",\n         y = \"Proportion correct\",\n         title = \"Accuracy per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np4 <- d_acc_rt_individual |> \n    ggplot(aes(x = condition, y = median_rt, color = condition, group = id)) +\n    geom_line(color = \"grey40\", alpha = 0.5) +\n    geom_jitter(size = 3, alpha = 0.8, \n                width = 0, height = 0) +\n    scale_color_manual(values = c(accuracy = \"tomato2\",\n                                 speed = \"skyblue3\")) +\n    labs(x = \"Instruction\",\n         y = \"Median Response Time [s]\",\n         title = \"Median Response Time per Person and Condition\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np3 + p4\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n:::{.callout-caution}\n## Hands-on: Datenqualität\n\nBesprechen Sie miteinander, was Sie nun über unsere Daten wissen.\n\n- Haben die Versuchspersonen die Aufgaben lösen können? \n\n- War die Aufgabe zu einfach, zu schwierig? \n\n- Denken Sie, die Personen waren motiviert?\n\n- Welche Datensätze / Trials möchten wir ausschliessen? (Dies müsste eigentlich **vor** dem Anschauen der Daten entschieden werden, um zu verhindern, dass man Datenpunkte ausschliesst, welche die Hypothese nicht bestätigen.)\n\n- Wie gut eignen sich die Daten, um die Forschungsfrage zu beantworten?\n\n- Was könnte bei einem nächsten Experiment besser gemacht werden?\n\n:::\n\n# Analyse: Daten zusammenfassen und explorieren\n\nGrafiken können einerseits eine Ergänzung zur statistischen Datenanalyse sein, wie auch die Resultate der Analysen (bspw. geschätzte Parameterwerte) visualisieren. \nSie haben den Vorteil, dass Informationen über Daten oder Analyseergebnisse gleichzeitig ersichtlich sind, sie können also vom Betrachtenden direkt verglichen werden.\n\nWir möchten die Daten hinsichtlich der Forschungsfragen visualisieren. \nDie Grafiken müssen vor allem präzise und informativ sein. \nUm Schlüsse aus Daten ziehen zu können, müssen diese zusammengefasst werden. \nDazu eignen sich Lagemasse oder **Masse der zentralen Tendenz**, also beispielsweise der Mittelwert, Median oder Modus. \nGleichzeitig ist es wichtig, dass auch **Verteilungsmasse** berichtet werden, wie *Standardabweichungen* oder *Standardfehler*. \nWir können auch mit Werte aus statistischen Modellen, wie *Parameterschätzungen* und *Konfidenzintervalle*, grafisch darstellen.\n\nMit Hilfe von Visualisierungen können z.B. Aussagen können gemacht werden über:\n\n- Verteilung der Daten\n- Zusammenhänge von Variablen (Korrelationen, Zeitverläufe)\n- Vergleiche und Unterschiede von Gruppen / Bedingungen\n\n\n## Verteilung der Rohdaten\n\nDaten von neurowissenschaftlichen Studien können wichtige Informationen enthalten, die ohne Grafiken übersehen werden können (@rousselet_beyond_2017). \nDas Visualisieren kann Muster zum Vorschein bringen, die durch statistische Auswertungen nicht sichtbar sind. \nDie Wichtigkeit von Datenvisualisierung für das Entdecken von Mustern in den Daten zeigte Francis Anscombe 1973 mit dem *Anscombe's Quartet*. \nDies diente als Inspiration für das Erstellen des \"künstlichen\" Datensatzes `DatasaurusDozen`, welchen wir in der letzten Veranstaltung visualisiert haben. \nVerschiedene Rohwerte, können dieselben Mittelwerte, Standardabweichungen und Korrelationen ergeben. \nNur wenn man die Rohwerte plottet erkennt man, wie unterschiedlich die Datenpunkte verteilt sind.\n\nDies wird ersichtlich, wenn wir die Mittelwerte und Standardabweichungen für jede Gruppe berechnen und plotten:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load DatasaurusDozen dataset\ndino_data <- read.csv(\"data/DatasaurusDozen.csv\") %>%\n    mutate(condition = as.factor(condition))\n\n# Plot mean and standard deviation for value 1 per condition \ndino_data |>   \n    group_by(condition) |>\n    summarise(mean_value1 = mean(value1),\n              sd_value1 = sd(value1)) |>\n    ggplot(mapping = aes(x = mean_value1,\n                     y = condition)) +\n    geom_point() +\n    geom_errorbar(aes(xmin = mean_value1 - sd_value1, \n                      xmax = mean_value1 + sd_value1), \n                  width = 0.2) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nUnd dann die Rohwerte visualisieren:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot raw values\ndino_data |> \n    ggplot(aes(x = value1, y = value2)) +\n    geom_point(size = 1) +\n    facet_wrap(~condition) +\n    theme_minimal()\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nHier sehen Sie das Ganze animiert:\n\n![Datensatz und Visualisierung von [@matejka_same_2017](https://www.autodesk.com/research/publications/same-stats-different-graphs)](https://damassets.autodesk.net/content/dam/autodesk/research/publications-assets/gifs/same-stats-different-graphs/DinoSequentialSmaller.gif)\n\n## Zentrale Tendenz und Verteilungsmasse\n\nMasse der zentralen Tendenz sind beispielsweise der Mittelwert, der Median und Modus. \nWenn wir uns dafür interessieren, wie sich die *accuracy* in Bezug auf alle Teilnehmenden verhält, schauen wir uns die zentrale Tendenz über alle Personen hinweg an. Es sollte nie nur die zentrale Tendenz, sondern immer auch ein passendes Verteilungsmass berichtet werden.\n\nWie oben schon gezeigt können wir dies z.B. mit Boxplots umsetzen Diese zeigen uns den Median und die Quartile sowie Ausreisser an. Eine andere Möglichkeit Verteilungen anzuzeigen sind die Violinplots. Hier wurden mit `geom_jitter()` auch die Mittelwerte der einzelnen Personen im Plot eingefügt.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\np_boxplot <- d_acc_rt_individual |> \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.25, width = 0.2) +\n    geom_boxplot(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(accuracy = \"tomato3\",\n                                     speed = \"skyblue3\")) +\n    labs(title = \"Boxplot\",\n         x = \"Instruction\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n# Violin Plot\np_violin <- d_acc_rt_individual |> \n  ggplot(aes(x = condition, y = accuracy, color = condition)) +\n    geom_jitter(alpha = 0.5, width = 0.2) +\n    geom_violin(alpha = 0, width = 0.2, color = \"black\") +\n    scale_fill_manual(values = c(accuracy = \"tomato3\",\n                                 speed = \"skyblue3\")) +\n    labs(title = \"Violin Plot\",\n         x = \"Instruction\",\n         y = \"Proportion correct\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np_boxplot + p_violin\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\nDas _Package_ {ggridges} bietet die Möglichkeit die Verteilungen zu plotten. \nMehr Informationen hierzu finden Sie [hier](https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html) in der Dokumentation.\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggridges)\np5 <- d_acc_rt_individual |> \n    ggplot(aes(x = accuracy, y = condition, fill = condition)) + geom_density_ridges2(scale = 0.5, alpha = 0.5) +\n    scale_fill_manual(values = c(accuracy = \"tomato3\",\n                                 speed = \"skyblue3\")) +\n    labs(title = \"Accuracy\",\n         x = \"Proportion corect\",\n         y = \"Instruction\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np6 <- d_acc_rt_individual |> \n    ggplot(aes(x = median_rt, y = condition, fill = condition)) + geom_density_ridges2(scale = 1, alpha = 0.5) +\n    scale_fill_manual(values = c(accuracy = \"tomato3\",\n                                 speed = \"skyblue3\")) +\n    labs(title = \"Median Response Time\",\n         x = \"Median Response Time [s]\",\n         y = \"Instruction\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np5 + p6\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n## Aggregierte Statistiken \n\nWenn wir Mittelwerte und Standardfehler angeben möchten können wir dies wie folgt tun. \nWichtig ist hier, dass wir _within-subject_ Standardfehler berechnen. \nGenaueres zu den Unterschieden zwischen within- und between-subject Standardfehlern finden Sie [hier](https://kogpsy.github.io/neuroscicomplabFS23/pages/chapters/summarizing-data.html). \nWir verwenden das _Package_ {Rmisc}. _Achtung:_ Da dieses jedoch wegen der Namen der Funktionen oft Namens-Konflikte auslöst, laden wir `Rmisc` nicht mit der `library()`-Funktion, sondern stellen es einfach vor die benötigte Funktion, z.B. so `Rmisc::summarySEwithin()`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_acc_within <- d |>\n    Rmisc::summarySEwithin(measurevar = \"corr\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np7 <- d_acc_within |>\n    ggplot(aes(x = condition, y = corr, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = corr-se, ymax = corr+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Accuracy\",\n         x = \"Instruction\",\n         y = \"Accuracy\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\n\nd_rt_within <- d |>\n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"id\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\np8 <- d_rt_within |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se)) +\n    geom_point(size = 3) +\n    labs(title = \"Median Response Time\",\n         x = \"Instruction\",\n         y = \"Median Response Time [s]\") +\n    theme_minimal(base_size = 12) +\n    theme(legend.position = \"none\")\n\np7 + p8\n```\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n- [Hier](http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)) finden Sie weitere Code-Beispiele für das Plotten von Verteilungsmassen.\n\n- [Hier](https://kogpsy.github.io/neuroscicomplabFS22/pages/chapters/07_response_times_i.html#zusammenfassen-zentrale-tendenz-und-dispersion) finden Sie Informationen, wie Reaktionszeiten zusammengefasst und visualisiert werden könnten.\n\n## Visualisieren von Modellschätzungen\n\nWenn für die statistische Analyse ein Modell geschätzt wurde, kann auch dies visualisiert werden. \nAuf diese Form der Visualisierung wird in diesem Kapitel aber nicht eingegangen. \n\n- [sjPlot](https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_model_estimates.html): Package zum Plotten von Fixed Effects\n\n- [see](https://dominiquemakowski.github.io/publication/ludecke2021see/ludecke2021see.pdf): Package zum Visualisieren von Statistischen Modellen\n\n\n# Kommunikation: Forschungsergebnisse visualisieren\n\nKommunikation der Ergebnisse findet vor allem in den wissenschaftlichen Artikeln, Postern oder Präsentationen statt. \nBei Visualisierungen die der Kommunkation dienen sind folgende Merkmale wichtig:\n\n## Beschriftungen\n\nDie genaue Beschriftung und deren Lesbarkeit ist für diese Form von Grafiken zentral. Achten Sie sich auf Folgendes: \n\n- Die Achsenbeschriftungen enthalten die verwendete Variable in Klartext (nicht den R Variablennamen) und wenn zutreffend auch die Masseinheit (z.B. *Response Time [ms]*). Beschriftungen können Sie einfügen mit `labs()`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_boxplot +\nlabs(title = \"Der Titel der Grafik\", \n     subtitle = \"Der Subtitel der Grafik\",\n     x = \"hier kommt Label x [Masseinheit]\", \n     y = \"hier kommt Label y [Masseinheit]\",\n     caption = \" Hier kommt eine Caption\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: No shared levels found between `names(values)` of the manual scale and the\ndata's fill values.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](data_visualization_2_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n- Farben / Formen usw. werden in einer Legende den Gruppen zugeordnet (Ausnahme: wenn Daten von einzelnen Personen geplottet werden, wird die Versuchspersonennummer nicht aufgeführt). \n\n- Masse der zentralen Tendenz und Varianzmasse werden beschrieben (z.B. Standardfehler oder Standardabweichung?)\n\n\n## 5 Merkmale einer guten Grafik\n\nEs gibt unzählige Optionen die eigenen Daten zu visualisieren. \nFolgende Prinzipien helfen beim Erstellen einer informativen Grafik, die zur Kommunikation der Ergebnisse dient.\n\n<aside>Die Punkte 3-5 wurden aus dem Buch \"The Visual Display of Quantitative Information\" von Edward Tufte, 1986 entnommen.</aside>\n\n#### 1. Eine Frage beantworten\n \nJede Grafik sollte mindestens eine teilweise aber auch mehrere Fragen beantworten.\n\n👉 Welche Frage möchte ich beantworten? Welche Form der Visualisierung beantwortet diese Frage am besten?\n\nHierbei kann es hilfreich sein den \"Arbeitstitel\" der Grafik als Frage zu formulieren. \n\n\n#### 2. Zielgruppe berücksichtigen\n\nBeim Erstellen der Grafik sollte beachtet werden, an wen sich die Grafik richtet. Für eine Präsentation müssen die Achsenbeschriftungen vergrössert und die Grafik simpel gehalten werden. In einem wissenschaftlichen Artikel kann die Grafik komplexer gestaltet werden, da die Lesenden sich mehr Zeit zum Anschauen nehmen können. Zudem sollten hier die Vorgaben des Journals berücksichtigt werden. Auch wichtig ist das Verwenden von \"farbenblind-freundlichen\" Palletten, rot und grün ist z.B. eine schlechte Wahl.\n\n👉 Für welchen Zweck / für wen erstelle ich die Grafik? Wie ist das Vorwissen des Zielpublikums?\n\n- Für einen Fachartikel lohnt es sich, zu Beginn die Vorgaben der Fachzeitschrift zu berücksichtigen.\n\n\n#### 3. Die Daten zeigen\n\nDas tönt simpel, wird aber oft nicht berücksichtigt. Bei einer Grafik geht es in erster Linie um die Daten. Es sollte die simpelste Form gewählt werden, welche die Informationen vermittelt. Oft braucht es keine ausgefallenen Grafikideen oder neuartigen Formate. Hierbei ist es wichtig, die Art der Daten zu berücksichtigen: Wie viele Variablen sind es? Sind diese kontinuierlich (z.B. Reaktionszeiten) oder diskret (z.B. Experimentalbedingungen)? Wie viele Dimensionen haben meine Daten? Mit zwei Achsen lassen sich zwei Dimensionen darstellen, zusätzlich können mit Farben und Formen noch weitere Dimensionen abgebildet werden (z.B. Millisekunden, Bedingung 1 und Bedingung 2). Es können Rohwerte geplottet werden oder *summary statistics* (z.B. Mittelwerte, Standardabweichungen)\n\n👉 Welche Art Grafik eignet sich für meine Frage und meine Daten? Schauen Sie z.B. [hier](https://www.data-to-viz.com) nach oder nutzen Sie das `esquisse`-Package.\n\n- Beispiele für verschiedenen Plots in R sind z.B. histogram, boxplot, violin plot, scatter plot / correlogram, jitter plot, raincloud plot, percentiles / shift functions, area chart, heat map.\n\n\n#### 4. Optimieren des *data-ink ratio*s \n\nDas *Daten-Tinte-Verhältnis* sollte so optimal wie möglich sein. Das bedeutet, das idealerweise jeder Strich, jeder Punkt, jedes Textfeld Information beinhaltet. Alles was keine Information transportiert oder nur wiederholt kann weggelassen werden.\n\n👉 Was kann ich weglassen?\n\n- In R kann zum Schluss des Plots `+ theme_minimal()` hinzugefügt werden, dies entfernt u.a. den grauen Hintergrund. Das Grau des Hintergrunds ist Farbe (*ink*), welche keine Information transportiert, das Weglassen lässt die Grafik ruhiger wirken.\n\n\n#### 5. Feedback einholen und revidieren\n\nDas Erstellen einer guten Grafik ist iterativ, das heisst, sie wird immer wieder überarbeitet, bis sie die Information möglichst einfach, genau aber klar kommuniziert. Hierbei ist Feedback oft unerlässlich.\n\n👉 Was denken andere über Ihre Grafik?\n\n\n\n\n",
    "supporting": [
      "data_visualization_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}